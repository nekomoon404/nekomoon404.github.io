<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>nekomoon的个人小站</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://nekomoon404.github.io/"/>
  <updated>2020-09-22T13:00:11.511Z</updated>
  <id>http://nekomoon404.github.io/</id>
  
  <author>
    <name>nekomoon</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>XGBoost原理简述</title>
    <link href="http://nekomoon404.github.io/2020/09/22/XGBoost%E5%8E%9F%E7%90%86%E7%AE%80%E8%BF%B0/"/>
    <id>http://nekomoon404.github.io/2020/09/22/XGBoost%E5%8E%9F%E7%90%86%E7%AE%80%E8%BF%B0/</id>
    <published>2020-09-22T12:18:46.000Z</published>
    <updated>2020-09-22T13:00:11.511Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>笔记主要是参考了贪心学院在B站的公开课<a href="https://www.bilibili.com/video/BV1si4y1G7Jb" target="_blank" rel="noopener">XGBoost的技术剖析</a></p><p>这篇博客也讲的十分详细：<a href="https://blog.csdn.net/wuzhongqiang/article/details/104854890" target="_blank" rel="noopener">白话机器学习算法理论+实战番外篇之Xgboost</a>，有一些上面的课程没有讲到的内容，如节点的最优切分点划分，要进行特征遍历，作者没有使用等宽或等频分桶，而是提出了等值percentiles划分算法（Weight Quantile Sketch）。</p><p>集成算法，弱分类器的概念等等就先略去了。</p></blockquote><p>根据各个弱分类器之间有无依赖关系，集成算法可以分为Boosting和Bagging：</p><ul><li>Boosting流派：各分类器之间没有依赖关系，必须串行，比如Adaboost，GBDT，Xgboost；</li><li>Bagging流派：各分类器之间没有依赖关系，可各自并行，比如随机森林。</li></ul><p>为什么XGBoost这么火？</p><ul><li><p>算法可以并行，训练效率高；</p></li><li><p>比起其他算法，世界效果好；</p></li><li><p>由于可控参数（超参数）多，可以灵活调整；</p></li></ul><p>学习路径：</p><ul><li>如何构造目标函数？（XGBoost的目标函数不是连续型的）</li><li>目标函数直接优化难，如何近似？（泰勒级数，Taylor Expansion）</li><li>如何把树的结果引入到目标函数？</li><li>仍然难优化，要不要使用贪心算法？</li></ul><h3 id="1-如何构造目标函数"><a href="#1-如何构造目标函数" class="headerlink" title="1.如何构造目标函数"></a>1.如何构造目标函数</h3><p>回顾如何使用多棵树来预测：</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/微信图片_20200922202546.png" style="zoom: 45%;"></p><p>假设已经训练了K颗树，则对于第$i$个样本的（最终）预测值为：</p><script type="math/tex; mode=display">\hat{y_i} = \sum^k_{k=1}f_k(x_i), \, f_k \in \mathcal{F}</script><p>目标函数为：</p><script type="math/tex; mode=display">Obj = \sum^n_{i=1} l(y_i,\hat{y_i}) + \sum^k_{k=1} \Omega(f_k)</script><p>其中前一项为损失函数，$y_i$为真实值，$\hat{y_i}$为预测值，$l(y_i,\hat{y_i})$为针对当前问题的loss；后一项为Penalty，或者称Regulation，控制模型的复杂度，防止过拟合。</p><p>现在的问题是如何给每一个树加上Penalty / Regulation。</p><p>回顾在决策树中如何定义树的复杂度：</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/微信图片_20200922202606.png" style="zoom:50%;"></p><p>$\sum^n_{i=1}l(y_i,\hat{y_i})$中计算了所有样本的loss，loss函数包含了不同树模型的loss，这时就可以使用叠加式的训练（Additive Training），当训练第$k$个模型（树）时，前面的第1到第$k-1$颗树是已知的。</p><p>假设现在我们要去构建第$k$颗树，</p><ul><li><p>给定$x_i$；</p></li><li><p>$\hat{y_i}^{(0)} = 0 \gets$  Default case ;</p></li><li>$\hat{y_i}^{(1)} = f_1(x_i) = \hat{y_i}^{(0)} + f_1(x_i)$；</li><li>$\hat{y_i}^{(2)} = f_1(x_i) + f_2(x_i) = \hat{y_i}^{(1)} + f_2(x_i)$；</li><li>$\dots$</li><li>$\hat{y_i}^{(k)} = f_1(x_i) + f_2(x_i) + \dots + f_k(x_i)= \sum^{k-1}_{j=1}f_j(x_i)+f_k(x_i)=\hat{y_i}^{(k-1)} + f_k(x_i)$；</li></ul><p>其中$\hat{y_i}^{(k-1)}$表示前$k-1$颗树的预测值之和，$f_k(x_i)$表示第$k$颗树的预测值，两者之和要和真实值$y_i$越接近越好。</p><p>因为前$k-1$颗树是训练好的，则目标函数可以写成：</p><script type="math/tex; mode=display">\begin{align*}Obj &= \sum^n_{i=1} l(y_i, \hat{y_i}^{(k)}) + \sum^k_{k=1}\Omega(f_k)\\    &= \sum^n_{i=1} l(y_i, \hat{y_i}^{(k-1)} + f_k(x_i)) + \sum^{k-1}_{j=1}\Omega(f_j)+\Omega(f_k)\end{align*}</script><p>其中$\hat{y_i}^{(k-1)}$和$\sum^{k-1}_{j=1}\Omega(f_j)$可以看作是常数，则当训练第$k$颗树时，我们要最小化：</p><script type="math/tex; mode=display">minimize \quad \sum^n_{i=1} l(y_i, \hat{y_i}^{(k-1)} + f_k(x_i)) + \Omega(f_k)</script><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/微信图片_20200922202613.png" style="zoom:50%;"></p><h3 id="2-使用泰勒级数优化目标函数"><a href="#2-使用泰勒级数优化目标函数" class="headerlink" title="2.使用泰勒级数优化目标函数"></a>2.使用泰勒级数优化目标函数</h3><p>由上一节我们可知，构建第$k$颗树时的目标函数是  ：</p><script type="math/tex; mode=display">\begin{align*}Obj &= \sum^n_{i=1} l(y_i, \hat{y_i}^{(k-1)} + f_k(x_i)) + \Omega(f_k)\end{align*}</script><p>回顾泰勒级数Taylor Expansion：</p><script type="math/tex; mode=display">f(x+\Delta x) \approx f(x) + f'(x) \cdot \Delta x + \frac{1}{2} f^{''}(x)\cdot \Delta x^2</script><p>令其中的$f(x) = l(y_i, \hat{y_i}^{(k-1)} )$，$\Delta x= f_k(x_i)$，则有：</p><script type="math/tex; mode=display">\begin{align*}Obj &= \sum^n_{i=1} l(y_i, \hat{y_i}^{(k-1)} + f_k(x_i)) + \Omega(f_k) \\    &= \sum^n_{i=1} \left[ l(y_i, \hat{y_i}^{(k-1)} ) +\partial_{\hat{y_i}^{(k-1)}} l(y_i, \hat{y_i}^{(k-1)} ) \cdot f_k(x_i) + \frac{1}{2}\partial^2_{\hat{y_i}^{(k-1)}} l(y_i, \hat{y_i}^{(k-1)} ) \cdot f^2_k(x_i) \right]+ \Omega(f_k) \\    &= \sum^n_{i=1} \left[ l(y_i, \hat{y_i}^{(k-1)} ) +g_i \cdot f_k(x_i) + h_i \cdot f^2_k(x_i) \right]+ \Omega(f_k)\end{align*}</script><p>第一项$ l(y_i, \hat{y_i}^{(k-1)} )$是已知的，那么最下化目标函数就等价于：</p><script type="math/tex; mode=display">minimize \sum^n_{i=1} \left[ g_i \cdot f_k(x_i) + h_i \cdot f^2_k(x_i) \right]+ \Omega(f_k)</script><p>注：当训练第$k$颗树时，$\{h_i, g_i\}$是已知的。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/微信图片_20200922202618.png" style="zoom: 50%;"></p><h3 id="3-在树的形状已知的情况下，求目标函数的最小值"><a href="#3-在树的形状已知的情况下，求目标函数的最小值" class="headerlink" title="3.在树的形状已知的情况下，求目标函数的最小值"></a>3.在树的形状已知的情况下，求目标函数的最小值</h3><p>接下来我们要把$f_k(x_i)$和$\Omega(f_k)$参数化。考虑现有如下图的一个树，那我们如何把这颗树用参数化表示出来：</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/微信图片_20200922202623.png" style="zoom:50%;"></p><p>定义一个权重变量，或者称leaf value，$w=(w_1, w_2, w_3) = (15, 12, 20)$；</p><p>定义一个函数$q(x)$，表示样本$x$的位置，$q(x_1) =1, q(x_2)=3, q(x_3)= 1, q(x_4) = 2, q(x_5)=3$；</p><p>则有$f_k(x_i) = w_{q(x_i)} $ ，这样就把$f_k(x_i)$参数化了，但有个问题是$w$的下标还是个函数，为此我们还需定义一个函数$I_j=\{i | q(x_i)=j\}$，表示那些样本$x_i$会落在第$j$个位置上，它按叶节点的位置把样本重新组织。$I_1=\{1,3\},I_2=\{4\}, I_3=\{2, 5\}$。</p><p>这样我们原先以样本为单位累加得到$\sum^n_{i=1}  g_i \cdot f_k(x_i)=\sum^n_{i=1}  g_i \cdot w_{q(x_i)}$这一项，就可以换种思路，以叶节点为单位累加，以上图为例：</p><script type="math/tex; mode=display">\begin{align*}&g_1 \cdot w_{q(x_1)}+g_2 \cdot w_{q(x_2)}+g_3 \cdot w_{q(x_3)}+g_4 \cdot w_{q(x_4)}+g_5 \cdot w_{q(x_5)}\\=&g_1 \cdot w_{q(x_1)}+g_3 \cdot w_{q(x_3)}+ \\&g_2 \cdot w_{q(x_2)}+\\&g_4 \cdot w_{q(x_4)}+g_5 \cdot w_{q(x_5)}\\=& g_1 \cdot w_1+g_3 \cdot w_1+ \\&g_2 \cdot w_2+\\&g_4 \cdot w_3+g_5 \cdot w_3\\=&\sum^T_{j=1}(\sum_{i\in I_j } g_i) \cdot w_j\end{align*}</script><p>接着考虑如何定义一颗树的复杂度，可以是树的复杂度 = 叶节点个数 + leaf value，即：</p><script type="math/tex; mode=display">\Omega(f_k) = \gamma T + \frac{1}{2} \lambda \sum^T_{j=1} w_j^2</script><p>其中$T$是叶节点的个数，$w_j$是第$j$个叶节点的leaf value；$\gamma$和$\lambda$控制两部分的权重，是超参数。</p><p>最后将两部分结合起来，得到新的目标函数（<strong>假设树的形状已知</strong>）</p><script type="math/tex; mode=display">\begin{align*}& \sum^n_{i=1} \left[ g_i \cdot f_k(x_i) + h_i \cdot f^2_k(x_i) \right]+ \Omega(f_k)\\=& \sum^n_{i=1} \left[ g_i \cdot w_{q(x_i)} + h_i \cdot w^2_{q(x_i)} \right]+ \gamma T + \frac{1}{2} \lambda \sum^T_{j=1} w_j^2  \\=& \sum^T_{j=1} \left[(\sum_{i\in I_j } g_i) \cdot w_j  + \frac{1}{2}(\sum_{i\in I_j } h_i + \lambda) \cdot w^2_j\right] + \gamma T\end{align*}</script><p>令$G_j = \sum_{i\in I_j } g_i$，$H_j = \sum_{i\in I_j } h_i$，则使前一项最小的$w_j$值（回顾一元二次方程）为：</p><script type="math/tex; mode=display">w_j^* = -\frac{G_j}{H_j+\lambda}</script><p>此时目标函数的最小值为：</p><script type="math/tex; mode=display">Obj* = \frac{1}{2} \cdot \sum^T_{j=1} \frac{G_j^2}{H_j+\lambda} + \gamma T</script><p> 那么到目前我们解决了，<strong>在树的形状已知的情况下</strong>，可以求出第$k$树的最小的目标函数值。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/微信图片_20200922202627.png" style="zoom:50%;"></p><p>那接下来我们要做的是在所有可能的形状的树中，寻找出$Obj^*$最小的那颗树。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/微信图片_20200922202633.png" style="zoom:50%;"></p><p>寻找树的形状可以用暴力算法（Brute Force Search），但这样做就效率太低了，复杂度也是节点个数的指数级的。 可行的方法是使用<strong>贪心算法</strong>去寻找。</p><p>回顾我们如何去构造一颗决策树。选择特征的依据是使不确定性变小，特征的score = 原（不确定性）- 分之后（不确定性），称为Information Gain（信息增益），每次分支的依据就是使信息增益最大化。那把这里的不确定性（Entropy）换成 $Obj$，就可以完成对有最小的$Obj^*$的树的寻找。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/微信图片_20200922202638.png" style="zoom:50%;"></p><p>通过下面的例子来看一下如何寻找最好的树的形状，即寻找最好的Split。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/微信图片_20200922202648.png" style="zoom:50%;"></p><p>xgboost贪心建树的思路：遍历所有特征以及所有分割点，每次算最好的那个。但这样做代价太大了，尤其是数据量很大，分割点很多的时候，计算起来非常复杂并且也无法读入内存进行计算。作者提出了一种近似分割的方式（可以理解为分割点分桶的思路），选出一些候选的分裂点，然后再遍历这些较少的分裂点来找到最佳分裂点。</p><p>进行分桶候选分裂点的一般思路是根据特征值的大小进行等宽分桶，或者进行等频分桶。这样做选择出的候选点确实少了很多，但这样划分是没什么依据的，缺乏可解释性。</p><p>作者采用了一种对loss的影响权重的等值percentiles（百分比分位数）划分算法（Weight Quantile Sketch）。考虑的是想让loss在左右子树上分布的均匀一些，而不是样本数量的均匀，因为每个样本对降低loss的贡献可能不一样，按样本均分会导致分开之后左子树和右子树loss分布不均匀，</p><p>其实这里这个损失函数还可以进一步化简的（和上面的化简不一样，上面的化简是把遍历样本转到了遍历叶子上得到基于决策树的目标函数，这里是从目标函数本身出发进行化简）：</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/微信图片_20200922205540.png" style="zoom:45%;"></p><p>后面的每一个分类器都是在拟合每个样本的一个残差 $\frac{g_i}{h_i}$，$h_i$可以看做计算残差时某个样本的重要性，即每个样本对降低loss的贡献程度。第一个问题说的听清楚了吧。</p><blockquote><p>Xgboost引入了二阶导之后，相当于在模型降低残差的时候给各个样本根据贡献度不同加入了一个权重，这样就能更好的加速拟合和收敛。GBDT只用到了一阶导数，这样只知道梯度大的样本降低残差效果好，梯度小的样本降低残差不好，但是好与不好的程度在GBDT中无法展现。而xgboost这里就通过二阶导可以展示出来，这样模型训的时候就有数了</p></blockquote>]]></content>
    
    <summary type="html">
    
      学习了XGBoost的原理。
    
    </summary>
    
    
      <category term="Machine Learning" scheme="http://nekomoon404.github.io/categories/Machine-Learning/"/>
    
    
      <category term="XGBoost" scheme="http://nekomoon404.github.io/tags/XGBoost/"/>
    
  </entry>
  
  <entry>
    <title>贷款违约预测（1）赛题理解</title>
    <link href="http://nekomoon404.github.io/2020/09/15/%E8%B4%B7%E6%AC%BE%E8%BF%9D%E7%BA%A6%E9%A2%84%E6%B5%8B%EF%BC%881%EF%BC%89%E8%B5%9B%E9%A2%98%E7%90%86%E8%A7%A3/"/>
    <id>http://nekomoon404.github.io/2020/09/15/%E8%B4%B7%E6%AC%BE%E8%BF%9D%E7%BA%A6%E9%A2%84%E6%B5%8B%EF%BC%881%EF%BC%89%E8%B5%9B%E9%A2%98%E7%90%86%E8%A7%A3/</id>
    <published>2020-09-15T11:05:51.000Z</published>
    <updated>2020-09-15T13:02:38.461Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-赛题概况"><a href="#1-赛题概况" class="headerlink" title="1.赛题概况"></a>1.赛题概况</h3><p>比赛地址：<a href="https://tianchi.aliyun.com/competition/entrance/531830/introduction" target="_blank" rel="noopener">零基础入门金融风控-贷款违约预测</a></p><p>本次比赛以金融风控中的个人信贷为背景，根据贷款申请人的数据信息预测其是否有违约的可能，以此判断是否通过此项贷款，是一个二分类问题。</p><p>赛题的数据来自某信贷平台的贷款记录，包括47列变量信息，其中15列为匿名变量，比赛界面有对应的数据概况介绍，说明列的性质特征。总数据量120万条，其中，训练集80万条，测试集A 20万条，测试集B 20万条。</p><p><strong>预测指标</strong>：采用AUC作为评价指标，AUC越接近1.0，模型的预测性能越好。</p><h3 id="2-二分类问题中常见的评估指标"><a href="#2-二分类问题中常见的评估指标" class="headerlink" title="2.二分类问题中常见的评估指标"></a>2.二分类问题中常见的评估指标</h3><p>1.<strong>混淆矩阵（Confuse Matrix）</strong></p><p>二分类问题的预测结果可以根据情况分成以下四类：</p><p>（1）真正 TP（True Positive）：预测值为1，真实值为1</p><p>（2）假正 FP（False Positive）：预测值为1，真实值为0</p><p>（3）真负 TN（True Negative）：预测值为1，真实值为0</p><p>（4）假负 FN（False Negative）：预测值为0，真实值为1</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200915195033.png" style="zoom: 80%;"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">y_true = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">y_pred = [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>]</span><br><span class="line">confusion_matrix(y_true, y_pred)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[<span class="number">0</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">1</span>]], dtype=int64)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tn, fp, fn, tp = confusion_matrix([<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>]).ravel()</span><br><span class="line">(tn, fp, fn, tp)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>2.<strong>准确率（Accuracy）</strong></p><p>分类正确的样本数占总样本数的比例数。准确率在样本不均衡的数据集上不适用。</p><script type="math/tex; mode=display">Accuracy = \frac{TP+TN}{TP+TN+FP+FN}</script><p>3.<strong>精确率（Precision）</strong></p><p>又称查准率，正确预测为正样本（TP）占预测为正样本（TP+FP）的比例。</p><script type="math/tex; mode=display">Percision=\frac{TP}{TP+FP}</script><p>4.<strong>召回率（Recall）</strong></p><p>又称查全率，正确预测为正样本（TP）占正样本的（TP+FN）比例。</p><script type="math/tex; mode=display">Recall=\frac{TP}{TP+FN}</script><p>5.<strong>F1 - score</strong></p><p>Precision和Recall指标有时是此消彼长的，即精准率高了，召回率就下降，在一些场景下要兼顾精准率和召回率，最常见的方法就是F-Measure，又称F-Score。F-Measure是P和R的加权调和平均，即；</p><script type="math/tex; mode=display">\frac{1}{F_{\beta}}=\frac{1}{1+\beta^2} \cdot \left( \frac{1}{P}+\frac{\beta^2}{R}\right) \\F_{\beta} = \frac{(1+\beta^2)\times P \times R}{(\beta^2 \times P) + R}</script><p>当$\beta=1$时，也就是常见的F1-Score，是P和R的调和平均，当F1较高时，模型的性能越好。</p><script type="math/tex; mode=display">F1-Socre = \frac{2\times P \times R }{P+R}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"></span><br><span class="line">y_true = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">y_pred = [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">print(<span class="string">'accuracy:'</span>,  metrics.accuracy_score(y_true, y_pred))</span><br><span class="line">print(<span class="string">'precision:'</span>, metrics.precision_score(y_true, y_pred))</span><br><span class="line">print(<span class="string">'recall:'</span>, metrics.recall_score(y_true, y_pred))</span><br><span class="line">print(<span class="string">'f1-score:'</span>, metrics.f1_score(y_true, y_pred))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">accuracy: <span class="number">0.25</span></span><br><span class="line">precision: <span class="number">0.3333333333333333</span></span><br><span class="line">recall: <span class="number">0.5</span></span><br><span class="line">f1-score: <span class="number">0.4</span></span><br></pre></td></tr></table></figure><p>6.<strong>P-R曲线（Precision-Recall Curve）</strong></p><p>描述精确率/召回率变化的曲线。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200915201039.png" style="zoom: 60%;"></p><p>若一个学习器A的P-R曲线被另一个学习器B的P-R曲线完全包住，则称：B的性能优于A。若A和B的曲线发生了交叉，则谁的曲线下的面积大，谁的性能更优。但一般来说，曲线下的面积是很难进行估算的，所以衍生出了“平衡点”（Break-Event Point，简称BEP），即当P=R时的取值，平衡点的取值越高，性能更优。</p><p>7.<strong>ROC曲线（Receiver Operating Characteristic）</strong></p><p>ROC曲线有个很好的特性：当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变。在实际的数据集中经常会出现<strong>类别不平衡（Class Imbalance）</strong>现象，即负样本比正样本多很多（或者相反），而且测试数据中的正负样本的分布也可能随着时间变化，ROC以及AUC可以很好的消除样本类别不平衡对指标结果产生的影响。</p><p>ROC曲线分别使用下面两个指标作为X轴和Y轴：</p><p>（1）真正率（True Positive Rate , TPR），又称灵敏度（sensitivity）：（其实和召回率一样）</p><script type="math/tex; mode=display">TPR = \frac{TP}{TP+FN}</script><p>（2）假正率（False Positive Rate , FPR），又称特异度（specificity）：</p><script type="math/tex; mode=display">FPR = \frac{FP}{TN+FP}</script><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200915202153.png" style="zoom:50%;"></p><p>8.<strong>AUC（Area Under Curve）</strong></p><p>曲线下面积，是处于ROC Curve下方的那部分面积的大小。对于ROC曲线下方面积越大表明模型性能越好，于是AUC就是由此产生的评价指标。通常，AUC的值介于0.5到1.0之间，较大的AUC代表了模型较好的性能。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line">y_true = np.array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line">y_score = np.array([<span class="number">0.1</span>, <span class="number">0.4</span>, <span class="number">0.35</span>, <span class="number">0.8</span>])</span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score, pos_label=<span class="number">2</span>) </span><br><span class="line">auc=metrics.auc(fpr, tpr)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">'ROC'</span>)</span><br><span class="line">plt.plot(fpr, tpr,<span class="string">'b'</span>,label=<span class="string">'AUC = %0.4f'</span>% auc)</span><br><span class="line">plt.legend(loc=<span class="string">'lower right'</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">1</span>],<span class="string">'r--'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'TPR'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'FPR'</span>)</span><br></pre></td></tr></table></figure><p><img src="/2020/09/15/%E8%B4%B7%E6%AC%BE%E8%BF%9D%E7%BA%A6%E9%A2%84%E6%B5%8B%EF%BC%881%EF%BC%89%E8%B5%9B%E9%A2%98%E7%90%86%E8%A7%A3/output_4_1.png" style="zoom:80%;"></p><blockquote><p>参考：<a href="https://www.cnblogs.com/guoyaohua/p/classification-metrics.html" target="_blank" rel="noopener">【机器学习】一文读懂分类算法常用评价指标</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      Datawhale的0基础入门金融风控之贷款违约预测挑战赛的Task1：赛题理解。
    
    </summary>
    
    
      <category term="Machine Learning" scheme="http://nekomoon404.github.io/categories/Machine-Learning/"/>
    
    
  </entry>
  
  <entry>
    <title>DL笔记（16）Transfer Learning</title>
    <link href="http://nekomoon404.github.io/2020/08/13/ML%E7%AC%94%E8%AE%B0%EF%BC%8816%EF%BC%89Transfer-Learning/"/>
    <id>http://nekomoon404.github.io/2020/08/13/ML%E7%AC%94%E8%AE%B0%EF%BC%8816%EF%BC%89Transfer-Learning/</id>
    <published>2020-08-13T00:51:13.000Z</published>
    <updated>2020-08-13T02:56:46.358Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><p>Transfer learning（迁移学习），是属于机器学习的一种研究领域，它专注于存储已有问题的解决模型，并将其利用在其他不同但相关问题上，正如人类可以将一个领域学习到的知识和经验，应用到其他相似的领域中去一样，机器同样也能做到。</p><p>传统的机器学习/数据挖掘只有在训练集数据和测试集数据都来自同一个feature space（特征空间）和统一分布的时候才运行的比较好，这意味着每一次换了数据都要重新训练模型，太麻烦了。比如：</p><p>（1）从数据类型/内容上看，对于新的数据集，获取新的训练数据很贵也很难。</p><p>（2）从时间维度上看，有些数据集很容易过期，即不同时期的数据分布也会不同。</p><blockquote><p>Transfer learning的概念参考了这篇博客<a href="https://cloud.tencent.com/developer/article/1636741" target="_blank" rel="noopener">迁移学习</a></p></blockquote><p><strong>not directly related</strong></p><p>以猫狗识别为例，解释“不直接相关”的含义：</p><ul><li><p>input <strong>domain（域）</strong>是类似的，但task是无关的，比如输入都是动物的图像，但这些data是属于另一组有关大象和老虎识别的task；</p></li><li><p>input domain是不同的，但task是一样的，比如task同样是做猫狗识别，但输入的是卡通类型的图像。</p></li></ul><blockquote><p>domain：包括两部分：1.feature space（特征空间）；2.probability（概率）。所以当我们说domain不同的时候，就得分两种情况。可能是feature space不同，也可能是feature space一样但probability不同。这里指的是前者，即feature space不同。</p></blockquote><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200813090714.png" style="zoom: 50%;"></p><p><strong>overview</strong></p><p>迁移学习是很多方法的集合，这里介绍一些概念：</p><ul><li>Target Data：和task直接相关的data；</li><li>Source Data：和task没有直接关系的data。</li></ul><blockquote><p>source是用于训练模型的域/任务，target是要用前者的模型对自己的数据进行预测/分类/聚类等机器学习任务的域/任务。</p></blockquote><p>按照labeled data和unlabeled data又可以划分为四种：</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200813090728.png" style="zoom: 50%;"></p><h3 id="2-labelled-source-data-amp-labeled-target-data"><a href="#2-labelled-source-data-amp-labeled-target-data" class="headerlink" title="2. labelled source data &amp; labeled target data"></a>2. labelled source data &amp; labeled target data</h3><p>这里target data和source data都是带有标签的：</p><ul><li><p>target data：$(x^t,y^t)$，作为有效数据，通常量是很少的。如果target data量非常少，则被称为one-shot learning；</p></li><li><p>source data：$(x^s, y^s)$，作为不直接相关数据，通常量是很多的。</p></li></ul><h4 id="2-1-Model-Fine-tuning"><a href="#2-1-Model-Fine-tuning" class="headerlink" title="2.1. Model Fine-tuning"></a>2.1. Model Fine-tuning</h4><p>Model Fine-tuning（模型微调）的基本思想：用source data去训练一个model，再用target data对model进行fine-tune（微调）。“微调”类似于pre-training，就是把用source data训练出的model参数当做是参数的初始值，再用target data继续训练下去即可，但当直接相关的数据量非常少时，这种方法很容易会出问题。所以训练的时候要小心，有许多技巧值得注意。</p><p><strong>Conservation Training</strong></p><p>如果现在有大量的source data，比如在语音识别中有大量不同人的声音数据，可以拿它去训练一个语音识别的神经网络，而现在你拥有的target data，即特定某个人的语音数据，可能只有十几条左右，如果直接拿这些数据去再训练，肯定得不到好的结果</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200813090732.png" style="zoom:50%;"></p><p>此时我们就需要在训练的时候加一些限制，让用target data训练前后的model不要相差太多：</p><ul><li>可以让新旧两个model在看到同一笔data的时候，output越接近越好；</li><li>或者让新旧两个model的L2 norm越小越好，参数尽可能接近；</li><li>总之让两个model不要相差太多，防止由于target data的训练导致过拟合。</li></ul><p>这里的限制就类似于做regularization。</p><p><strong>Layer Transfer</strong></p><p>现在我们已经有一个用source data训练好的model，此时把该model的某几个layer拿出来复制到同样大小的新model里，接下来<strong>用target data去训练余下的没有被复制到的layer</strong>。这样做的好处是target data只需要考虑model中非常少的参数，这样就可以避免过拟合。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200813090735.png" style="zoom:50%;"></p><p>这个对部分layer进行迁移的过程，就体现了迁移学习的思想，那么哪些layer需要被复制迁移，哪些不需要呢？</p><p>值得注意的是，<strong>在不同的task上，需要被复制迁移的layer往往是不一样的</strong>：</p><ul><li><p>在语音识别中，往往迁移的是最后几层layer，再重新训练与输入端相邻的那几层。</p><p>由于人口腔结构不同，同样的发音方式得到的发音是不一样的，NN的前几层会从声音信号里提取出发音方式，再用后几层判断对应的词汇，从这个角度看，NN的后几层是跟特定的人没有关系的，因此可做迁移。</p></li><li><p>在图像处理中，往往迁移的是前面几层layer，再重新训练后面的layer。</p><p>CNN在前几层通常是做最简单的识别，比如识别是否有直线斜线、是否有简单的几何图形等，这些layer的功能是可以被迁移到其它task上通用的。</p></li><li><p>主要还是具体问题具体分析。</p></li></ul><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200813090739.png" style="zoom:50%;"></p><h4 id="2-2-Multitask-Learning"><a href="#2-2-Multitask-Learning" class="headerlink" title="2.2. Multitask Learning"></a>2.2. Multitask Learning</h4><p>Fine-tune仅考虑在target data上的表现，而Multitask Learning（多任务学习），则是同时考虑model在source data和target data上的表现。</p><p>如果两个task的输入特征类似，则可以用同一个神经网络的前几层layer做相同的工作，到后几层再分方向到不同的task上，这样做的好处是前几层得到的data比较多，可以被训练得更充分。有时候task A和task B的输入输出都不相同，但中间可能会做一些类似的处理，则可以让两个神经网络共享中间的几层layer，也可以达到类似的效果。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200813090743.png" style="zoom:50%;"></p><p>以上方法要求不同的task之间要有一定的“共性”，这样才有共用一部分layer的可能性。</p><p><strong>Multilingual Speech Recognition</strong></p><p>多任务学习可以应用在语音识别上，比如可以同时对法语、德语、西班牙语、意大利语训练一个model，它们在前几层layer上共享参数，而在后几层layer上拥有自己各自的参数。在机器翻译上也可以使用同样的思想，比如训练一个同时可以中翻英和中翻日的model。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200813090746.png" style="zoom:50%;"></p><p>注属于同一个语系的语言翻译，比如欧洲国家的语言，几乎都是可以做迁移学习的；而语音方面则可迁移的范围更广。下图展示了只用普通话的语音数据和加了欧洲语言后的语音数后得到的错误率对比，其中横轴为使用的普通话数据量，纵轴为错误率，可以看出使用了迁移学习后，只需要原先一半的普通话语音数据就可以得到几乎一样的准确率</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200813090749.png" style="zoom: 50%;"></p><h4 id="2-3-Progressive-Neural-Network"><a href="#2-3-Progressive-Neural-Network" class="headerlink" title="2.3. Progressive Neural Network"></a>2.3. Progressive Neural Network</h4><p>如果两个task完全不相关，硬是把它们拿来一起训练反而会起到负面效果。而在Progressive Neural Network（渐进式神经网络）中，每个task对应model的hidden layer的输出都会被接到后续model的hidden layer的输入上，这样做的好处是：</p><ul><li>task 2的data并不会影响到task 1的model，因此task 1一定不会比原来更差；</li><li><p>task 2虽然可以借用task 1的参数，但可以将之直接设为0，最糟的情况下就等于没有这些参数，也不会对本身的表现产生影响；</p></li><li><p>task 3也做一样的事情，同时从task 1和task 2的hidden layer中得到信息。</p></li></ul><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200813090753.png" style="zoom:50%;"></p><blockquote><p>论文<a href="https://arxiv.org/pdf/1606.04671.pdf" target="_blank" rel="noopener">arxiv.org/pdf/1606.04671.pdf)</a></p><p>关于Progressive Neural Network可以参考：<a href="https://www.cnblogs.com/wangxiaocvpr/p/6002214.html" target="_blank" rel="noopener">论文笔记之：Progressive Neural Network Google DeepMind</a>；<a href="https://zhuanlan.zhihu.com/p/146454996" target="_blank" rel="noopener">Progressive Neural Network</a></p></blockquote><h3 id="3-labelled-source-data-amp-unlabeled-target-data"><a href="#3-labelled-source-data-amp-unlabeled-target-data" class="headerlink" title="3. labelled source data &amp; unlabeled target data"></a>3. labelled source data &amp; unlabeled target data</h3><p>下面介绍target data不带标签，而source data带标签的情况：</p><ul><li><p>target data：$(x^t)$</p></li><li><p>source data：$(x^s, y^s)$</p></li></ul><h4 id="3-1-Domain-adversarial-Training"><a href="#3-1-Domain-adversarial-Training" class="headerlink" title="3.1. Domain-adversarial Training"></a>3.1. Domain-adversarial Training</h4><p>如果source data是有label的，而target data是没有label的，该怎么处理呢？比如source data是labeled MNIST数字集，而target data则是加了颜色和背景的unlabeled数字集，虽然都是做数字识别，但两者的情况是非常不匹配的。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200813090756.png" style="zoom:50%;"></p><p>这个时候一般会把source data当做训练集，而target data当做测试集，如果不管训练集和测试集之间的差异，直接训练一个普通的model，得到的结果准确率会相当低。实际上，神经网络的前几层可以被看作是在抽取feature，后几层则是在做classification。如果把用MNIST训练好的model所提取出的feature做t-SNSE降维后的可视化，可以发现MNIST的数据特征明显分为紫色的十团，分别代表10个数字，而作为测试集的数据却是挤成一团的红色点，因此它们的特征提取方式根本不匹配。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200813090801.png" style="zoom:50%;"></p><p>所以我们希望前面的特征提取器(feature extractor)可以把domain的特性去除掉，不再使红点与蓝点分成两群，而是让它们都混在一起。这样我们就可以将用黑白MNIST训练好的model用在彩色MNIST数据上。</p><p>这里采取的做法是，在特征提取器(feature extractor)之后接一个<strong>域分类器(domain classifier)</strong>，以便分类出这些提取到的feature是来自于MNIST的数据集还是来自于MNIST-M的数据集，这个生成+辨别的架构与GAN非常类似。</p><p>只不过在这里，feature extractor可以通过把feature全部设为0，很轻易地骗过domain classifier，因此还需要给feature classifier增加任务的难度，它不只要骗过domain classifier，还要同时满足label predictor的需求。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200813090806.png" style="zoom: 50%;"></p><p>此时通过特征提取器得到的feature不仅可以消除不同domain的特性，还要保留原先digit的特性，既可以区分不同类别的数字集，又可以正确地识别出不同的数字。</p><p>通常神经网络的参数都是朝着最小化loss的目标共同前进的，但在这个神经网络里，三个组成部分的参数“各怀鬼胎”：</p><ul><li>对Label predictor，要把不同数字的分类准确率做的越高越好；</li><li>对Domain classifier，要正确地区分某张image是属于哪个domain；</li><li>对Feature extractor，要提高Label predictor的准确率，但要降低Domain classifier的准确率。</li></ul><p>这里可以看出，Feature extractor和Domain classifier的目标是相反的，要做到这一点，只需要在两者之间加一层梯度反转的layer即可（给domain classifier的梯度乘一个$-\lambda$），当NN做backward的时候，两者的参数更新往相反的方向走。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200813090809.png" style="zoom:50%;"></p><p>注意到，Domain classifier只能接受到Feature extractor给到的特征信息，而无法直接看到图像的样子，因此它最后一定会鉴别失败，所以如何提高Domain classifier的能力，让它经过一番“奋力挣扎”之后才牺牲是很重要的，如果它一直很弱，就无法把Feature extractor的潜能激发到极限。</p><h4 id="3-2-Zero-shot-Learning"><a href="#3-2-Zero-shot-Learning" class="headerlink" title="3.2. Zero-shot Learning"></a>3.2. Zero-shot Learning</h4><p>同样是source data有label，target data没有label的情况，但在Zero-shot Learning中的定义更严格一些，它假设source和target是两个完全不同的task，数据完全不相关。</p><p>在语音识别中，经常会遇到这个问题，毕竟词汇千千万万，总有一些词汇是训练时不曾遇到过的，它的处理方法是不要直接将识别的目标定成word，而是定成phoneme(音素)，再建立文字与phoneme之间的映射表即可。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200813090812.png" style="zoom:50%;"></p><p>在图像处理中，我们可以把每个类别都用其<strong>属性（attribute）</strong>表示，并且要具备独一无二的属性，在数据集中把每种动物按照特性划分，比如是否毛茸茸、有几只脚等，在训练的时候我们不直接去判断类别，而是去判断该图像的属性，再根据这些属性去找到最契合的类别即可。</p><p>有时候属性的维数也很大，以至于我们对属性要做embedding的降维映射，同样的，还要把训练集中的每张图像都通过某种转换投影到embedding space上的某个点，并且要保证属性投影的$g(y^i)$和对应图像投影的$f(x^i)$越接近越好，这里的$f()$和$g()$可以是两个神经网络。当遇到新的图像时，只需要将其投影到相同的embedding space，即可判断它与哪个属性对应的类别更接近。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200813090816.png" style="zoom:50%;"></p><p>但如果我们根本就无法找出每个动物的属性$y^i$是什么，那该怎么办？可以使用word vector，比如直接从维基百科上爬取图像对应的文字描述，再用word vector降维提取特征，映射到同样的空间即可。</p><p>以下这个loss function存在些问题，它会让model把所有不同的x和y都投影到同一个点上：</p><script type="math/tex; mode=display">f^*,g^*=\arg \min\limits_{f,g} \sum\limits_n ||f(x^n)-g(y^n)||_2</script><p>类似用t-SNE的思想，我们既要考虑同一对$x^n$和$y^n$距离要接近，又要考虑不属于同一对的$x^n$与$y^m$距离要拉大(这是前面的式子没有考虑到的)，于是有：</p><script type="math/tex; mode=display">f^*,g^*=\arg \min\limits_{f,g} \sum\limits_n \max(0, k-f(x^n)\cdot g(y^n)+\max\limits_{m\ne n} f(x^n)\cdot g(y^m))</script><p>其中$\max()$项的最小值是0，当：</p><script type="math/tex; mode=display">k-f(x^n)\cdot g(y^n)+\max\limits_{m\ne n} f(x^n)\cdot g(y^m)<0</script><p>即：</p><script type="math/tex; mode=display">f(x^n)\cdot g(y^n)-\max\limits_{m\ne n} f(x^n)\cdot g(y^m)>k</script><p>就表明此时$f(x^n)$和$g(y^n)$的inner product很大，即两者很接近，而$f(x^n)$和其他的$g(y^m)$即差的很远，它们的inner product很小。</p><p><strong>convex combination of semantic embedding</strong></p><p>还有另外一个简单的Zero-Shot learning的方法叫做convex combination of semantic embedding。假设我们现在有一个语音辨识系统，有一个word vector，这两个是从网络上下载下来的，就可以做这件事情。</p><p>我把一张图丢到neural network里面去，它的output没有办法决定是哪一个class，但它觉得有0.5的几率是lion，有0.5的几率是tiger。接下来你在去找lion跟tiger的word vector，然后把lion跟tiger的word vector得到新的vector(用1:1的比例混合,0.5V(tiger)+0.5V(lion))，那你再看哪一个word的vector跟这个混合之后的结果最接近。假设是liger最接近，那这个东西就是liger(狮虎)。这样就省去了Training。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200813102225.png" style="zoom: 33%;"></p><p>Zero-shot Learning in Machine Translation</p><p>下面是一个机器翻译的例子，Google Neural Machine Translation。在training的时候，machine看过如何把英文翻译成韩文，知道怎么把韩文翻译为英文，知道怎么把英文翻译为日文，知道怎么把日文翻译为英文。但是它从来没有看过日文翻译韩文的data，但是可以翻，但是它从来没有看过韩文翻译日文的data，但是可以翻。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200813103134.png" style="zoom: 40%;"></p><p>为什么zero-shot在这个task上是可行的呢？如果你今天用同一个model做了不同语言之间的translation以后，machine可以学到的事情是：对不同语言的input 句子都可以project（投影）到同一个space上面。句子在这个space上的位置只跟句子的semantic有关。</p><p>比如现在根据learn好的translation，那个translation有一个encoder，它会把input的句子变成vector，decoder根据这个vector解回一个句子，就是翻译的结果。那把不同语言都丢到这个encoder里面让它变成vector的话，那这些不同语言的不同句子在这个space上面有什么不一样的关系呢？</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200813103139.png" style="zoom: 40%;"></p><p>它发现有日文、英文、韩文这三个句子，这三个句子讲的是同一件事情，通过encoder embedding之后，它们在space上面是差不多的位置。machine做的是发现一个sequence language，每一种不同的语言都先要先转成它知道的sequence language，在用这个sequence language转为另外一种语言。所以对某一个翻译task ，你的input语言和output语言machine没有看过，它也可以透过这种自己学出来的sequence language来做translation。</p><p>——————</p><p>最后简单介绍下Transfer Learning的另外两种情况：</p><ul><li><p>Target data有label，source data没有label:  <strong>Self-taught learning</strong>。它的基本思想是：</p><ul><li>Learning to extract better representation from the source data(unsupervised approach)</li><li>Extracting better representation for target data</li></ul><p>Self-taught learning和semi-supervised learning有些不一样的地方，semi-supervised learning在learning的时候会有一些labelled data和unlabeled data，可以说source data是unlabeled data，target data是label data，所以Self-taught learning也是一种semi-supervised learning。但它和一般的semi-supervised learning有些不一样，一般的semi-supervised learning会假设unlabeled data至少和labelled data是有关系的，但在Self-taught learning中，source data和target data的关系是比较远的。</p></li><li><p>Target label没有label，source data也没有label: <strong>Self-taught clustering</strong>。</p></li></ul><blockquote><p>论文：<a href="http://ai.stanford.edu/~hllee/icml07-selftaughtlearning.pdf" target="_blank" rel="noopener">Self-taught learning</a>；<a href="https://www.cse.ust.hk/~qyang/Docs/2008/dwyakicml.pdf" target="_blank" rel="noopener">Self-taught clustering</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      文本主要介绍了Transfer Learning（迁移学习）的两种类型：labelled source data &amp; labeled target data；labelled source data &amp; unlabeled target data。
    
    </summary>
    
    
      <category term="Deep Learning" scheme="http://nekomoon404.github.io/categories/Deep-Learning/"/>
    
    
      <category term="Transfer Learning" scheme="http://nekomoon404.github.io/tags/Transfer-Learning/"/>
    
      <category term="Model Fine-tuning" scheme="http://nekomoon404.github.io/tags/Model-Fine-tuning/"/>
    
      <category term="Multitask Learning" scheme="http://nekomoon404.github.io/tags/Multitask-Learning/"/>
    
      <category term="Progressive Neural Network" scheme="http://nekomoon404.github.io/tags/Progressive-Neural-Network/"/>
    
      <category term="Domain-adversarial Training" scheme="http://nekomoon404.github.io/tags/Domain-adversarial-Training/"/>
    
  </entry>
  
  <entry>
    <title>DL笔记（15）Unsupervised Learning-Generative Model</title>
    <link href="http://nekomoon404.github.io/2020/07/29/ML%E7%AC%94%E8%AE%B0%EF%BC%8815%EF%BC%89Unsupervised-Learning-Generative-Model/"/>
    <id>http://nekomoon404.github.io/2020/07/29/ML%E7%AC%94%E8%AE%B0%EF%BC%8815%EF%BC%89Unsupervised-Learning-Generative-Model/</id>
    <published>2020-07-29T07:59:14.000Z</published>
    <updated>2020-08-12T07:59:14.000Z</updated>
    
    <content type="html"><![CDATA[<p>关于Generative Model推荐一篇很好的文章，来自OpenAI的<a href="https://openai.com/blog/generative-models/" target="_blank" rel="noopener">Generative Models</a>。文章的开头引用了<em>Richard Feynman</em>的话，<em>“What I cannot create, I do not understand”</em>，我无法创造的东西，我也无法真正理解，机器可以做猫狗分类，但却不一定知道“猫”和“狗”的概念，但如果机器能自己画出“猫”来，它或许才真正理解了“猫”这个概念，这也是Generative Model想要让machine做的事。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729160702.png" style="zoom:67%;"></p><p>下面将简要介绍：PixelRNN、VAE和GAN这三种Generative model的方法。</p><h3 id="1-PixelRNN"><a href="#1-PixelRNN" class="headerlink" title="1. PixelRNN"></a>1. PixelRNN</h3><p>RNN可以处理长度可变的input，它的基本思想是可以根据过去发生的状态去推测下一个状态。PixelRNN的基本思想是每次只画一个pixel来生成一个image，这个pixel是由过去所有已产生的pixel共同决定的。例如一个$3\times 3$的Image，第一次给一个橙色的pixel，输入到NN中，output得到一个蓝色的pixel；然后再将上一步得到的橙色和蓝色的pixel一起输入到NN中得到一个浅蓝色的pixel；再下一步将这三个pixel输入到NN中得到一个灰色的pixel，以此类推就可以得到一个$3\times 3$的image。这种方法的精髓在于根据过去预测未来，画出来的图一般都是比较清晰的</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729161342.png" style="zoom:67%;"></p><p>（Reference[1]: <a href="https://arxiv.org/abs/1601.06759" target="_blank" rel="noopener"><em>Oord A, Kalchbrenner N, Kavukcuoglu K. Pixel recurrent neural networks[J]. arXiv preprint arXiv:1601.06759, 2016.</em></a>）</p><p>这个方法也适用于语音生成，可以用前面一段的语音去预测接下来生成的语音信号。也可以用在影像上，用前面一段video来预测后面的video。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729161919.png" style="zoom:67%;"></p><p>（Reference[2]: <a href="https://arxiv.org/abs/1609.03499" target="_blank" rel="noopener"><em>Oord A, Dieleman S, Zen H, et al. Wavenet: A generative model for raw audio[J]. arXiv preprint arXiv:1609.03499, 2016.</em></a> </p><p>Reference[3]:  <a href="https://arxiv.org/abs/1610.00527" target="_blank" rel="noopener"><em>Kalchbrenner N, Oord A, Simonyan K, et al. Video pixel networks[C]//International Conference on Machine Learning. 2017: 1771-1779.</em></a>）</p><p><strong>pokemon creation</strong></p><p>下面这个小例子是给machine792个pekemon的image，想让machine学会去生成pekeon的Image。</p><p><img src="/2020/07/29/ML%E7%AC%94%E8%AE%B0%EF%BC%8815%EF%BC%89Unsupervised-Learning-Generative-Model/QQ图片20200729163517.png" style="zoom:67%;"></p><p>在使用Generative model去生成宝可梦之前，有几个tips需要注意：</p><ul><li><p>为了减少运算量，将40×40的图像截取成20×20</p></li><li><p>如果将每个pixel都以[R, G, B]的vector表示的话，生成的图像都是灰蒙蒙的，原因如下：</p><ul><li><p>亮度比较高的图像，一般都是RGB值差距特别大而形成的，如果各个维度的值大小比较接近，则生成的图像偏向于灰色；</p></li><li><p>如果用sigmoid function，最终生成的RGB往往都是在0.5左右（归一化之后），导致色彩度不鲜艳；</p></li><li><p>解决方案：将所有色彩集合成一个1-of-N encoding，由于色彩种类比较多，因此这里先对相近的颜色做clustering聚类表示为一种颜色，最终获得了167种色彩组成的向量。我们用这样的向量去表示每个pixel，可以让生成的色彩比较鲜艳。</p></li></ul></li></ul><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729163521.png" style="zoom:67%;"></p><p>相关数据连接如下：</p><ul><li>原始图像(40*40)数据的<a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2016/Pokemon_creation/image.rar" target="_blank" rel="noopener">链接</a></li><li>裁剪后的图像(20*20)数据<a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2016/Pokemon_creation/pixel_color.txt" target="_blank" rel="noopener">链接</a></li><li>数值与色彩(RGB)的映射关系<a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2016/Pokemon_creation/colormap.txt" target="_blank" rel="noopener">链接</a></li></ul><p>使用PixelRNN训练好模型之后，给它看没有被放在训练集中的3张图像的一部分，分别遮住原图的50%和75%，得到的原图如下：</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729163524.png" style="zoom:67%;"></p><p>训练好的pixel RNN预测到的图片如下：</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729164544.png" style="zoom:60%;"></p><p>做这种Generation的task有一个难点是，设计上的好坏较难去evaluate。接下来我们让训练好的model凭空去画，但如果什么都不给machine让它从头开始画的话，它得到的每一个image可能都是一样的，因此我们要故意加一些random，即machine在画下一个pixel的时候不一定是选几率最高的颜色，也有几率选几率比较低的颜色，这样它每次画出来的图才会有点不一样。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729163528.png" style="zoom:67%;"></p><h3 id="2-VAE"><a href="#2-VAE" class="headerlink" title="2. VAE"></a>2. VAE</h3><p>上一篇笔记中介绍过Auto-encoder，如果我们拿出其中的Decoder，给它随机的code，就可以生成对应的图像。但普通的Decoder生成效果并不好，VAE（Variational Auto-encoder，可变自动编码器）可以得到更好的效果。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729165853.png" style="zoom:67%;"></p><p>在VAE中，code不再直接等于Encoder的输出，这里假设目标降维空间为3维，那我们使Encoder分别输出$m_1,m_2,m_3$和$\sigma_1,\sigma_2,\sigma_3$，此外我们从正态分布中随机取出三个点$e_1,e_2,e_3$，将下式作为最终的编码结果：</p><script type="math/tex; mode=display">c_i = \exp(\sigma_i)\cdot e_i+m_i</script><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729165849.png" style="zoom:67%;"></p><p>再将$c_i$输入到Decoder里面得到output，我们希望MInimize reconstruction error。但此时，我们的训练目标不仅要最小化input和output之间的差距，还要同时最小化下式（比较“神妙”）：</p><script type="math/tex; mode=display">\sum\limits_{i=1}^3 (1+\sigma_i-(m_i)^2-e^{\sigma_i})</script><h4 id="2-1-Pokemon-Creation"><a href="#2-1-Pokemon-Creation" class="headerlink" title="2.1. Pokemon Creation"></a>2.1. Pokemon Creation</h4><p>与PixelRNN不同的是，VAE画出的图一般都是不太清晰的，但在某种程度上我们可以控制生成的image。假设我们现在把VAE用在Pokemon creation上面，在Trainig的时候我们input一个pokemon，然后reconstruct一个同样的pokemon，learn出来的code设为10维。Learn好这个VAE之后，我们把Decoder的部分拿出来。我们在给Decoder输入10维的vector时可以固定其中的8维，只选2维出来，我们可以在2维平面上sample一系列的点，加上我们固定的8维后Input到Decoder中看输出的image是什么样的。这样我们就可以解读code的每一个dimension是代表什么含义，然后去控制VAE去生成一些image。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729171354.png" style="zoom:67%;"></p><p>下面是固定code中的8维，让剩下的2维变化得到的image，发现image的变化确实是有些规律的。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729171550.png" style="zoom:67%;"></p><h4 id="2-2-Writing-Poerty"><a href="#2-2-Writing-Poerty" class="headerlink" title="2.2. Writing Poerty"></a>2.2. Writing Poerty</h4><p>VAE还可以用来写诗，将input和output都换成是sentence，我们只需要得到某两句话对应的code，然后在降维后的空间中得到这两个code所在点的连线，从中间等间隔地取一些点，把这些点输入给Decoder，得到还原后的句子，就可以得到类似下图中的效果。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729172145.png" style="zoom: 80%;"></p><h4 id="2-3-Why-VAE"><a href="#2-3-Why-VAE" class="headerlink" title="2.3. Why VAE?"></a>2.3. Why VAE?</h4><p>VAE和传统的Auto-encoder相比，有什么优势呢？事实上，VAE就是加了噪声noise的Autoencoder，它的抗干扰能力更强，过渡生成能力也更强。</p><p>对原先的Autoencoder来说，假设我们得到了满月和弦月的code，从两者连线中随机获取一个点并映射回原来的空间，得到的图像很可能是完全不一样的东西，因为code和output得到的image是一一对应的。</p><p>而对VAE来说，它要保证在降维后的code空间中，加了noise的一段范围内的所有点都能够映射到目标图像，如下图所示，当某个点既被要求映射到满月、又被要求映射到弦月，则它最终映射出来的结果就很有可能是两者之间的过渡图像。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729172808.png" style="zoom:67%;"></p><p>再回过来头看VAE的结构，其中：</p><ul><li><p>$m_i$其实就代表原来的code</p></li><li><p>$c_i$则代表加了noise以后的code</p></li><li><p>$\sigma_i$代表了noise的variance，描述了noise的大小，这是由NN学习到的参数</p><p>（注：使用$\exp(\sigma_i)$的目的是保证variance是正的）</p></li><li><p>$e_i$是正态分布中随机采样的点</p></li></ul><p>注意到，损失函数仅仅让input和output差距最小是不够的，因为variance是由机器自己决定的，如果不加以约束，它自然会去让variance=0，这就跟普通的Autoencoder没有区别了。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729165857.png" style="zoom:67%;"></p><p>额外加的限制函数解释如下：</p><p>下图中，蓝线表示$e^{\sigma_i}$，红线表示$1+\sigma_i$，两者相减得到绿线。绿线的最低点$\sigma_i=0$，则variance $e^{\sigma_i}=1$，此时loss最低，而$(m_i)^2$项则是对code的L2 regularization，让它比较sparse，不容易过拟合。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729165901.png" alt></p><p>上面是比较直观的理由，以下是paper上比较常见的解释。我们回归到我们要做的事情是什么，假设要machine generate pokemon的image，那每一张pokemon的图都可以想成是高维空间中的一个点。假设它是20*20的image，在高维空间中也就是400维的点，在图上我们用一维描述它，但其实是一个高维的空间。那现在要做的就是estimate p(x)的分布，它表示一张图片像宝可梦的几率，然后就可以根据p(x)高的地方去sample出一张像宝可梦的图。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729204112.png" style="zoom:60%;"></p><p>Estimate the probability distributon可以用Gaussion mixture model。Guassion mixture model：现在有一个distribution(黑色的线)，这个黑色的distribution其实是很多的Gaussion(青蓝色)用不同的weight叠合起来的结果。如果你的gaussion数目够多，你就可以产生很复杂的distribution，公式为 $p(x)=\sum_{m}p(m)p(x|m)$ 。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729172813.png" style="zoom:67%;"></p><p>这样每一个$x$并不属于某一个class或者cluster，而是有一个vector来描述它不同面向的disstribution，描述它不同面向的特性，<strong>VAE其实就是Gaussian Mixture Model的Distributed representation的版本</strong>。</p><p>假设我们要sample一个vector $z$，$z$是从normal distribution中sample出来的，$z$的每一个dimension都代表了某种attribute（特质，特性）。由$z$可以决定Gaussian的mean $\mu$和variance $\sigma$，由于$z$是continous的，所有它有无穷的可能，那mean和variance也有无穷多的可能。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729172816.png" style="zoom:67%;"></p><p>$P(x)$的曲线是这样产生的：$z$上的每一个点都有可能被sample到，当sample出一个点后它就会对应到一个Gaussian，把它们mixture起来就得到了$P(x)$，即$P(x)=\int \limits_{z}P(z)P(x|z)dz $（注意因为$z$是continous的，所以这里要用积分，而不是sum）。</p><h4 id="2-4-Maximizing-Likelihood"><a href="#2-4-Maximizing-Likelihood" class="headerlink" title="2.4. Maximizing Likelihood"></a>2.4. Maximizing Likelihood</h4><p>那给出一个$z$怎么找出mean和variance呢，假设mean和variance都来自一个function，这个function就可以是一个NN。当然$z$的分布不一定是Gaussian，可以自己设定。那训练这个NN的目标就是要Maximiza the likelihood of the observed $x$，即使下式最大：</p><script type="math/tex; mode=display">L=\sum \limits_{x}\log P(x)</script><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729172821.png" style="zoom:67%;"></p><p>我们要做的就是调NN里的参数weight和bias，使得likelihood最大。然后我们需要引入另一个distribution $q(z|x)$，它是given $x$来决定在$z$的space上的mean和variance，还需要有另外一个NN’，input $x$之后会output对应的$z$的mean $\mu’(x)$和variance $\sigma’(x)$，即决定$z$要从什么样的mean和variance中被sample出来。</p><p>上图中上面的NN就相当于是VAE中的Decoder，下面的NN就相当于是VAE中的ENcoder。</p><p>下面是对$L=\sum \limits_{x}\log P(x)$的表达式的具体的推导：</p><p>推导$\log P(x)=L_b+KL(q(z|x)||P(z|x))$：</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729214950.png" style="zoom:67%;"></p><p>我们本来要做的是找使得$L$最大的$P(x|z)$，现在转换为求使$L_b$最大的$P(x|z)$和$q(z|x)$。 </p><p>如果我们只找$p(x∣z)$ 这一项的话，然后去maximizing $L_b$ ，当增加$L_b$的时候，有可能会增加likehood，但不知道likehood跟lower bound之间到底有还差多少距离。你希望你做到的是：当lower bound上升的时候，likehood也跟着上升。但是有可能会遇到糟糕的事情是：lower bound上升的时候，likehood反而下降，因为不知道它们之间的差距是多少。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729221051.png" style="zoom:95%;"></p><p>引入$q(z|x)$这一项就是为了解决这一问题。如上图中蓝色的是likehood， $\log P(x)=L_b+KL$，如果你今天调 $q(z|x)$来maximizing $L_b$，会发现$q(z|x)$跟$\log P(x)$是没有关系的，即ikelihood不变，那maximizing $L_b$的同时也在minimize KL divergence，即让lower bound（$L_b$）跟likehood越来越接近。如果固定住 $p(x|z)$这一项，去调 $q(z|x)$这一项的话，会让$L_b$ 一直上升，直到KL divergence会完全不见。由于likehood一定要比lower bound大，这时你再调$p(x|z)$和$q(z|x)$来maximizing $L_b$的话，就可以保证likehood会一定增大。</p><p>这样做也会得到一个副产物，当maximize $L_b$这一项的时候，会让KL divergence越来越小，意味着会让 $q(z|x)$ 跟 $p(z|x)$越来越接近。所以接下来做的事情就是找$p(x|z)$跟$q(z|x)$，可以让$L_b$越大越好，就等同于让likehood越来越大，最后顺便会得到$q(z|x)$可以去approximation $p(z|x)$。</p><p>而$q$是个neural network，要去minimize $KL(q(z|x)||P(z))$就是去调NN‘让它产生的distribution和normal distribution越接近越好，而loss function就是之前讲过的那个式子$\sum \limits^{3} \limits_{i=1}(\exp(\sigma_i)-(1+\sigma_i)+(m_i)^2)$（这部分的推导可以参考VAE的原始论文）。</p><p>另外一项是转化为$\log P(x|z))$的期望值：</p><script type="math/tex; mode=display">P(x)=\int \limits_{z}P(z)P(x|z)dz=E_{q(z|x)}[\log P(x|z)]</script><p>可以理解是我们从$q(z|x)$中去sample data，要让$\log P(x|z)$越大越好，这其实就是Auto-encoder在做的事情。你可以把$x$输入到NN’中得到mean $\mu’(x)$和variance $\sigma’(x)$，根据这个mean和variance可以sample出一个$z$；接下来把z输入到NN，得到mean $\mu(x)$和variance $\sigma(x)$，我们的目标是让这个mean和variance代表的distribution是$x$的几率越大越好，在实际使用中往往不考虑variance，那我们就是让最后输出的mean和$x$越接近越好，这不就是Auto-encoder在做的事情。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729224154.png" style="zoom:90%;"></p><p><strong>Conditional VAE</strong></p><p>还有一种方法叫Conditional VAE，举个例子，如果你让VAE可以产生手写的数字，给它一个digit，然后它把这个digit的特性抽取出来(笔画的粗细等等)，然后丢进encoder的时候一方面给它有关这个数字特性的distribution，另外一方面告诉decoder它是什么数字。那你就可以根据这一个digit，generate跟它style相近的digit。Conditional VAE可以根据某一个digit画出跟它style相近的数字。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729230209.png" style="zoom:80%;"></p><p><strong>Problems of VAE</strong></p><p>VAE有一个缺点，它只是在努力做到让生成的图像与数据集里的图像尽可能相似，却从来没有想过怎么样真的产生一张新的图像，因此由VAE生成的图像大多是数据集中图像的线性变化，而很难自主生成全新的图像。假设Decoder output跟真正的image之间有一个pixel的差距，那有时不同的pixel落在不同的位置会得到非常不一样的结果，如下图中的两个数字“7”，人很容易发现其区别：左边的像是真的数字，而右边明显是fake。但对VAE来说，它们只是有一个pixel的差异，两张image都是一样好或者不好的。VAE做到的只是模仿，而不是创造，GAN的诞生，就是为了创造。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729224258.png" style="zoom:67%;"></p><h3 id="3-GAN"><a href="#3-GAN" class="headerlink" title="3. GAN"></a>3. GAN</h3><p>Generative Adversarial Network（GAN，对抗生成网络），基本思想类似天敌之间相互竞争，相互进步。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200812231603.png" style="zoom:67%;"></p><p>GAN由生成器(Generator)和判别器(Discriminator)组成：</p><ul><li>对判别器的训练：把生成器产生的图像标记为0，真实图像标记为1，丢给判别器训练分类，希望它能分辨real image和fake image；</li><li>对生成器的训练：调整生成器的参数，使产生的图像（fake image）能够“骗过”判别器，即判别器输出越接近1越好；</li><li>每次训练GAN时生成器和判别器要分开训练：先Fix住生成器，训练判别器的参数；再Fix 判别器，训练生成器的参数，如此反复。</li></ul><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200812231826.png" style="zoom:80%;"></p><p>（PS：李老师后面会有专门介绍GAN的课程，之后再做详细记录吧。）</p>]]></content>
    
    <summary type="html">
    
      文本介绍了三种无监督学习的Generative Model：Pixel RNN，Variational Auto-encoder(VAE)和Generative Adversarial Network(GAN)。
    
    </summary>
    
    
      <category term="Deep Learning" scheme="http://nekomoon404.github.io/categories/Deep-Learning/"/>
    
    
      <category term="Pixel RNN" scheme="http://nekomoon404.github.io/tags/Pixel-RNN/"/>
    
      <category term="VAE" scheme="http://nekomoon404.github.io/tags/VAE/"/>
    
      <category term="GAN" scheme="http://nekomoon404.github.io/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>DL笔记（14）Unsupervised Learning-Deep Auto-encoder</title>
    <link href="http://nekomoon404.github.io/2020/07/29/ML%E7%AC%94%E8%AE%B0%EF%BC%8814%EF%BC%89Unsupervised-Learning-Deep-Auto-encoder/"/>
    <id>http://nekomoon404.github.io/2020/07/29/ML%E7%AC%94%E8%AE%B0%EF%BC%8814%EF%BC%89Unsupervised-Learning-Deep-Auto-encoder/</id>
    <published>2020-07-29T02:31:01.000Z</published>
    <updated>2020-07-29T04:31:01.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-Auto-encoder"><a href="#1-Auto-encoder" class="headerlink" title="1. Auto-encoder"></a>1. Auto-encoder</h3><p><strong>Auto-encoder本质上就是一个自我压缩和解压的过程</strong>，比如在做图像处理时，我们想要获取压缩后的code，它代表了对原始数据的某种紧凑精简的有效表达，即降维结果，这个过程中我们需要：</p><ul><li>Encoder(编码器)，它可以把原先的图像压缩成更低维度的向量；</li><li>Decoder(解码器)，它可以把压缩后的向量还原成图像；</li></ul><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729103552.png" alt></p><p>注意到，Encoder和Decoder都是Unsupervised Learning，由于code是未知的，对Encoder来说，我们手中的数据只能提供图像作为NN的input，却不能提供code作为output；对Decoder来说，我们只能提供图像作为NN的output，却不能提供code作为input。</p><p>因此Encoder和Decoder单独拿出一个都无法进行训练，我们需要把它们连接起来，这样整个神经网络的输入和输出都是我们已有的图像数据，就可以同时对Encoder和Decoder进行训练，而降维后的编码结果就可以从最中间的那层hidden layer中获取。</p><h4 id="1-1-Compare-with-PCA"><a href="#1-1-Compare-with-PCA" class="headerlink" title="1.1. Compare with PCA"></a>1.1. Compare with PCA</h4><p>实际上PCA用到的思想与之非常类似，<strong>PCA的过程本质上就是按组件拆分，再按组件重构的过程</strong>。在PCA中，假设input一张image $x$（本应该是把$x-\bar{x}$当做input，这边我们把$\bar{x}$省略掉，通常在做NN的时候，你拿到的data其实会normalization的，即data的mean是0）。我们先把$x$乘上weight $W$，通过NN的一个layer得到得到component的weight $c$，然后再乘上$W^T$得到重组后的$\hat x$，同样我们期望重构后的$\hat x$与原始的$x$越接近越好，即Minimize $(x-\hat{x})^2$。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729103708.png" alt></p><p>如果把这个过程看作是神经网络，那么原始的$x$就是input layer，重构$\hat x$就是output layer，中间组件分解权重$c$就是hidden layer，在PCA中它是linear的，我们通常又叫它瓶颈层(<strong>Bottleneck layer</strong>)</p><p>由于经过组件分解降维后的$c$，维数要远比输入输出层来得低，因此hidden layer实际上非常窄，因而有Bottleneck layer的叫法。对比于Auto-encoder，从input layer到hidden layer的按组件分解实际上就是编码(encode)过程，从hidden layer到output layer按组件重构实际上就是解码(decode)的过程。</p><p>这时候你可能会想，可不可以用更多层hidden layer呢？答案是肯定的</p><h4 id="1-2-Deep-Auto-encoder"><a href="#1-2-Deep-Auto-encoder" class="headerlink" title="1.2. Deep Auto-encoder"></a>1.2. Deep Auto-encoder</h4><p><strong>Multi Layer</strong></p><p>对deep的自编码器来说，实际上就是通过多级编码降维，再经过多级解码还原的过程，此时：</p><ul><li>从input layer到bottleneck layer的部分都属于<strong>Encoder​</strong>；</li><li>从bottleneck layer到output layer的部分都属于<strong>Decoder​</strong>；</li><li>bottleneck layer的output就是自编码结果<strong>code​</strong>。</li></ul><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729103712.png" alt></p><p>（paper: <a href="https://www.cs.toronto.edu/~hinton/science.pdf" target="_blank" rel="noopener"><em>Hinton G E, Salakhutdinov R R. Reducing the dimensionality of data with neural networks[J]. science, 2006, 313(5786): 504-507.</em></a>）</p><p>Training这个Deep Auto-encoder的方法就是用之前讲过的Backpropagation，在多层layer的中间会有一层特别“窄”的layer，即为Bottleneck layer，它的output就代表了一组Code。从整个NN的input到Bottleneck layer就是Encoder，从Bottleneck layer的output到整个NN的output就是Decoder。</p><p>注意到，如果按照PCA的思路，则<strong>Encoder的参数$W_i$需要和Decoder的参数$W_i^T$保持一致</strong>的对应关系，这可以通过给两者相同的初始值并设置同样的更新过程得到，这样做的好处是，可以节省一半的参数，降低overfitting的概率。但这件事情<strong>并不是必要的</strong>，实际操作的时候，你完全可以对神经网络进行直接训练而不用保持编码器和解码器的参数一致</p><p><strong>Visualize</strong></p><p>下图给出了Hinton分别采用PCA和Deep Auto-encoder对手写数字进行编码解码后的结果，从784维降到30维，然后再从30维reconstruct到784维，可以看出，Deep的自编码器还原效果比PCA要更好。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729103715.png" alt></p><p>如果将其降到二维平面做可视化，不同颜色代表不同的数字，可以看到：</p><ul><li>通过PCA降维得到的编码结果中，不同颜色代表的数字被混杂在一起；</li><li>通过Deep Auto-encoder降维得到的编码结果中，不同颜色代表的数字被分散成一群一群的。</li></ul><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729103718.png" alt></p><h3 id="2-More-Application"><a href="#2-More-Application" class="headerlink" title="2. More Application"></a>2. More Application</h3><h4 id="2-1-Text-Retrieval"><a href="#2-1-Text-Retrieval" class="headerlink" title="2.1.  Text Retrieval"></a>2.1.  Text Retrieval</h4><p>Auto-encoder也可以被用在文字处理上，用Auto-encoder把一篇文章压成code。比如我们要做文字检索，很简单的一个做法是Vector Space Model，把每一篇文章都表示成空间中的一个vector。</p><p>假设查询者输入了某个词汇，那我们就把该查询词汇也变成空间中的一个点，并计算query和每一篇document之间的内积 inner product 或余弦相似度 cos-similarity（余弦相似度有均一化的效果，可能会得到更好的结果）。下图中跟query向量最接近的几个向量的cosine-similarity是最大的，于是可以从这几篇文章中去检索。实际上这个模型的好坏，就取决于从document转化而来的vector的好坏，它是否能够充分表达文章信息。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729103721.png" alt></p><p><strong>Bag-of-word</strong></p><p>最简单的vector表示方法是Bag-of-word，维数等于所有词汇的总数，某一维等于1则表示该词汇在这篇文章中出现，此外还可以根据词汇的重要性在对应的维上乘weight。但这个模型是非常脆弱的，对它来说每个词汇都是相互独立的，无法体现出词汇之间的语义(semantic)。</p><p><strong>Auto-encoder</strong></p><p>虽然Bag-of-word不能直接用于表示文章，但我们可以把它作为Auto-encoder的input，通过降维来抽取有效信息，以获取所需的vector。同样为了可视化，这里将Bag-of-word降维到二维平面上，下图中每个点都代表一篇文章，不同颜色则代表不同的文章类型，发现同一类文章都有较好地聚集在一起。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729103725.png" alt></p><p>如果用户做查询，就把查询的语句（query）用相同的方式映射到该二维平面上，并找出属于同一类别的所有文章即可。在矩阵分解(Matrix Factorization)中，我们介绍了LSA算法，它可以用来寻找每个词汇和每篇文章背后的隐藏关系(vector)，如果在这里我们采用LSA，并使用二维latent vector来表示每篇文章，得到的可视化结果如上图右下角所示，可见效果并没有Auto-encoder好。</p><h4 id="2-2-Similar-Image-Search"><a href="#2-2-Similar-Image-Search" class="headerlink" title="2.2. Similar Image Search"></a>2.2. Similar Image Search</h4><p>Auto-encoder同样可以被用在图像检索（Image Search）上。以图找图最简单的做法就是直接对输入的图片与数据库中的图片计算pixel的相似度，并挑出最像的图片，但这种方法的效果是不好的，因为单纯的pixel所能够表达的信息太少了。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729150042.png" style="zoom:60%;"></p><p>我们需要使用Deep Auto-encoder对图像进行降维和特征提取，并在编码得到的code所在空间做检索。下图展示了Encoder的过程，并给出了原图与Decoder后的图像对比。因为Auto-encoder是unsupervised的方法，所有通常我们不必担心数据量的问题。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729103728.png" alt></p><p>这么做的好处如下：</p><ul><li>Auto-encoder可以通过降维提取出一张图像中最有用的特征信息，包括pixel与pixel之间的关系；</li><li>降维之后数据的size变小了，这意味着模型所需的参数也变少了，同样的数据量对参数更少的模型来说，可以训练出更精确的结果，一定程度上避免了过拟合的发生；</li><li>Auto-encoder是一个无监督学习的方法，数据不需要人工打上标签，这意味着我们只需简单处理就可以获得大量的可用数据；</li></ul><p>下图给出了分别以原图的pixel计算相似度和以auto-encoder后的code计算相似度的两种方法在图像检索上的结果，可以看到，通过pixel检索到的图像会出现很多奇怪的物品，而通过code检索到的图像则都是人脸</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729103731.png" alt></p><p>可能有些人脸在原图的pixel上看起来并不像，但把它们投影到256维的空间中却是相像的，可能在投影空间中某一维就代表了人脸的特征，因此能够被检索出来。</p><h4 id="2-3-Pre-training-DNN"><a href="#2-3-Pre-training-DNN" class="headerlink" title="2.3. Pre-training DNN"></a>2.3. Pre-training DNN</h4><p>在训练神经网络的时候，我们一般都会对如何初始化参数比较困扰，预训练(pre-training)是一种寻找比较好的参数初始化值的方法，而我们<strong>可以用Auto-encoder来做pre-training</strong>。</p><p>以MNIST数据集为例，我们对每层hidden layer都做一次auto-encoder，<strong>使每一层都能够提取到上一层最佳的特征向量</strong></p><p>为了方便表述，这里用$x-z-\widetilde{x}$来表示一个自编码器，其中$x$表述输入输出层的维数，$z$表示隐藏层的维数。</p><ul><li><p>首先使input通过一个$784-1000-784$的自编码器，当该自编码器训练稳定后，就把参数$W^1$固定住，然后将数据集中所有784维的图像都转化为1000维的vector</p><p>注意：这里encoder做的不是降维而是升维，当编码后的维数比输入维数要高时，需要注意可能会出现编码前后原封不动的情况，$W^1$的一部分就是个identity matrix。为此需要额外加一个很强的正则项regularization，比如L1 regularization，强迫使code的分布是分散的。</p></li></ul><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729103735.png" alt></p><ul><li>接下来把训练好的Auto-encoder中的$W^1$保留下来，再让这些1000维的vector通过一个$1000-1000-1000$的编码器，其$a^1$与$\widetilde{a}^1$越接近越好，当其训练稳定后，再把参数$W^2$保留下来fix住，对数据集再做一次转换。</li></ul><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729103738.png" alt></p><ul><li>接下来再用转换后的数据集去训练第三个$1000-500-1000$的自编码器，训练稳定后固定$W^3$，数据集再次更新转化为500维。</li></ul><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729103741.png" alt></p><ul><li><p>此时三个隐藏层的参数$W^1$、$W^2$、$W^3$就是训练整个神经网络时的参数初始值；</p></li><li><p>然后随机初始化最后一个隐藏层到输出层之间的参数$W^4$；</p></li><li><p>再用反向传播去调整一遍参数，因为$W^1$、$W^2$、$W^3$都已经是很好的参数值了，这里只是做微调，这个步骤也因此得名为<strong>Fine-tune</strong>。</p></li></ul><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729103744.png" alt></p><p>由于现在训练机器的条件比以前更好，因此pre-training并不是必要的，但它也有自己的优势。如果你只有大量的unlabeled data和少量的labeled data，那你可以先用这些unlabeled data把$W^1$、$W^2$、$W^3$先初始化好，最后再用labeled data去微调$W^1$~$W^4$即可。因此pre-training在有大量unlabeled data的场景下(如半监督学习)是比较有用的。</p><h4 id="2-4-CNN"><a href="#2-4-CNN" class="headerlink" title="2.4. CNN"></a>2.4. CNN</h4><p><strong>CNN as Encoder</strong></p><p>处理图像通常都会用卷积神经网络CNN，它的基本思想是交替使用卷积层和池化层，让图像越来越小，最终展平，这个过程跟Encoder编码的过程其实是类似的</p><p>理论上要实现自编码器，Decoder只需要做跟Encoder相反的事即可，那对CNN来说，解码的过程也就变成了交替使用去卷积层Deconvolution和去池化层Unpooling即可。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729103747.png" alt></p><p>那什么是去卷积层(Deconvolution)和去池化层(Unpooling)呢？</p><p><strong>Unpooling</strong></p><p>做pooling的时候，假如得到一个4×4的matrix，就把每4个pixel分为一组，从每组中挑一个最大的留下，此时图像就变成了原来的四分之一大小。如果还要做Unpooling，就需要提前记录pooling所挑选的pixel在原图中的位置，下图中用灰色方框标注。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729103751.png" alt></p><p>然后做Unpooling，就要把当前的matrix放大到原来的四倍，也就是把2×2 matrix里的pixel按照原先记录的位置插入放大后的4×4 matrix中，其余项补0即可。当然这不是唯一的做法，在<code>Keras</code>中，pooling并没有记录原先的位置，做Unpooling的时候就是直接把pixel的值复制四份填充到扩大后的matrix里即可。</p><p><strong>Deconvolution</strong></p><p>实际上，Deconvolution就是convolution。这里以一维的卷积为例，假设输入是5维，过滤器(filter)的大小是3。</p><p>卷积的过程就是每三个相邻的点通过过滤器生成一个新的点，如下图左侧所示。在你的想象中，去卷积的过程应该是每个点都生成三个点，不同的点对生成同一个点的贡献值相加；但实际上，这个过程就相当于在周围补0之后再次做卷积，如下图右侧所示，两个过程是等价的。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729103754.png" alt></p><p>卷积和去卷积的过程中，不同点在于，去卷积需要补零且过滤器的weight与卷积是相反的：</p><ul><li>在卷积过程中，依次是橙线、蓝线、绿线；</li><li>在去卷积过程中，依次是绿线、蓝线、橙线。</li></ul><p>因此在实践中，做去卷积的时候直接对模型加卷积层即可。</p><h4 id="2-5-Generate"><a href="#2-5-Generate" class="headerlink" title="2.5. Generate"></a>2.5. Generate</h4><p>在用自编码器的时候，通常是获取Encoder之后的code作为降维结果，但实际上Decoder也是有作用的，我们可以拿它来生成新的image。以MNIST为例，训练好编码器之后，取出其中的Decoder，输入一个随机的code，就可以生成一张图像</p><p>假设将28×28维的图像通过一层2维的hidden layer投影到二维平面上，得到的结果如下所示，不同颜色的点代表不同的数字，然后在红色方框中，等间隔的挑选二维向量丢进Decoder中，就会生成许多数字的图像。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729103800.png" alt></p><p>这往往需要我们先观察一下二维的code的分布，确定哪些region是有值的，然后sample出来。此外，我们还可以对code加L2 regularization，以限制code分布的范围集中在0附近，此时就可以直接以0为中心去随机采取样本点，再通过Decoder生成图像。观察生成的数字图像，可以发现横轴的维度可以理解是表示是否含有圆圈，纵轴的维度表示是否倾斜。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729103803.png" alt></p><h3 id="3-Other-Auto-encoder"><a href="#3-Other-Auto-encoder" class="headerlink" title="3. Other Auto-encoder"></a>3. Other Auto-encoder</h3><h4 id="3-1-De-noising-Auto-encoder"><a href="#3-1-De-noising-Auto-encoder" class="headerlink" title="3.1. De-noising Auto-encoder"></a>3.1. De-noising Auto-encoder</h4><p>有一个方法可以让Auto-encoder做的更好，叫作De-noising Auto-encoder（去噪自编码器）。它的基本思想是，把输入的$x$加上一些噪声(noise)变成$x’$，再对$x’$依次做编码(encode)和解码(decode)，得到还原后的$y$。</p><p>值得注意的是，一般的自编码器都是让输入输出尽可能接近，但在去噪自编码器中，我们的目标是<strong>让解码后的$y$与加噪声之前的$x$越接近越好</strong>。这种方法可以<strong>增加系统的鲁棒性</strong>，因为此时的编码器Encoder不仅仅是在学习如何做编码，它还学习到了如何过滤掉噪声这件事情。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729103757.png" alt></p><p>（paper: <a href="https://www.cs.toronto.edu/~larocheh/publications/icml-2008-denoising-autoencoders.pdf" target="_blank" rel="noopener"><em>Vincent, Pascal, et al. “Extracting and composing robust features with denoising autoencoders.” ICML, 2008.</em></a>）</p><h4 id="3-2-Contractive-Auto-encoder"><a href="#3-2-Contractive-Auto-encoder" class="headerlink" title="3.2. Contractive Auto-encoder"></a>3.2. Contractive Auto-encoder</h4><p>Contractive Auto-encoder（收缩自动编码器）的基本思想是，在做encode编码的时候，要加上一个约束，它可以使得：input的变化对编码后得到的code的影响最小化。</p><p>这个描述跟去噪自编码器很像，只不过去噪自编码器的重点在于加了噪声之后依旧可以还原回原先的输入，而收缩自动编码器的重点在于加了噪声之后能够保持编码结果不变。</p><p>（paper: <a href="https://icml.cc/Conferences/2011/papers/455_icmlpaper.pdf" target="_blank" rel="noopener"><em>Rifai, Salah, et al. “Contractive auto-encoders: Explicit invariance during feature extraction.“ Proceedings of the 28th International Conference on Machine Learning (ICML-11). 2011.</em></a>）</p><p>其实还有很多nonlinear的dimension reduction的方法，比如Restricted Boltzmann Machine（受限玻尔兹曼机），它并不是neural network的方法，只是看起来有点像；Deep Belief Network（深度信念网络），它也和Deep neural network不是一回事。</p><h4 id="3-3-Seq2Seq-Auto-encoder"><a href="#3-3-Seq2Seq-Auto-encoder" class="headerlink" title="3.3. Seq2Seq Auto-encoder"></a>3.3. Seq2Seq Auto-encoder</h4><p>在之前介绍的自编码器中，输入都是一个固定长度的vector，但类似文章、语音等信息实际上不应该单纯被表示为vector，那会丢失很多前后联系的信息。Seq2Seq就是为了解决这个问题提出的，具体内容在RNN那次的笔记中有介绍。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729154125.png" style="zoom: 50%;"></p>]]></content>
    
    <summary type="html">
    
      文本介绍了Auto-encoder（自编码器）的基本思想，与PCA的联系，从单层编码到多层的变化；以及Auto-encoder的一些应用，包括在文字搜索和图像搜索上的应用，预训练DNN，利用CNN实现自编码器，加噪声的自编码器等。
    
    </summary>
    
    
      <category term="Deep Learning" scheme="http://nekomoon404.github.io/categories/Deep-Learning/"/>
    
    
      <category term="Auto-encoder" scheme="http://nekomoon404.github.io/tags/Auto-encoder/"/>
    
      <category term="Fine-tune" scheme="http://nekomoon404.github.io/tags/Fine-tune/"/>
    
  </entry>
  
  <entry>
    <title>DL笔记（13）Unsupervised Learning-Neighbor Embedding</title>
    <link href="http://nekomoon404.github.io/2020/07/29/ML%E7%AC%94%E8%AE%B0%EF%BC%8813%EF%BC%89Unsupervised-Learning-Neighbor-Embedding/"/>
    <id>http://nekomoon404.github.io/2020/07/29/ML%E7%AC%94%E8%AE%B0%EF%BC%8813%EF%BC%89Unsupervised-Learning-Neighbor-Embedding/</id>
    <published>2020-07-29T00:35:26.000Z</published>
    <updated>2020-07-29T02:35:26.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-Manifold-Learning"><a href="#1-Manifold-Learning" class="headerlink" title="1.Manifold Learning"></a>1.Manifold Learning</h3><p>之前的两篇笔记中介绍了PCA和Word Embedding，它们都是线性降维的方法，本文要介绍的Neighbor Embedding是非线性降维的方法，它用的是降维之前每一个data point与它的“邻居”之间的关系来做降维，这种方法也叫作<strong>Manifold Learning（流行学习）</strong>，简单地可以理解为是高维空间中的低维空间。</p><p>样本点的分布可能是在高维空间里的一个流行(Manifold)，也就是说，样本点其实是分布在低维空间里面，只是被“扭曲”地塞到了一个高维空间里。比如地球的表面就是一个流行(Manifold)，它是一个二维的平面，但是被塞到了一个三维空间里。</p><p>在Manifold中，只有对距离很近用欧式距离判断其相似程度才会成立，如而在下图的S型曲面中，当点的距离比较远时，用欧氏距离是无法判断两个样本点的相似程度的。而Manifold Learning要做的就是把这个S型曲面降维展开，把塞在高维空间里的低维空间摊平，此时使用欧氏距离就可以描述样本点之间的相似程度，这会对接下来要做的cluster或者supervised learning都会有帮助的。类似的方法有很多，接下来简单介绍几种方法，最后介绍一下t-SNE。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729085418.png" style="zoom: 50%;"></p><h3 id="2-Locally-Linear-Embedding"><a href="#2-Locally-Linear-Embedding" class="headerlink" title="2. Locally Linear Embedding"></a>2. Locally Linear Embedding</h3><p><strong>LLE（locally linear embedding，局部线性嵌入）</strong>的基本思想是：假设在原来的空间中，样本点的分布如下所示，我们关注$x^i$和它的邻居$x^j$，用$w_{ij}$来描述$x_i$和$x_j$的关系。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729085428.png" style="zoom:50%;"></p><p>假设每一个样本点$x^i$都是可以用它的neighbor做linear combination组合而成，那$w_{ij}$就是拿$x^j$去组合$x^i$时的权重weight，因此找点与点的关系$w_{ij}$这个问题就转换成，找一组使得所有样本点与周围点线性组合的差距能够最小的参数$w_{ij}$：</p><script type="math/tex; mode=display">\sum\limits_i||x^i-\sum\limits_j w_{ij}x^j ||_2</script><p>接下来就要做Dimension Reduction，把$x^i$和$x^j$降维到$z^i$和$z^j$，并且保持降维前后两个点之间的关系$w_{ij}$是不变的。这就像是白居易的诗《长恨歌》中写到的“在天愿做比翼鸟，在地愿做连理枝”。</p><p>LLE的具体做法如下：</p><ul><li><p>在原先的高维空间中找到$x^i$和$x^j$之间的关系$w_{ij}$以后就把它固定住</p></li><li><p>使$x^i$和$x^j$降维到新的低维空间上的$z^i$和$z^j$</p></li><li><p>$z^i$和$z^j$需要minimize下面的式子：</p><script type="math/tex; mode=display">\sum\limits_i||z^i-\sum\limits_j w_{ij}z^j ||_2</script></li><li><p>即在原本的空间里，$x^i$可以由周围点通过参数$w_{ij}$进行线性组合得到，则要求在降维后的空间里，$z^i$也可以用同样的线性组合得到</p></li></ul><p>实际上，LLE并没有给出明确的降维函数，它没有明确地告诉我们怎么从$x^i$降维到$z^i$，只是给出了降维前后的约束条。<strong>在实际应用LLE的时候，对$x^i$来说，需要选择合适的邻居点数目K才会得到好的结果</strong>。用LLE或者其他类似的方法有一个好处就是，比如原来你不知道$x^i$、$x^j$，只知道$w_{i,j}$，那你也可用LLE来降维。</p><p>下图给出了原始paper中的实验结果，K太小或太大得到的结果都不太好，注意到在原先的空间里，只有距离很近的点之间的关系需要被保持住，如果K选的很大，就会选中一些由于空间扭曲才导致距离接近的点，而这些点的关系我们并不希望在降维后还能被保留。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729085432.png" style="zoom:50%;"></p><h3 id="3-Laplacian-Eigenmaps"><a href="#3-Laplacian-Eigenmaps" class="headerlink" title="3. Laplacian Eigenmaps"></a>3. Laplacian Eigenmaps</h3><p>另一种方法叫<strong>Laplacian Eigenmaps（拉普拉斯特征映射）</strong>。之前在讲semi-supervised learning有提到smoothness assumption，即我们仅知道两点之间的欧氏距离是不够的，还需要观察两个点在high density区域下的距离。如果两个点在high density的区域里比较近，那才算是真正的接近。我们可以依据某些规则把样本点建立graph，那么smoothness的距离就可以使用graph中连接两个点路径上的edges数来近似。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729085435.png" style="zoom:50%;"></p><p>简单回顾一下在semi-supervised：如果两个点$x^1$和$x^2$在高密度区域上是相近的，那它们的label $y^1$和$y^2$很有可能是一样的</p><script type="math/tex; mode=display">L=\sum\limits_{x^r} C(y^r,\hat y^r) + \lambda S\\S=\frac{1}{2}\sum\limits_{i,j} w_{i,j}(y^i-y^j)^2=y^TLy</script><p>其中$C(y^r,\hat y^r)$表示labeled data项，$\lambda S$表示unlabeled data项，它就像是一个regularization term，用于判断我们当前得到的label是否是smooth的。</p><p>其中如果点$x^i$与$x^j$是相连的，则$w_{i,j}$等于相似度，否则为0，$S$的表达式希望在$x^i$与$x^j$很接近的情况下，相似度$w_{i,j}$很大，而label差距$|y^i-y^j|$越小越好，同时也是对label平滑度的一个衡量</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729085438.png" style="zoom: 50%;"></p><p>降维的基本原则：如果$x^i$和$x^j$在high density区域上是相近的，即相似度$w_{i,j}$很大，则降维后的$z^i$和$z^j$也需要很接近，总体来说就是让下面的式子尽可能小：</p><script type="math/tex; mode=display">S=\frac{1}{2}\sum\limits_{i,j} w_{i,j}(y^i-y^j)^2</script><p>注意，与LLE不同的是，这里的$w_{i,j}$表示$x^i$与$x^j$这两点的相似度，上式也可以写成$S=\sum\limits_{i,j} w_{i,j} ||z^i-z^j||_2$</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729085442.png" style="zoom:50%;"></p><p>（paper：<a href="http://web.cse.ohio-state.edu/~belkin.8/papers/LEM_NIPS_01.pdf" target="_blank" rel="noopener"><em>Belkin, M., Niyogi, P. Laplacian eigenmaps and spectral techniques for embedding and clustering. Advances in neural information processing systems . 2002</em></a>）</p><p>但光有上面这个式子是不够的，假如令所有的z相等，比如令$z^i=z^j=0$，那上式就会直接停止更新。在semi-supervised中，如果所有label $z^i$都设成一样，会使得supervised部分的$\sum\limits_{x^r} C(y^r,\hat y^r)$变得很大，因此lost就会很大，但在这里少了supervised的约束，因此我们<strong>需要给$z$一些额外的约束</strong>：</p><ul><li>假设降维后$z$所处的空间为$M$维，则$Span \{z^1,z^2,…,z^N\}=R^M$，我们希望降维后的$z$占据整个$M$维的空间，而不希望它展开后在一个比$M$更低维的空间里</li><li>最终解出来的$z$其实就是Graph Laplacian $L$比较小的特征值所对应的特征向量。</li></ul><p>这也是Laplacian Eigenmaps名称的由来，我们找的$z$就是Laplacian matrix的特征向量。如果通过拉普拉斯特征映射找到$z$之后再对其利用K-means做聚类，就叫做<strong>谱聚类(spectral clustering)</strong>。</p><h3 id="4-t-SNE"><a href="#4-t-SNE" class="headerlink" title="4. t-SNE"></a>4. t-SNE</h3><p>t-SNE（T-distributed Stochastic Neighbor Embedding，t分布随机邻居嵌入）</p><p>前面的方法有一个缺点就是，<strong>只假设了相邻的点要接近，却没有假设不相近的点要分开</strong>，所以在MNIST使用LLE会遇到下图的情形，它确实会把同一个class的点都聚集在一起，却没有办法避免不同class的点重叠在一个区域，这就会导致依旧无法区分不同class的现象。COIL-20数据集包含了同一张图片进行旋转之后的不同形态，对其使用LLE降维后得到的结果是，同一个圆圈代表同张图像旋转的不同姿态，但许多圆圈之间存在重叠</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729085450.png" style="zoom:80%;"></p><p>做t-SNE同样要降维，在原来$x$的分布空间上，我们需要计算所有$x^i$与$x^j$之间的相似度$S(x^i,x^j)$，然后需要将其做归一化：$P(x^j|x^i)=\frac{S(x^i,x^j)}{\sum_{k\ne i}S(x^i,x^k)}$，即$x^j$与$x^i$的相似度（similarity）占 除了$x^j$之外所有的点与$x^i$的simiarity之和的比例。将$x$降维到$z$，同样可以计算相似度$S’(z^i,z^j)$，并做归一化：$Q(z^j|z^i)=\frac{S’(z^i,z^j)}{\sum_{k\ne i}S’(z^i,z^k)}$。</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729085455.png" style="zoom:80%;"></p><p>注意，这里的归一化是有必要的，因为我们无法判断在$x$和$z$所在的空间里，$S(x^i,x^j)$与$S’(z^i,z^j)$的scale是否是一致的，需要将其映射到一个统一的概率区间，即(0,1)。</p><p>我们<strong>希望找到的投影空间$z$，可以让$P(x^j|x^i)$和$Q(z^j|z^i)$的分布越接近越好</strong>。用于<strong>衡量两个分布之间相似度的方法就是**</strong>KL散度(KL divergence)**，我们的目标就是让$L$越小越好，解法可以用Gradient Descent：</p><script type="math/tex; mode=display">L=\sum\limits_i KL(P(*|x^i)||Q(*|z^i))\\=\sum\limits_i \sum\limits_jP(x^j|x^i)log \frac{P(x^j|x^i)}{Q(z^j|z^i)}</script><p>（<strong>KL Divergence</strong></p><p>这里简单补充一下KL散度的基本知识。KL 散度，最早是从信息论里演化而来的，所以在介绍 KL 散度之前，我们要先介绍一下信息熵，信息熵的定义如下：</p><script type="math/tex; mode=display">H=-\sum\limits_{i=1}^N p(x_i)\cdot log\ p(x_i)</script><p>其中$p(x_i)$表示事件$x_i$发生的概率，信息熵其实反映的就是要表示一个概率分布所需要的平均信息量</p><p>在信息熵的基础上，我们定义KL散度为：</p><script type="math/tex; mode=display">D_{KL}(p||q)=\sum\limits_{i=1}^N p(x_i)\cdot (log\ p(x_i)-log\ q(x_i))\\=\sum\limits_{i=1}^N p(x_i)\cdot log\frac{p(x_i)}{q(x_i)}</script><p>$D_{KL}(p||q)$表示的就是概率$q$与概率$p$之间的差异，很显然，KL散度越小，说明概率$q$与概率$p$之间越接近，那么预测的概率分布与真实的概率分布也就越接近。）</p><h5 id><a href="#" class="headerlink" title=" "></a> </h5><p>t-SNE会计算所有样本点之间的相似度，运算量会比较大，当数据量大的时候跑起来效率会比较低。常见的做法是对原先的空间用类似PCA的方法先做一次降维，然后用t-SNE对这个简单降维空间再做一次更深层次的降维，以期减少运算量。</p><p>值得注意的是，t-SNE的式子无法对新的样本点进行处理，一旦出现新的$x^i$，就需要重新跑一遍该算法，所以<strong>t-SNE通常不是用来训练模型的，它更适合用于做基于固定数据的可视化</strong>。t-SNE常用于将固定的高维数据可视化到二维平面上。</p><p><strong>t-SNE Similarity Measure</strong></p><p>t-SNE中对如何计算similarity的选择是非常的“神妙的“，如果根据欧氏距离计算降维前的相似度，往往采用<strong>RBF function</strong> $S(x^i,x^j)=\exp (-||x^i-x^j||_2)$，这个表达式的好处是，只要两个样本点的欧氏距离稍微大一些，相似度就会下降得很快</p><p>在t-SNE之前有一种叫做SNE的方法，它在降维后的新空间采用与上述相同的相似度算法$S’(z^i,z^j)=e^{-||z^i-z^j||_2}$。而t-SNE的“神妙”之处在于，它在降维后的新空间所采取的相似度算法是与之前不同的，它选取了<strong>t-distribution</strong>中的一种，即$S’(z^i,z^j)=\frac{1}{1+||z^i-z^j||_2}$。</p><p>以下图为例，假设横轴代表了在原先$x$空间上的欧氏距离或者做降维之后在$z$空间上的欧氏距离，红线代表RBF function，是降维前的分布；蓝线代表了t-distribution，是降维后的分布</p><p>你会发现，降维前后相似度从RBF function到t-distribution：</p><ul><li>如果原先在高维空间中两个点距离($\Delta x$)比较近，则降维转换之后，它们的相似度($\Delta y$)依旧是比较接近的</li><li>如果原先在高维空间中两个点距离($\Delta x$)比较远，则降维转换之后，它们的相似度($\Delta y$)会被拉得更远</li></ul><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729085459.png" style="zoom:80%;"></p><p>也就是说t-SNE可以聚集相似的样本点，同时还会放大不同类别之间的距离，从而使得不同类别之间的分界线非常明显，特别适用于可视化，下图则是对MNIST和COIL-20先做PCA降维，再做t-SNE降维可视化的结果：</p><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729085502.png" style="zoom:80%;"></p><p><strong>Conclusion</strong></p><p>小结一下，本文主要介绍了三种非线性降维的算法：</p><ul><li>LLE(Locally Linear Embedding)，局部线性嵌入算法，主要思想是降维前后，每个点与周围邻居的线性组合关系不变，$x^i=\sum\limits_j w_{ij}x^j$、$z^i=\sum\limits_j w_{ij}z^j$；</li><li>Laplacian Eigenmaps，拉普拉斯特征映射，主要思想是在high density的区域，如果$x^i$、$x^j$这两个点相似度$w_{i,j}$高，则投影后的距离$||z^i-z^j||_2$要小；</li><li>t-SNE(t-distribution Stochastic Neighbor Embedding)，t分布随机邻居嵌入，主要思想是，通过降维前后计算相似度由RBF function转换为t-distribution，在聚集相似点的同时，拉开不相似点的距离，比较适合用在数据固定的可视化领域。</li></ul>]]></content>
    
    <summary type="html">
    
      本文介绍了一些非线性降维算法，包括LLE(Locally Linear Embedding，局部线性嵌入)、Laplacian Eigenmaps(拉普拉斯特征映射)和t-SNE(T-distributed Stochastic Neighbor Embedding，t分布随机邻居嵌入t-SNE)。
    
    </summary>
    
    
      <category term="Deep Learning" scheme="http://nekomoon404.github.io/categories/Deep-Learning/"/>
    
    
      <category term="Manifold Learning" scheme="http://nekomoon404.github.io/tags/Manifold-Learning/"/>
    
      <category term="LLE(Locally Linear Embedding)" scheme="http://nekomoon404.github.io/tags/LLE-Locally-Linear-Embedding/"/>
    
      <category term="Laplacian Eigenmaps" scheme="http://nekomoon404.github.io/tags/Laplacian-Eigenmaps/"/>
    
      <category term="t-SNE" scheme="http://nekomoon404.github.io/tags/t-SNE/"/>
    
      <category term="KL Divergence" scheme="http://nekomoon404.github.io/tags/KL-Divergence/"/>
    
  </entry>
  
  <entry>
    <title>DL笔记（12）Unsupervised Learning-Word Embedding</title>
    <link href="http://nekomoon404.github.io/2020/07/26/ML%E7%AC%94%E8%AE%B0%EF%BC%8812%EF%BC%89Unsupervised-Learning-Word-Embedding/"/>
    <id>http://nekomoon404.github.io/2020/07/26/ML%E7%AC%94%E8%AE%B0%EF%BC%8812%EF%BC%89Unsupervised-Learning-Word-Embedding/</id>
    <published>2020-07-26T02:46:43.000Z</published>
    <updated>2020-07-26T03:46:43.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Word Embedding（词嵌入）</strong>就是specific用在word上的Dimension Reductionn，在word embedding里面我们希望machine做的是，machine在看了大量的文章以后，它可以自动地把每一个词汇用不同的vector来表示，而vector的dimension能代表某种含义，至少能够做到比如一些词汇有相近的语义或特殊的关系，可以在vector上呈现出来，而这些我们用来描述词汇的vector就称之为Word Embedding。</p><p><strong>1-of-N Encoding</strong></p><p>一个词汇用vector来描述它，最简单的方法就是<strong>1-of-N Encoding</strong>，假设这个vector的维数就等于世界上所有单词的数目，那么对每一个单词来说，只需要某一维为1，其余都是0即可；这样做的坏处是词汇与词汇之间的关系无法借用这种vector来传递出来，每一个词汇对应的vector都是独立的，无法建立起同类word之间的联系。</p><p><strong>Word Class</strong></p><p>还可以把有同样性质的word进行聚类(clustering)，划分成多个class，然后用word所属的class来表示这个word，但光做clustering是不够的，太粗略了，不同class之间关联依旧无法被有效地表达出来。</p><p><img src="/2020/07/26/ML%E7%AC%94%E8%AE%B0%EF%BC%8812%EF%BC%89Unsupervised-Learning-Word-Embedding/QQ图片20200726112225.png" style="zoom:67%;"></p><h3 id="1-Word-Embedding"><a href="#1-Word-Embedding" class="headerlink" title="1. Word Embedding"></a>1. Word Embedding</h3><p>在Word Embedding中，一个词汇不是硬归类在某一个cluster里面，每一个词汇都用一个continuous的vector来描述词，vector的每个dimension可能都代表着某种含义。Word Embedding把每一个word都投影到高维空间上，当然这个空间的维度要远比1-of-N Encoding的维度低，假如1-of-N Encoding有10w维，那Word Embedding只需要50~100维就够了，这实际上也是Dimension Reduction的过程。</p><p>类似<strong>语义(semantic)</strong>的词汇，在这个word embedding的投影空间上是比较接近的，而且该空间里的每一维都可能有特殊的含义。比如词嵌入的投影空间如下图所示，则横轴可以理解是代表了生物与其它东西之间的区别，而纵轴则代表了会动的东西与静止的东西之间的差别。Word embedding是一个无监督的方法(unsupervised approach)，只要让机器阅读大量的文章，它就可以知道每一个词汇embedding之后的特征向量应该长什么样子。</p><p><img src="/2020/07/26/ML%E7%AC%94%E8%AE%B0%EF%BC%8812%EF%BC%89Unsupervised-Learning-Word-Embedding/QQ图片20200726112236.png" style="zoom:67%;"></p><p>我们的任务就是训练一个neural network，input是词汇，output则是它所对应的word embedding vector，实际训练的时候我们只有data的input，该如何解这类问题呢？之前提到过一种<strong>基于神经网络的降维方法，Auto-encoder</strong>，就是训练一个model，让它的输入等于输出，取出中间的某个隐藏层就是降维的结果，自编码的本质就是通过自我压缩和解压的过程来寻找各个维度之间的相关信息；但word embedding这个问题是不能用Auto-encoder来解的，因为输入的向量通常是1-of-N编码，各维无关，很难通过自编码的过程提取出什么有用信息。</p><p>那找Word Embedding的基本思想就是：<strong>每一个词汇的含义都可以根据它的上下文来得到</strong>。A word can be understood by its context，you shall know a word by the cmpany it keeps.</p><p>比如机器在两个不同的地方阅读到了“马英九520宣誓就职”、“蔡英文520宣誓就职”，它就会发现“马英九”和“蔡英文”前后都有类似的文字内容，于是机器就可以推测“马英九”和“蔡英文”这两个词汇代表了可能有同样地位的东西，即使它并不知道这两个词汇是人名。</p><p><img src="/2020/07/26/ML%E7%AC%94%E8%AE%B0%EF%BC%8812%EF%BC%89Unsupervised-Learning-Word-Embedding/QQ图片20200726112239.png" style="zoom:67%;"></p><p>那如何用这个思想来找出word embedding的vector呢？有两种常用的做法：</p><ul><li><strong>Count based</strong>（基于计数的词嵌入）</li><li><strong>Prediction based</strong>（基于预测的词嵌入）</li></ul><h4 id="1-1-Count-based"><a href="#1-1-Count-based" class="headerlink" title="1.1. Count based"></a>1.1. Count based</h4><p>假如$w_i$和$w_j$这两个词汇常常在同一篇文章中出现(co-occur)，它们的word vector分别用$V(w_i)$和$V(w_j)$来表示，则$V(w_i)$和$V(w_j)$会比较接近。假设$N_{i,j}$是$w_i$和$w_j$这两个词汇在相同文章里同时出现的次数，我们希望它与$V(w_i)\cdot V(w_j)$的内积越接近越好，这个思想和之前的文章中提到的矩阵分解(matrix factorization)的思想其实是一样的。这种方法有一个很代表性的例子是<a href="http://nlp.stanford.edu/projects/glove/" target="_blank" rel="noopener">Glove Vector</a></p><p><img src="/2020/07/26/ML%E7%AC%94%E8%AE%B0%EF%BC%8812%EF%BC%89Unsupervised-Learning-Word-Embedding/QQ图片20200726112242.png" style="zoom:67%;"></p><h4 id="1-2-Prediction-based"><a href="#1-2-Prediction-based" class="headerlink" title="1.2. Prediction based"></a>1.2. Prediction based</h4><h5 id="1-2-1-Language-model"><a href="#1-2-1-Language-model" class="headerlink" title="1.2.1. Language model"></a>1.2.1. Language model</h5><p>Prediction based的方法可以用在Language Modeling上，即predict一个句子出现的几率，比如你想让machine去估测“wreck a nice beach”这个句子出现的几率。但实际上你没有办法去估测一个句子出现的几率，因为word数目就已经很多了，那由word组成的句子就更数不胜数，即使我们能搜到很多句子的database要预测的句子在database出现过的几率极小，且很可能是0。所以在预测句子出现的几率时，通常会将其拆分成小的片段，然后分别去计算每一片段出现的几率，比如我们要计算“wreck a nice beach”出现的几率，那就分别去计算”Start”后面接”wreck”的几率P(wreck|START)，”wreck”后面接”a”的几率P(a|wreck)……其中$P(b|a)$可以用统计的方法去计算，也可以用NN（Neural Network）来做，去计算input 一个词汇a，output词汇b的几率。</p><p><img src="/2020/07/26/ML%E7%AC%94%E8%AE%B0%EF%BC%8812%EF%BC%89Unsupervised-Learning-Word-Embedding/QQ图片20200726152637.png" style="zoom:95%;"></p><p>Language Modeling其实很有用的，可以用在机器翻译或者语音识别当中，它们需要这样的语言模型，比如在做语言辨识使只考虑声学的特性是不够的，不同的sentence可能有相同的发音，所以需要一个语言模型来告诉你哪个句子出现的几率是最高的。下面是一篇最早用神经网络来解决Language Model的paper，<a href="http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf" target="_blank" rel="noopener"><em>Bengio Y, Ducharme R, Vincent P, et al. A neural probabilistic language model[J]. Journal of machine learning research, 2003, 3(Feb): 1137-1155.</em></a>，为后来深度学习在解决语言模型问题甚至很多别的nlp问题时奠定了坚实的基础。</p><blockquote><p>关于这篇论文的解读：<a href="https://www.jianshu.com/p/be242ed3f314" target="_blank" rel="noopener">A Neural Probabilistic Language Model 论文阅读及实战</a>，<a href="https://zhuanlan.zhihu.com/p/81392113" target="_blank" rel="noopener">解析NNLM-A Neural Probabilistic Language Model</a>，<a href="https://zhuanlan.zhihu.com/p/21240807" target="_blank" rel="noopener">A Neural Probabilistic Language Model</a></p></blockquote><p><img src="/2020/07/26/ML%E7%AC%94%E8%AE%B0%EF%BC%8812%EF%BC%89Unsupervised-Learning-Word-Embedding/QQ图片20200726152642.png" style="zoom:95%;"></p><h5 id="1-2-2-how-to-do-perdition"><a href="#1-2-2-how-to-do-perdition" class="headerlink" title="1.2.2. how to do perdition"></a>1.2.2. how to do perdition</h5><p>给定一个sentence，我们要训练一个神经网络，它要做的就是根据当前的word $w_{i-1}$，来预测下一个可能出现的word $w_i$是什么 。假设我们使用1-of-N encoding把$w_{i-1}$表示成feature vector，它作为neural network的input，output的维数和input相等，只不过每一维都是小数，代表在1-of-N Encoding中该维为1其余维为0所对应的word会是下一个word $w_i$的概率。</p><p>如果我们把第一个hidden layer的input $z_1,z_2,…$拿出来，即NN的input乘一个matrix transform（做dimension reduction）得到的feature，用来做代表这个word的vector，它们所组成的$Z$就是word的另一种表示方式，当我们input不同的词汇，向量$Z$就会发生变化。也就是说，第一层hidden layer的维数可以由我们决定，而它的input又唯一确定了一个word，因此提取出第一层hidden layer的input，实际上就得到了一组可以自定义维数的Word Embedding的向量。如果把这些vector都画到平面上，就有可能得到“相似的word有相近的vector”这种图。</p><p><img src="/2020/07/26/ML%E7%AC%94%E8%AE%B0%EF%BC%8812%EF%BC%89Unsupervised-Learning-Word-Embedding/QQ图片20200726112245.png" style="zoom:67%;"></p><h5 id="1-2-3-Why-prediction-works"><a href="#1-2-3-Why-prediction-works" class="headerlink" title="1.2.3. Why prediction works"></a>1.2.3. Why prediction works</h5><p>prediction-based方法是如何体现根据词汇的上下文来了解该词汇的含义这件事呢？</p><p> 假设在两篇文章中，“蔡英文”和“马英九”代表$w_{i-1}$，“宣誓就职”代表$w_i$，我们希望对神经网络输入“蔡英文”或“马英九”这两个词汇，输出都是”宣誓就职”，即vector中对应“宣誓就职”词汇的那个维度的概率值是高的。为了使这两个不同的input通过NN能得到相同的output，就必须在进入hidden layer之前，就通过weight的转换将这两个input vector投影到位置相近的低维空间上。</p><p>也就是说，尽管两个input vector作为1-of-N编码看起来完全不同，但经过linear transform之后，将两者都降维到某一个空间中，在这个空间里，经过转换后的new vector 1和vector 2是非常接近的，因此它们同时进入一系列的hidden layer，最终输出时得到的output是相同的。因此，词汇上下文的联系就自动被考虑在这个prediction model里面。</p><p><img src="/2020/07/26/ML%E7%AC%94%E8%AE%B0%EF%BC%8812%EF%BC%89Unsupervised-Learning-Word-Embedding/QQ图片20200726112248.png" style="zoom:67%;"></p><p>总结一下，对1-of-N编码进行Word Embedding降维的结果就是神经网络模型第一层hidden layer的输入向量$\left [ \begin{matrix} z_1\ z_2\ … \end{matrix} \right ]^T$，该向量同时也考虑了上下文词汇的关联，我们可以通过控制第一层hidden layer的大小从而控制目标降维空间的维数。</p><p>有一个Tips是，在用prediction based的word embedding时，我们用的network的hidden layer通常只有一层，而不会是deep，并且activation function会用linear的，这样就有很像PCA。（提出这个方法的作者曾表示想要找word embedding其实不必用deep network，用shallow的network就够了，而且会train得非常快；另一个理由是word embedding有点像feature extraction，word embedding这个model抽出的vector是要拿来当接下来其他NLP task的Input，其他task用的是deep的model，那或许特征提取的部分就不需用deep的model。）</p><h5 id="1-2-4-Sharing-Parameters"><a href="#1-2-4-Sharing-Parameters" class="headerlink" title="1.2.4. Sharing Parameters"></a>1.2.4. Sharing Parameters</h5><p>你可能会觉得通过当前词汇预测下一个词汇这个约束太弱了（即只看一个词汇去predict下一个词汇），由于不同词汇的搭配千千万万，即便是人也无法准确地给出下一个词汇具体是什么。所有你可以扩展这个问题，使用10个及以上的词汇去预测下一个词汇，可以帮助得到较好的结果。这里假设machine看的是前2个词汇，在实际使用中你可以extent到让machine看前10个词汇或前20个词汇，道理是一样的。</p><p><img src="/2020/07/26/ML%E7%AC%94%E8%AE%B0%EF%BC%8812%EF%BC%89Unsupervised-Learning-Word-Embedding/QQ图片20200726160338.png" style="zoom: 80%;"></p><p>如果是一般的神经网络，我们直接把$w_{i-2}$和$w_{i-1}$这两个vector拼接成一个更长的vector作为input即可。但实际上，我们会用一个trick，希望和$w_{i-2}$相连的weight与和$w_{i-1}$相连的weight是tight在一起的，简单来说就是$w_{i-2}$与$w_{i-1}$的相同dimension对应到第一层hidden layer相同neuron之间的连线拥有相同的weight，即share parameters，在上图中，用同样的颜色标注相同的weight。（回想在CNN中，不同的fliter也会share同样的参数）。</p><p>如果我们不这么做，那把同一个word放在$w_{i-2}$的位置和放在$w_{i-1}$的位置，得到的Embedding结果是会不一样的，把两组weight设置成相同，可以使$w_{i-2}$与$w_{i-1}$的相对位置不会对结果产生影响。除此之外，这么做还可以通过共享参数的方式有效地减少参数量，不会由于input的word数量增加而导致参数量剧增。</p><h5 id="1-2-5-Formulation"><a href="#1-2-5-Formulation" class="headerlink" title="1.2.5. Formulation"></a>1.2.5. Formulation</h5><p>假设$w_{i-2}$的1-of-N编码为$x_{i-2}$，$w_{i-1}$的1-of-N编码为$x_{i-1}$，维数均为$|V|$，表示数据中的words总数。Hidden layer的input为向量$z$，长度为$|Z|$，表示降维后的维数。则有：</p><script type="math/tex; mode=display">z=W_1 x_{i-2}+W_2 x_{i-1}</script><p>其中$W_1$和$W_2$都是$|Z|×|V|$维的weight matrix，它由$|Z|$组$|V|$维的向量构成。我们强迫让$W_1=W_2=W$，此时$z=W(x_{i-2}+x_{i-1})$。因此，只要我们得到了这组参数$W$，就可以与1-of-N编码$x$相乘得到word embedding的结果$z$</p><p><img src="/2020/07/26/ML%E7%AC%94%E8%AE%B0%EF%BC%8812%EF%BC%89Unsupervised-Learning-Word-Embedding/QQ图片20200726112255.png" style="zoom:67%;"></p><h5 id="1-2-6-In-Practice"><a href="#1-2-6-In-Practice" class="headerlink" title="1.2.6. In Practice"></a>1.2.6. In Practice</h5><p>那在实际操作上，我们如何保证$W_1$和$W_2$一样呢？以下图中的$w_i$和$w_j$为例，我们希望它们的weight是一样的：</p><ul><li><p>首先在训练的时候就要给它们一样的初始值</p></li><li><p>然后分别计算loss function $C$对$w_i$和$w_j$的偏微分，并对其进行更新</p><script type="math/tex; mode=display">w_i=w_i-\eta \frac{\partial C}{\partial w_i}\\w_j=w_j-\eta \frac{\partial C}{\partial w_j}</script><p>这个时候你就会发现，$C$对$w_i$和$w_j$的偏微分是不一样的，这意味着即使给了$w_i$和$w_j$相同的初始值，更新过一次之后它们的值也会变得不一样，因此我们必须保证两者的更新过程是一致的，即：</p><script type="math/tex; mode=display">w_i=w_i-\eta \frac{\partial C}{\partial w_i}-\eta \frac{\partial C}{\partial w_j}\\w_j=w_j-\eta \frac{\partial C}{\partial w_j}-\eta \frac{\partial C}{\partial w_i}</script></li><li><p>这个时候，我们就保证了$w_i$和$w_j$始终相等：</p><ul><li>$w_i$和$w_j$的初始值相同</li><li>$w_i$和$w_j$的更新过程相同</li></ul></li></ul><p><img src="/2020/07/26/ML%E7%AC%94%E8%AE%B0%EF%BC%8812%EF%BC%89Unsupervised-Learning-Word-Embedding/QQ图片20200726112259.png" style="zoom:67%;"></p><p>如何去训练这个神经网络呢？注意到这个NN完全是unsupervised，你只需要上网爬一下文章数据直接“喂”给它即可。比如喂给NN的input是“潮水”和“退了”，希望它的output是“就”，之前提到这个NN的输出是一个由概率组成的vector，而targret“就“是只有某一维为1的1-of-N编码，我们希望minimize它们之间的cross entropy，也就是使得输出的那个vector在“就”所对应的那一维上概率最高。</p><p><img src="/2020/07/26/ML%E7%AC%94%E8%AE%B0%EF%BC%8812%EF%BC%89Unsupervised-Learning-Word-Embedding/QQ图片20200726112303.png" style="zoom:67%;"></p><h5 id="1-2-7-Various-Architectures"><a href="#1-2-7-Various-Architectures" class="headerlink" title="1.2.7. Various Architectures"></a>1.2.7. Various Architectures</h5><p>除了上面的基本形态，Prediction-based方法还可以有多种变形：</p><ul><li><p>CBOW(Continuous bag of word model)</p><p>用前后的词汇去预测中间的词汇</p></li><li><p>Skip-gram</p><p>用中间的词汇去预测前后的词汇</p></li></ul><p><img src="/2020/07/26/ML%E7%AC%94%E8%AE%B0%EF%BC%8812%EF%BC%89Unsupervised-Learning-Word-Embedding/QQ图片20200726112306.png" style="zoom:67%;"></p><p>尽管word2vec是deep learning的一个应用，但这个neural network其实并不是deep的，它就只有一个linear的hidden layer。我们把1-of-N编码输入给神经网络，经过weight的转换得到Word Embedding，再通过第一层hidden layer就可以直接得到输出。其实过去有很多人使用过deep model，但这个task不用deep就可以实现，这样做既可以减少运算量，跑大量的data，又可以节省下训练的时间(deep model很可能需要长达好几天的训练时间)。</p><p>Word2Vec会有一些有趣的特性，当把同样类型的东西word vector摆在一起(Italy跟Rome摆在一起，Japen跟Tokyo摆在一起，每一个国家和它的首都之间是有类似的关系的)，或者把动词的三种时态摆在一起，动词的三态中间有某种类似的关系，如下右图中的三角形。</p><p><img src="/2020/07/26/ML%E7%AC%94%E8%AE%B0%EF%BC%8812%EF%BC%89Unsupervised-Learning-Word-Embedding/QQ图片20200726163009.png" style="zoom: 80%;"></p><blockquote><p>关于<strong>word2vec</strong>，可以参考：<a href="https://zhuanlan.zhihu.com/p/26306795" target="_blank" rel="noopener">[NLP] 秒懂词向量Word2vec的本质</a>；<a href="https://zhuanlan.zhihu.com/p/53425736" target="_blank" rel="noopener">word2vec详解(CBOW，skip-gram，负采样，分层Softmax)</a></p></blockquote><h3 id="2-Application"><a href="#2-Application" class="headerlink" title="2. Application"></a>2. Application</h3><h4 id="2-1-Subtraction"><a href="#2-1-Subtraction" class="headerlink" title="2.1. Subtraction"></a>2.1. Subtraction</h4><p><em>机器问答</em></p><p>从得到的Word2vec里，我们可以发现一些原本并不知道的word与word之间的关系。把word vector两两相减，再投影到下图中的二维平面上，如果某些量量配对的word之间有相同关系，比如中下图每对word中的两个word是前者包含后者的关系，那它们的vector做Subtraction（相减）就会被投影到同一块区域。</p><p><img src="/2020/07/26/ML%E7%AC%94%E8%AE%B0%EF%BC%8812%EF%BC%89Unsupervised-Learning-Word-Embedding/QQ图片20200726112309.png" style="zoom:67%;"></p><p>利用这个概念，我们可以做一些简单的推论：</p><ul><li><p>在word vector的特征上，$V(Rome)-V(Italy)≈V(Berlin)-V(Germany)$</p></li><li><p>此时如果有人问“罗马之于意大利等于柏林之于？”，那机器就可以回答这个问题</p><p>因为德国的vector会很接近于“柏林的vector-罗马的vector+意大利的vector”，因此机器只需要计算$V(Berlin)-V(Rome)+V(Italy)$，然后选取与这个结果最接近的vector即可</p></li></ul><p><img src="/2020/07/26/ML%E7%AC%94%E8%AE%B0%EF%BC%8812%EF%BC%89Unsupervised-Learning-Word-Embedding/QQ图片20200726112312.png" style="zoom:67%;"></p><h4 id="2-2-Multi-lingual-Embedding"><a href="#2-2-Multi-lingual-Embedding" class="headerlink" title="2.2. Multi-lingual Embedding"></a>2.2. Multi-lingual Embedding</h4><p><em>机器翻译</em></p><p>此外，Word2vec还可以建立起不同语言之间的联系。如果你要用上述方法分别训练一个英文的<strong>语料库(corpus)</strong>和中文的语料库，你会发现两者的word vector之间是没有任何关系的，因为Word Embedding只体现了上下文的关系，如果你的文章没有把中英文混合在一起使用，机器就没有办法判断中英文词汇之间的关系。</p><p>但是，如果你知道某些中文词汇和英文词汇的对应关系，你可以先分别获取它们的word vector，然后再去训练一个模型，把具有相同含义的中英文词汇投影到新空间上的同一个点。接下来遇到未知的新词汇，无论是中文还是英文，你都可以采用同样的方式将其投影到新空间，就可以自动做到类似翻译的效果。</p><p><img src="/2020/07/26/ML%E7%AC%94%E8%AE%B0%EF%BC%8812%EF%BC%89Unsupervised-Learning-Word-Embedding/QQ图片20200726112315.png" style="zoom:67%;"></p><p>参考文献：<a href="https://ai.stanford.edu/~wzou/emnlp2013_ZouSocherCerManning.pdf" target="_blank" rel="noopener"><em>Bilingual Word Embeddings for Phrase-Based Machine Translation, Will Zou, Richard Socher, Daniel Cer and Christopher Manning, EMNLP, 2013</em></a></p><h4 id="2-3-Multi-domain-Embedding"><a href="#2-3-Multi-domain-Embedding" class="headerlink" title="2.3. Multi-domain Embedding"></a>2.3. Multi-domain Embedding</h4><p><em>图像分类</em></p><p>这个Embedding不只局限于文字的应用，你也可以对文字+图像做Embedding。假设你已经得到horse、cat和dog这些<strong>词汇</strong>的vector在空间上的分布情况，你就可以去训练一个模型，把一些已知的horse、cat和dog<strong>图片</strong>去投影到和对应词汇相同的空间区域上。</p><p>比如对模型输入一张图像，使之输出一个跟word vector具有相同维数的vector，使dog图像的映射向量就散布在dog词汇向量的周围，horse图像的映射向量就散布在horse词汇向量的周围。训练好这个模型之后，输入新的未知图像，根据投影之后的位置所对应的word vector，就可以判断它所属的类别。</p><p><img src="/2020/07/26/ML%E7%AC%94%E8%AE%B0%EF%BC%8812%EF%BC%89Unsupervised-Learning-Word-Embedding/QQ图片20200726112318.png" style="zoom:67%;"></p><p>Paper:  <a href="https://papers.nips.cc/paper/5027-zero-shot-learning-through-cross-modal-transfer.pdf" target="_blank" rel="noopener">zero-shot learning through cross-modal transfer</a></p><p>我们知道在做图像分类的时候，很多情况下都是事先定好要分为哪几个具体的类别，再用这几个类别的图像去训练模型，由于我们无法在训练的时候穷尽所有类别的图像，因此在实际应用的时候一旦遇到属于未知类别的图像，这个模型就无能为力了。而使用<strong>image+word Embedding</strong>的方法，就算输入的图像类别在训练时没有被遇到过，比如上图中的cat，但如果这张图像能够投影到cat的word vector的附近，根据词汇向量与图像向量的对应关系，你自然就可以知道这张图像叫做cat。</p><h4 id="2-4-Document-Embedding"><a href="#2-4-Document-Embedding" class="headerlink" title="2.4. Document Embedding"></a>2.4. Document Embedding</h4><p><em>文档嵌入</em></p><p>除了Word Embedding，我们还可以对Document做Embedding。最简单的方法是把document变成bag-of-word，然后用Auto-encoder就可以得到该文档的语义嵌入(Semantic Embedding)，但光这么做是不够的。</p><p><img src="/2020/07/26/ML%E7%AC%94%E8%AE%B0%EF%BC%8812%EF%BC%89Unsupervised-Learning-Word-Embedding/QQ图片20200726112321.png" style="zoom:67%;"></p><p>因为词汇的顺序代表了很重要的含义，两句词汇相同但语序不同的话可能会有完全不同的含义，比如</p><ul><li>白血球消灭了传染病——正面语义</li><li>传染病消灭了白血球——负面语义</li></ul><p><img src="/2020/07/26/ML%E7%AC%94%E8%AE%B0%EF%BC%8812%EF%BC%89Unsupervised-Learning-Word-Embedding/QQ图片20200726112324.png" style="zoom:67%;"></p><p>想要解决这个问题，具体可以参考下面的几种处理方法（都是unsupervised的做法）：</p><ul><li><strong>Paragraph Vector</strong>: <a href="https://arxiv.org/pdf/1405.4053.pdf" target="_blank" rel="noopener"><em>Le, Quoc, and Tomas Mikolov. “Distributed Representations of Sentences and Documents.“ ICML, 2014</em></a></li><li><strong>Seq2seq Auto-encoder</strong>: <a href="https://arxiv.org/pdf/1506.01057.pdf" target="_blank" rel="noopener"><em>Li, Jiwei, Minh-Thang Luong, and Dan Jurafsky. “A hierarchical neural autoencoder for paragraphs and documents.” arXiv preprint, 2015</em></a></li><li><strong>Skip Thought</strong>: <a href="https://papers.nips.cc/paper/5950-skip-thought-vectors.pdf" target="_blank" rel="noopener"><em>Ryan Kiros, Yukun Zhu, Ruslan Salakhutdinov, Richard S. Zemel, Antonio Torralba, Raquel Urtasun, Sanja Fidler, “Skip-Thought Vectors” arXiv preprint, 2015.</em></a></li></ul>]]></content>
    
    <summary type="html">
    
      本文介绍了NLP领域中的Word Embedding（词嵌入），它是specific用在word上的Dimension Reduction方法，介绍了常用的两种方法：Count-based和Prediction-based，以及Word Embedding的一些应用。
    
    </summary>
    
    
      <category term="Deep Learning" scheme="http://nekomoon404.github.io/categories/Deep-Learning/"/>
    
    
      <category term="Word embedding" scheme="http://nekomoon404.github.io/tags/Word-embedding/"/>
    
      <category term="1-of-N Encoding" scheme="http://nekomoon404.github.io/tags/1-of-N-Encoding/"/>
    
      <category term="Count based" scheme="http://nekomoon404.github.io/tags/Count-based/"/>
    
      <category term="Prediction based" scheme="http://nekomoon404.github.io/tags/Prediction-based/"/>
    
      <category term="Language model" scheme="http://nekomoon404.github.io/tags/Language-model/"/>
    
      <category term="Word2Vec" scheme="http://nekomoon404.github.io/tags/Word2Vec/"/>
    
  </entry>
  
  <entry>
    <title>DL笔记（11）Unsupervised Learning-PCA</title>
    <link href="http://nekomoon404.github.io/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/"/>
    <id>http://nekomoon404.github.io/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/</id>
    <published>2020-07-25T13:24:52.000Z</published>
    <updated>2020-07-26T13:24:52.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-Unsupervised-Learning"><a href="#1-Unsupervised-Learning" class="headerlink" title="1.Unsupervised Learning"></a>1.Unsupervised Learning</h3><p>无监督学习(Unsupervised Learning)可以做的事大致分为两种：</p><ul><li>“化繁为简”<ul><li>聚类(Clustering)</li><li>降维(Dimension Reduction)</li></ul></li><li>“无中生有”：Generation</li></ul><p>对于无监督学习(Unsupervised Learning)来说，我们通常只会拥有$(x,\hat y)$中的$x$或$\hat y$，其中：</p><ul><li><strong>化繁为简</strong>就是把复杂的input变成比较简单的output，比如把一大堆没有打上label的树图片转变为一棵抽象的树，此时training data只有input $x$，而没有output $\hat y$；</li><li><strong>无中生有</strong>就是随机给function一个数字，它就会生成不同的图像，此时training data没有input $x$，而只有output $\hat y$。</li></ul><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200725214439.png" style="zoom:67%;"></p><p>下面我们先简单介绍下Clustering，然后focus在dimension reduction上，而且只focus在linear dimension reduction上。</p><h3 id="2-Clustering"><a href="#2-Clustering" class="headerlink" title="2. Clustering"></a>2. Clustering</h3><p>Clustering（聚类），顾名思义，就是把相近的样本划分为同一类，比如对下面这些没有标签的image进行分类，手动打上cluster 1、cluster 2、cluster 3的标签，这个分类过程就是化繁为简的过程。那有一个很critical的问题：我们到底要分几个cluster？</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200725214453.png" style="zoom:67%;"></p><h4 id="2-1-K-means"><a href="#2-1-K-means" class="headerlink" title="2.1. K-means"></a>2.1. K-means</h4><p>最常用的聚类方法是<strong>K-means</strong>：</p><ul><li>我们有一大堆的unlabeled data $\{x^1,…,x^n,…,x^N\}$，我们要把它划分为K个cluster；</li><li>对每个cluster都要找一个center $c^i,i\in \{1,2,…,K\}$，initial的时候可以从training data里随机挑K个object $x^n$出来作为K个center $c^i$的初始值；</li><li>遍历所有的object $x^n$，并判断它属于哪一个cluster，如果$x^n$与第i个cluster的center $c^i$最接近，那它就属于该cluster，我们用$b_i^n=1$来表示第n个object属于第i个cluster，$b_i^n=0$表示不属于；</li><li>更新center：把每个cluster里的所有object取平均值作为新的center值，即$c^i=\sum\limits_{x^n}b_i^n x^n/\sum\limits_{x^n} b_i^n$；</li><li>重复进行以上的操作；</li></ul><p>注：如果不是从原先的data set里取center的初始值，可能会导致部分cluster没有样本点。</p><h4 id="2-2-HAC"><a href="#2-2-HAC" class="headerlink" title="2.2. HAC"></a>2.2. HAC</h4><p><strong>HAC（Hierarchical Agglomerative Clustering，层次聚类）</strong>。假设现在我们有5个样本点，想要做clustering：</p><ul><li><p>build a tree:</p><p>（整个过程类似建立<a href="https://www.jianshu.com/p/0b476f861bdc" target="_blank" rel="noopener">Huffman Tree</a>，只不过Huffman是依据词频，而HAC是依据相似度建树）</p><ul><li>对5个样本点两两计算相似度，挑出最相似的一对，比如样本点1和2；</li><li>将样本点1和2进行merge (可以对两个vector取平均)，生成代表这两个样本点的新结点；</li><li>此时只剩下4个结点，再重复上述步骤进行样本点的合并，直到只剩下一个root结点。</li></ul></li><li><p>pick a threshold：</p><p>选取阈值，形象来说就是在构造好的tree上横着切一刀，相连的叶结点属于同一个cluster；</p><p>下图中，不同颜色的横线和叶结点上不同颜色的方框对应着切法与cluster的分法，比如按红色的线切就会分成2个cluster，按蓝色的线切就会分成3个cluster。</p></li></ul><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200725214456.png" style="zoom:67%;"></p><p>HAC和K-means最大的区别在于如何决定cluster的数量，在K-means里，K的值是要你直接决定的；而在HAC里，你并不需要直接决定分多少cluster，而是去决定“这一刀切在树的哪里”</p><h3 id="3-Dimension-Reduction"><a href="#3-Dimension-Reduction" class="headerlink" title="3. Dimension Reduction"></a>3. Dimension Reduction</h3><p>clustering的缺点是<strong>以偏概全</strong>，它强迫每个object都要属于某个cluster。但实际上某个object可能拥有多种属性，或者多个cluster的特征，如果把它强制归为某个cluster，就会失去很多信息；或许我们应该用一个vector来描述该object，这个vector的每一维都代表object的某种属性（这个vector的dimension肯定要比object原来的feature数目少），这种做法就叫做<strong>Distributed Representation</strong>。如果原先的object是high dimension的，比如image，那现在用计算出来的它的某些attribute（属性，特征）来描述它，就可以使之从高维空间转变为低维空间，这就是所谓的<strong>降维(Dimension Reduction)</strong>。Distribution Representation和Dimension Reduction其实是一样的事情，只是叫法不同。</p><p>比如哟下图中动漫“全职猎人”中小杰的念能力分布，从表中可以看出我们不能仅仅把他归为强化系，而应该要用一个vector来表示他的attribute。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200725214500.png" style="zoom:67%;"></p><h4 id="3-1-Why-Dimension-Reduction-Help"><a href="#3-1-Why-Dimension-Reduction-Help" class="headerlink" title="3.1 Why Dimension Reduction Help?"></a>3.1 Why Dimension Reduction Help?</h4><p>接下来我们从另一个角度来看为什么Dimension Reduction可能是有用的。假设data为下图左侧中的3D螺旋式分布，你会发现用3D的空间来描述这些data其实是很浪费的，因为我们完全可以把这个卷摊平，此时只需要用2D的空间就可以描述这个3D的信息。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200725214449.png" style="zoom: 80%;"></p><p>如果以MNIST(手写数字集)为例，每一张image都有28*28的dimension，但我们反过来想，大多数28*28 dimension的vector转成image，看起来都不会像是一个数字，所以描述数字所需要的dimension可能远比28*28要来得少。</p><p>举一个极端的例子，下面这几张表示“3”的image，我们完全可以用中间这张image旋转$\theta$角度来描述，也就是说，我们只需要用$\theta$这一个dimension就可以描述原先28*28 dimension的图像。你只要抓住角度的变化就可以知道28维空间中的变化，这里的28*28维pixel就是之前提到的樊一翁的胡子，而1维的角度则是他的头，也就是“去芜存菁，化繁为简”的思想</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200725214503.png" style="zoom:67%;"></p><h4 id="3-2-How-to-do-Dimension-Reduction？"><a href="#3-2-How-to-do-Dimension-Reduction？" class="headerlink" title="3.2. How to do Dimension Reduction？"></a>3.2. How to do Dimension Reduction？</h4><p>那怎么去做Dimension Reduction呢，在Dimension Reduction里，我们要找一个function，这个function的input是原始的$x$，output是经过降维之后的$z$。最简单的方法是<strong>Feature Selection</strong>，即直接从原有的dimension里删掉一些直观上就对结果没有影响的dimension，就做到了降维，比如下图中从$x_1,x_2$两个维度中直接拿掉$x_1$；但这个方法不总是有用，因为很多情况下任何一个dimension其实都不能被拿掉，就像下图中的螺旋卷。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200725214506.png" style="zoom: 67%;"></p><h3 id="4-PCA"><a href="#4-PCA" class="headerlink" title="4. PCA"></a>4. PCA</h3><p>另一个常见的方法叫做<strong>PCA</strong>（Principe Component Analysis，主成分分析）。PCA认为降维就是一个很简单的linear function，它的input x和output z之间是linear transform，即$z=Wx$，PCA要做的，就是根据training data的$x$<strong>把W给找出来</strong>。</p><h4 id="4-1-PCA-for-1-Dimension"><a href="#4-1-PCA-for-1-Dimension" class="headerlink" title="4.1 PCA for 1-Dimension"></a>4.1 PCA for 1-Dimension</h4><p>我们先考虑一个简单的case，假设$z$是1维的vector，也就是把$x$投影到一维空间，此时$W$是一个row vector。$z_1=w^1\cdot x$，其中$w^1$表示$w$的第一个row vector，我们<strong>假设$w^1$的长度为1，即$||w^1||_2=1$，此时$z_1$就是$x$在$w^1$方向上的投影</strong>。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200725224416.png" style="zoom:67%;"></p><p>那我们到底要找什么样的$w^1$呢？假设我们现在已有的宝可梦样本点分布如下，横坐标代表宝可梦的攻击力，纵坐标代表防御力，我们的任务是把这个二维分布投影到一维空间上。我们希望选这样一个$w^1$，它使得$x$经过投影之后得到的$z_1$分布越大越好，也就是说经过这个投影后，不同样本点之间的区别，应该仍然是可以被看得出来的。即：</p><ul><li><p>我们希望找一个projection（投影）的方向，它可以让$x$经过projection后的variance越大越好；</p></li><li><p>我们不希望projection使这些data point通通挤在一起，导致点与点之间的奇异度消失；</p></li><li>要去maximize的对象是$z_1$的variance，其中variance的计算公式：$Var(z_1)=\frac{1}{N}\sum\limits_{z_1}(z_1-\bar{z_1})^2, ||w^1||_2=1$，$\bar {z_1}$是$z_1$的平均值。</li></ul><p>如下图给出了所有样本点在两个不同的方向上投影之后的variance比较情况，从这个图上，你可以看出$w^1$或许是代表宝可梦的强度，宝可梦可能有一个隐藏的factor代表它的强度，这个隐藏的factor同时影响了它的防御力跟攻击力，所以防御力跟攻击力是会同时上升的。</p><h4 id="4-2-PCA-for-n-D"><a href="#4-2-PCA-for-n-D" class="headerlink" title="4.2 PCA for n-D"></a>4.2 PCA for n-D</h4><p>当然我们不可能只投影到一维空间，我们还可以投影到更高维的空间</p><p>对$z=Wx$来说：</p><ul><li>$z_1=w^1\cdot x$，表示$x$在$w^1$方向上的投影</li><li>$z_2=w^2\cdot x$，表示$x$在$w^2$方向上的投影</li><li>…</li></ul><p>$z_1,z_2,…$串起来就得到$z$，而$w^1,w^2,…$分别是$W$的第1,2,…个row，需要注意的是，<strong>这里的$w^i$必须相互正交，此时$W$是正交矩阵(orthogonal matrix)</strong>，如果不加以约束，则算出来的的$w^1,w^2,…$实际上是相同的值 。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200725224420.png" style="zoom:67%;"></p><h4 id="4-3-Lagrange-multiplier"><a href="#4-3-Lagrange-multiplier" class="headerlink" title="4.3. Lagrange multiplier"></a>4.3. Lagrange multiplier</h4><p>求解PCA，实际上已经有现成的函数可以调用，此外你也可以把PCA描述成neural network，然后用gradient descent的方法来求解，这里主要介绍用<strong>Lagrange multiplier（拉格朗日乘数法）</strong>求解PCA的数学推导过程。</p><p>（注：$w^i$和$x$均为列向量，下文中类似$w^i\cdot x$表示的是矢量内积，而$(w^i)^T\cdot x$表示的是矩阵相乘。）</p><p><strong>Step1: calculate $w^1$</strong></p><p>目标：maximize $(w^1)^TSw^1 $，条件：$(w^1)^Tw^1=1$</p><ul><li><p>首先计算出$\bar{z_1}$：</p><script type="math/tex; mode=display">\begin{split}&z_1=w^1\cdot x\\&\bar{z_1}=\frac{1}{N}\sum z_1=\frac{1}{N}\sum w^1\cdot x=w^1\cdot \frac{1}{N}\sum x=w^1\cdot \bar x\end{split}</script></li><li><p>然后计算maximize的对象$Var(z_1)$：</p><p>（其中$Cov(x)=\frac{1}{N}\sum(x-\bar x)(x-\bar x)^T$）</p><script type="math/tex; mode=display">\begin{split}Var(z_1)&=\frac{1}{N}\sum\limits_{z_1} (z_1-\bar{z_1})^2\\&=\frac{1}{N}\sum\limits_{x} (w^1\cdot x-w^1\cdot \bar x)^2\\&=\frac{1}{N}\sum (w^1\cdot (x-\bar x))^2\\&=\frac{1}{N}\sum(w^1)^T(x-\bar x)(x-\bar x)^T w^1\\&=(w^1)^T\frac{1}{N}\sum(x-\bar x)(x-\bar x)^T w^1\\&=(w^1)^T Cov(x)w^1\end{split}</script></li><li><p>当然这里想要求$Var(z_1)=(w^1)^TCov(x)w^1$的最大值，还要加上$||w^1||_2=(w^1)^Tw^1=1$的约束条件，否则$w^1$可以取无穷大。</p></li><li><p>令$S=Cov(x)$，它是：</p><ul><li>对称的(symmetric)</li><li>半正定的(positive-semidefine)，即所有特征值(eigenvalues)是非负的(non-negative)</li></ul><p>（看来是要复习一下研一上学的矩阵理论了(￣ω￣;)）</p></li><li><p>使用拉格朗日乘数法，利用目标和约束条件构造函数：</p><script type="math/tex; mode=display">g(w^1)=(w^1)^TSw^1-\alpha((w^1)^Tw^1-1)</script></li><li><p>对$w^1$这个vector里的每一个element做偏微分：</p><script type="math/tex; mode=display">\partial g(w^1)/\partial w_1^1=0\\\partial g(w^1)/\partial w_2^1=0\\\partial g(w^1)/\partial w_3^1=0\\...</script></li><li><p>整理上述推导式，可以得到：</p><p>其中，$w^1$是$S$的特征向量(eigenvector)</p><script type="math/tex; mode=display">Sw^1=\alpha w^1</script></li><li><p>注意到满足$(w^1)^Tw^1=1$的特征向量$w^1$有很多，我们要找的是可以maximize $(w^1)^TSw^1$的那一个，于是利用上一个式子：</p><script type="math/tex; mode=display">(w^1)^TSw^1=(w^1)^T \alpha w^1=\alpha (w^1)^T w^1=\alpha</script></li><li><p>此时maximize $(w^1)^TSw^1$就变成了maximize $\alpha$，也就是$S$的最大的特征值$\alpha$对应的那个特征向量，就是我们要找的$w^1$</p></li><li><p>结论：<strong>$w^1$是$S=Cov(x)$这个matrix中的最大的特征值$\lambda_1$对应的特征向量</strong></p></li></ul><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200725224424.png" style="zoom:67%;"></p><p><strong>Step2: calculate $w^2$</strong></p><p>在推导$w^2$时，相较于$w^1$，多了一个限制条件：$w^2$必须与$w^1$正交(orthogonal)。</p><p>目标：maximize $(w^2)^TSw^2$，条件：$(w^2)^Tw^2=1,(w^2)^Tw^1=0$</p><p>结论：<strong>$w^2$也是$S=Cov(x)$这个matrix第二大的特征值$\lambda_2$对应的特征向量</strong></p><ul><li><p>同样是用拉格朗日乘数法求解，先写一个关于$w^2$的function，包含要maximize的对象，以及两个约束条件</p><script type="math/tex; mode=display">g(w^2)=(w^2)^TSw^2-\alpha((w^2)^Tw^2-1)-\beta((w^2)^Tw^1-0)</script></li><li><p>对$w^2$的每个element做偏微分：</p><script type="math/tex; mode=display">\partial g(w^2)/\partial w_1^2=0\\\partial g(w^2)/\partial w_2^2=0\\\partial g(w^2)/\partial w_3^2=0\\...</script></li><li><p>整理后得到：</p><script type="math/tex; mode=display">Sw^2-\alpha w^2-\beta w^1=0</script></li><li><p>上式两侧同乘$(w^1)^T$，得到：</p><script type="math/tex; mode=display">(w^1)^TSw^2-\alpha (w^1)^Tw^2-\beta (w^1)^Tw^1=0</script></li><li><p>其中$\alpha (w^1)^Tw^2=0,\beta (w^1)^Tw^1=\beta$，</p><p>而由于$(w^1)^TSw^2$是vector×matrix×vector=scalar，因此在外面套一个transpose（转置）不会改变其值，因此该部分可以转化为：</p><p>（注：$S$是symmetric matrix（对称矩阵）的，既有$S^T=S$。）</p><script type="math/tex; mode=display">\begin{split}(w^1)^TSw^2&=((w^1)^TSw^2)^T\\&=(w^2)^TS^Tw^1\\&=(w^2)^TSw^1\end{split}</script><p>我们已经知道$w^1$满足$Sw^1=\lambda_1 w^1$，代入上式：</p><script type="math/tex; mode=display">\begin{split}(w^1)^TSw^2&=(w^2)^TSw^1\\&=\lambda_1(w^2)^Tw^1\\&=0\end{split}</script></li><li><p>因此有$(w^1)^TSw^2=0$，$\alpha (w^1)^Tw^2=0$，$\beta (w^1)^Tw^1=\beta$，又根据</p><script type="math/tex; mode=display">(w^1)^TSw^2-\alpha (w^1)^Tw^2-\beta (w^1)^Tw^1=0</script><p>可以推得$\beta=0$</p></li><li><p>此时$Sw^2-\alpha w^2-\beta w^1=0$就转变成了$Sw^2-\alpha w^2=0$，即</p><script type="math/tex; mode=display">Sw^2=\alpha w^2</script></li><li><p>由于$S$是symmetric的，因此在不与$w_1$冲突的情况下，这里$\alpha$选取第二大的特征值$\lambda_2$时，可以使$(w^2)^TSw^2$最大</p></li><li><p>结论：<strong>$w^2$也是$S=Cov(x)$这个matrix中的特征向量，对应第二大的特征值$\lambda_2$</strong></p></li></ul><p>（实对称矩阵的不同特征值对应的特征向量是正交的，这个在线性代数或者矩阵理论课程中都有讲过，或者可以参考<a href="https://ccjou.wordpress.com/2011/02/09/實對稱矩陣可正交對角化的證明/" target="_blank" rel="noopener">實對稱矩陣可正交對角化的證明</a>，这是我上学期末在复习矩阵理论的时候发现了一个台湾线代老师的博客，里面有非常多讲解线代知识的文章，思路和内容都要比SJTU用的教材好太多，简直救我期末于水火ヾ(ｏ･ω･)ﾉ）</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200725224427.png" style="zoom:67%;"></p><h4 id="4-4-PCA-decorrelation"><a href="#4-4-PCA-decorrelation" class="headerlink" title="4.4. PCA-decorrelation"></a>4.4. PCA-decorrelation</h4><p>$z=W\cdot x$的神奇之处在于$Cov(z)=D$，即$z$的covariance是一个diagonal matrix，推导过程如下图所示。PCA可以让不同dimension之间的covariance变为0，即不同new feature之间是没有correlation的，这样做的好处是，<strong>减少feature之间的联系从而减少model所需的参数量</strong>。</p><p>如果你把原来的input data通过PCA之后再给其他model使用，那这些model就可以使用简单的形式，而无需考虑不同dimension之间类似$x_1\cdot x_2,x_3\cdot x_5^3,…$这些交叉项，此时model得到简化，参数量大大降低，相同的data量可以得到更好的训练结果，从而可以避免overfitting的发生。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200725224431.png" style="zoom:67%;"></p><h3 id="5-PCA-Another-Point-of-View"><a href="#5-PCA-Another-Point-of-View" class="headerlink" title="5. PCA - Another Point of View"></a>5. PCA - Another Point of View</h3><p>上面我们进行了PCA的数学推导，下面从另一个角度更直观地介绍PCA做了什么。</p><h4 id="5-1-Reconstruction-Component"><a href="#5-1-Reconstruction-Component" class="headerlink" title="5.1. Reconstruction Component"></a>5.1. Reconstruction Component</h4><p>假设我们现在考虑的是手写数字识别，这些数字是由一些类似于笔画的basic component组成的，本质上就是一个vector，记做$u_1,u_2,u_3,…$，以MNIST为例，不同的笔画都是一个28×28的vector，把某几个vector加起来，就组成了一个28×28的digit，写成表达式就是：$x≈c_1u^1+c_2u^2+…+c_ku^k+\bar x$，其中$x$代表某张digit image中的pixel，它等于k个component的加权和$\sum c_iu^i$，加上所有image的平均值$\bar x$。</p><p>比如7就是$x=u^1+u^3+u^5$，我们可以用$\left [\begin{matrix}c_1\ c_2\ c_3…c_k \end{matrix} \right]^T$来表示一张digit image，如果component的数目k远比pixel的数目要小，那这个描述就是比较有效的。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200726082706.png" style="zoom:67%;"></p><p>实际上目前我们并不知道$u^1$~$u^k$具体的值，因此我们要找这样k个vector，使得$x-\bar x$与$\hat x$越接近越好：</p><script type="math/tex; mode=display">x-\bar x≈c_1u^1+c_2u^2+...+c_ku^k=\hat x</script><p>而用未知component来描述的这部分内容，叫做<strong>Reconstruction error</strong>，即$||(x-\bar x)-\hat x||$，接下来我们就要去找k个vector $u^i$去minimize这个error：</p><script type="math/tex; mode=display">L=\min\limits_{u^1,...,u^k}\sum||(x-\bar x)-(\sum\limits_{i=1}^k c_i u^i) ||_2</script><p>回顾PCA，$z=W\cdot x$，实际上我们<strong>通过PCA最终解得的$\{w^1,w^2,…,w^k\}$就是使reconstruction error最小化的$\{u^1,u^2,…,u^k\}$</strong>，简单证明如下：</p><ul><li>将所有的$x^i-\bar x≈c_1^i u^1+c_2^i u^2+…$写在一起，就可以用下图中的矩阵相乘来表示，我们的目标是使等号两侧矩阵之间的差距越小越好；</li></ul><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200726082710.png" style="zoom:67%;"></p><ul><li><p>可以使用<strong>SVD（Singular Value Decomposition，奇异值分解）</strong>将每个matrix $X_{m×n}$都拆成matrix $U_{m×k}$、$\Sigma_{k×k}$、$V_{k×n}$的乘积，其中k为component的数目；</p><p>（SVD可以参考<a href="[https://ccjou.wordpress.com/%E5%B0%88%E9%A1%8C%E6%8E%A2%E7%A9%B6/%E5%A5%87%E7%95%B0%E5%80%BC%E5%88%86%E8%A7%A3%E5%B0%88%E9%A1%8C/](https://ccjou.wordpress.com/專題探究/奇異值分解專題/">奇異值分解專題</a>)，我之前也有纸质笔记，有时间的话可以整理一下，咕咕咕。）</p></li><li><p>值得注意的是，使用SVD拆解后的三个矩阵相乘，是跟等号左边的矩阵$X$最接近的，此时$U$就对应着$u^i$那部分的矩阵，$\Sigma\cdot V$就对应着$c_k^i$那部分的矩阵</p></li><li><p>根据SVD的结论，组成矩阵$U$的k个列向量(标准正交向量, orthonormal vector)就是$XX^T$最大的k个特征值(eignvalue)所对应的特征向量(eigenvector)，而$XX^T$实际上就是$x$的covariance matrix，因此$U$就是PCA的k个解组成的matrix；</p></li><li><p>因此我们可以发现，通过PCA找出来的Dimension Reduction的transform，实际上就是把$X$拆解成能够最小化Reconstruction error的component的过程，通过PCA所得到的$w^i$就是component $u^i$，而Dimension Reduction的结果就是参数$c_i$</p></li><li><p>简单来说就是，用PCA对$x$进行降维的过程中，我们要找的投影方式$w^i$就相当于恰当的组件$u^i$，投影结果$z^i$就相当于这些组件各自所占的比例$c_i$</p></li></ul><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200726082713.png" style="zoom:67%;"></p><ul><li><p>下面的式子简单演示了将一个样本点$x$划分为k个组件的过程，其中$\left [\begin{matrix}c_1 \ c_2\ … c_k \end{matrix} \right ]^T$是每个组件的比例；把$x$划分为k个组件即从n维投影到k维空间，$\left [\begin{matrix}c_1 \ c_2\ … c_k \end{matrix} \right ]^T$也是投影结果，其中$x$和$u_i$均为n维列向量。</p><script type="math/tex; mode=display">\begin{split}&x=\left [\begin{matrix}u_1\ u_2\ ...\ u_k\end{matrix}\right ]\cdot\left [\begin{matrix}c_1\\c_2\\...\\c_k\end{matrix}\right ]\\ \\&\left [\begin{matrix}x_1\\x_2\\...\\x_n\end{matrix}\right ]=\left [\begin{matrix}u_1^1\ u_2^1\ ... u_k^1 \\u_1^2\ u_2^2\ ... u_k^2 \\...\\u_1^n\ u_2^n\ ... u_k^n\end{matrix}\right ]\cdot\left [\begin{matrix}c_1\\c_2\\...\\c_k\end{matrix}\right ]\\\end{split}</script></li></ul><h4 id="5-2-NN-for-PCA"><a href="#5-2-NN-for-PCA" class="headerlink" title="5.2. NN for PCA"></a>5.2. NN for PCA</h4><p>现在我们已经知道，用PCA找出来的$\{w^1,w^2,…,w^k\}$就是k个component $\{u^1,u^2,…,u^k\}$，而$\hat x=\sum\limits_{k=1}^K c_k w^k$，我们要使$\hat x$与$x-\bar x$之间的差距越小越好，我们已经根据SVD找到了$w^k$的值，而对每个不同的样本点，都会有一组不同的$c_k$值，在PCA中我们已经证得，$\{w^1,w^2,…,w^k\}$这k个vector是标准正交化的(orthonormal)，因此：</p><script type="math/tex; mode=display">c_k=(x-\bar x)\cdot w^k</script><p>这个时候我们就可以使用神经网络来表示整个过程，假设$x$是3维向量，要投影到k=2维的component上：</p><ul><li>对$x-\bar x$与$w^k$做inner product的过程类似于neural network，$x-\bar x$在3维空间上的坐标就相当于是neuron的input，而$w^1_1$，$w^1_2$，$w^1_3$则是neuron的weight，表示在$w^1$这个维度上投影的参数，而$c_1$则是这个neuron的output，表示在$w^1$这个维度上投影的坐标值；对$c_2$也同理</li></ul><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200726082717.png" style="zoom:67%;"></p><ul><li>得到$c_1$之后，再让它乘上$w^1$，得到$\hat x$的一部分</li></ul><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200726082720.png" style="zoom: 50%;"></p><ul><li>对$c_2$进行同样的操作，乘上$w^2$，贡献$\hat x$的剩余部分，此时我们已经完整计算出$\hat x$三个分量的值</li></ul><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200726082723.png" style="zoom:67%;"></p><ul><li><p>此时，PCA就被表示成了只含一层hidden layer的神经网络，且这个hidden layer是线性的激活函数，训练目标是让这个NN的input $x-\bar x$与output $\hat x$越接近越好，这件事就叫做<strong>Autoencoder</strong>。</p></li><li><p>注意，<strong>通过PCA求解出的$w^i$与直接对上述的神经网络做梯度下降所解得的$w^i$是会不一样的</strong>，因为PCA解出的$w^i$是正交的(orgonormal)，而用NN的方式得到的解无法保证$w^i$相互垂直，NN无法做到Reconstruction error比PCA小，因此：</p><ul><li>在linear的情况下，直接用PCA找$W$远比用神经网络的方式更快速方便</li><li>用NN的好处是，它可以使用不止一层hidden layer，它可以做<strong>deep</strong> autoencoder</li></ul></li></ul><h4 id="5-3-Weakness-of-PCA"><a href="#5-3-Weakness-of-PCA" class="headerlink" title="5.3. Weakness of PCA"></a>5.3. Weakness of PCA</h4><p>PCA也有很明显的弱点：</p><ul><li><p>它是<strong>unsupervised</strong>的，如果我们要将下图绿色的点投影到一维空间上，PCA给出的从左上到右下的划分很有可能使原本属于蓝色和橙色的两个class的点被merge在一起</p><p>这时要解决问题可能就需要引入label data，LDA（Linear Discriminant Analysis，线性判别分析）则是考虑了labeled data之后进行降维的一种方式，但属于supervised，不在本文讨论。</p></li></ul><blockquote><p>LDA不同于PCA方差最大化理论，LDA算法的思想是将数据投影到低维空间之后，使得同一类数据尽可能的紧凑，不同类的数据尽可能分散。因此，LDA算法是一种有监督的机器学习算法。同时，LDA有如下两个假设:(1) 原始数据根据样本均值进行分类。(2) 不同类的数据拥有相同的协方差矩阵。</p><p>（摘自文章<a href="https://zhuanlan.zhihu.com/p/51769969" target="_blank" rel="noopener">机器学习-LDA(线性判别降维算法)</a>）</p></blockquote><ul><li>它是<strong>linear</strong>的，对于下图中的彩色曲面，我们期望把它平铺拉直进行降维，但这是一个non-linear的投影转换，PCA无法做到这件事情，PCA只能做到把这个曲面打扁压在平面上，类似下图，而无法把它拉开。对类似曲面空间的降维投影，需要用到non-linear transformation</li></ul><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200726082726.png" style="zoom:67%;"></p><h3 id="6-More-Examples"><a href="#6-More-Examples" class="headerlink" title="6. More Examples"></a>6. More Examples</h3><h4 id="6-1-PCA-for-Pokemon"><a href="#6-1-PCA-for-Pokemon" class="headerlink" title="6.1. PCA for Pokemon"></a>6.1. PCA for Pokemon</h4><p>这里举一个实际应用的例子，用PCA来分析宝可梦的数据，假设总共有800只宝可梦，每只都用一个六维的vector来表示，即vector={HP, Atk, Def, Sp Atk, Sp Def, Speed}，然后我们用PCA来分析，首先要面对的问题是，要将6维的vector投影到多少维的空间上？</p><p>如果做可视化分析的话，投影到二维或三维平面可以方便人眼观察，实际上，宝可梦的$cov(x)$是6维，最多可以投影到6维空间。一个常用的方法是：我们可以先找出6个特征向量和对应的特征值$\lambda_i$，其中$\lambda_i$表示第$i$个投影维度的variance有多大(即在第i个维度的投影上点的散步程度有多大，variance越大，点的分布就越散，这也是我们所希望的)，然后我们就可以计算出每个$\lambda_i$的比例，ratio=$\frac{\lambda_i}{\sum\limits_{i=1}^6 \lambda_i}$</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200726082729.png" style="zoom:67%;"></p><p>从上图的ratio可以看出$\lambda_5$、$\lambda_6$所占比例不高，即第5和第6个principle component(可以理解为维度)所发挥的作用是比较小的，用这两个dimension做投影所得到的variance很小，投影在这两个方向上的点比较集中，意味着这两个维度表示的是宝可梦的共性，无法对区分宝可梦的特性做出太大的贡献，所以我们只需要利用前4个principle component即可。 </p><p>注意到新的维度本质上就是旧的维度的加权矢量和，下图给出了前4个维度的加权情况，从PC1到PC4这4个principle component都是6维度加权的vector，它们都可以被认为是某种组件，每一个宝可梦都可以由这4个principle component加权之和。</p><p>我们来仔细分析一下这四个component代表的“含义”：</p><ul><li><p>对第一个vector PC1来说，每个值都是正的，因此这个组件在某种程度上代表了宝可梦的强度</p></li><li><p>对第二个vector PC2来说，防御力Def很大而速度Speed很小，这个组件可以增加宝可梦的防御力但同时会牺牲一部分的速度</p></li><li><p>如果将宝可梦仅仅投影到PC1和PC2这两个维度上，则降维后的二维可视化图像如下图所示：</p><p>从该图中也可以得到一些信息：</p><ul><li>在PC2维度上特别大的那个样本点刚好对应着普普(海龟)，确实是防御力且速度慢的宝可梦</li><li>在PC1维度上特别大的那三个样本点则对应着盖欧卡、超梦等综合实力很强的宝可梦</li></ul></li></ul><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200726082731.png" style="zoom:67%;"></p><ul><li><p>对第三个vector PC3来说，sp Def很大而HP和Atk很小，这个组件是用生命力和攻击力来换取特殊防御力</p></li><li><p>对第四个vector PC4来说，HP很大而Atk和Def很小，这个组件是用攻击力和防御力来换取生命力</p></li><li><p>同样将宝可梦只投影到PC3和PC4这两个维度上，则降维后得到的可视化图像如下图所示：</p><p>该图同样可以告诉我们一些信息：</p><ul><li>在PC3维度上特别大的样本点依旧是普普，第二名是冰柱机器人，它们的特殊防御力都比较高</li><li>在PC4维度上特别大的样本点则是吉利蛋和幸福蛋，它们的生命力比较强</li></ul></li></ul><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200726082735.png" style="zoom:67%;"></p><h4 id="6-2-PCA-for-MNIST"><a href="#6-2-PCA-for-MNIST" class="headerlink" title="6.2. PCA for MNIST"></a>6.2. PCA for MNIST</h4><p>再次回到手写数字识别的问题上来，这个时候我们就可以熟练地把一张数字图像用多个组件(维度)表示出来了：</p><script type="math/tex; mode=display">digit\ image=a_1 w^1+a_2 w^2+...</script><p>这里的$w^i$就表示降维后的其中一个维度，即一个principle component，它是由原先28×28维进行加权求和的结果，因此$w^i$也是一张28×28的图像，下图列出了通过PCA得到的前30个组件的形状：</p><p>注：PCA就是求$Cov(x)=\frac{1}{N}\sum (x-\bar x)(x-\bar x)^T$的前30个最大的特征值对应的特征向量</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200726082738.png" style="zoom:67%;"></p><h4 id="6-3-PCA-for-Face-Recognition"><a href="#6-3-PCA-for-Face-Recognition" class="headerlink" title="6.3. PCA for Face Recognition"></a>6.3. PCA for Face Recognition</h4><p>同理，在人脸识别的例子中，通过PCA找出人脸的前30个component(维度)，如下图所示，用这些脸的组件做线性组合就可以得到所有的脸。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200726082741.png" style="zoom:67%;"></p><p>在对MNIST和Face的PCA结果展示的时候，你可能会注意到我们找到的组件好像并不算是组件，比如MNIST找到的几乎是完整的数字雏形，而Face找到的也几乎是完整的人脸雏形，但我们预期的组件不应该是类似于横折撇捺，眼睛鼻子眉毛这些吗？如果你仔细思考了PCA的特性，就会发现得到这个结果是可能的：</p><script type="math/tex; mode=display">digit\ image=a_1 w^1+a_2 w^2+...</script><p>注意到linear combination的weight $a_i$可以是正的也可以是负的，因此我们可以通过把组件进行相加或相减来获得目标图像，这会导致你找出来的component不是基础的组件，但是通过这些组件的加加减减肯定可以获得基础的组件元素。</p><h4 id="6-4-NMF"><a href="#6-4-NMF" class="headerlink" title="6.4. NMF"></a>6.4. NMF</h4><p>如果你要一开始就得到类似笔画这样的基础组件，就要使用<strong>NMF(non-negative matrix factorization)，非负矩阵分解</strong>的方法。PCA可以看成对原始矩阵$X$做SVD进行矩阵分解，但并不保证分解后矩阵的正负，实际上当进行图像处理时，如果部分组件的matrix包含一些负值的话，如何处理负的像素值也会成为一个问题(可以做归一化处理，但比较麻烦)。而NMF的基本思想是，强迫使所有component的每一个dimension都是正的，且它的加权值$a_1$都必须是正的，也就是说<strong>所有图像都必须由组件叠加得到</strong>：</p><ul><li>Forcing $a_1$, $a_2$…… be non-negative<ul><li>additive combination</li></ul></li><li>Forcing $w_1$, $w_2$…… be non-negative<ul><li>More like “parts of digits”</li></ul></li></ul><p>(注：关于NMF的具体算法内容可参考paper <a href="https://papers.nips.cc/paper/1861-algorithms-for-non-negative-matrix-factorization.pdf" target="_blank" rel="noopener"><em>Daniel D. Lee and H. Sebastian Seung. “Algorithms for non-negative matrix factorization.”Advances in neural information processing systems. 2001.</em> </a>）</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200726094309.png" style="zoom: 45%;"></p><p><strong>NMF for MNIST</strong></p><p>在MNIST数据集上，通过NMF找到的前30个组件如下图所示，可以发现这些组件都是由基础的笔画构成：</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200726082745.png" style="zoom:67%;"></p><p><strong>NMF for Face</strong></p><p>在Face数据集上，通过NMF找到的前30个组价如下图所示，相比于PCA这里更像是脸的一部分</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200726082748.png" style="zoom:67%;"></p><h4 id="More-Related-Approaches"><a href="#More-Related-Approaches" class="headerlink" title="More Related Approaches"></a>More Related Approaches</h4><p>降维的方法有很多，这里再列举一些与PCA有关的方法：</p><ul><li><p>Multidimensional Scaling (<strong>MDS</strong>) [Alpaydin, Chapter 6.7]</p><p>MDS不需要把每个data都表示成feature vector，只需要知道特征向量之间的distance，就可以做降维，PCA保留了原来在高维空间中的距离，在某种情况下MDS就是特殊的PCA</p></li><li><p><strong>Probabilistic PCA</strong> [Bishop, Chapter 12.2]</p><p>PCA概率版本</p></li><li><p><strong>Kernel PCA</strong> [Bishop, Chapter 12.3]</p><p>PCA非线性版本</p></li><li><p>Canonical Correlation Analysis (<strong>CCA</strong>) [Alpaydin, Chapter 6.9]</p><p>CCA常用于两种不同的data source的情况，比如同时对声音信号和唇形的图像进行降维</p></li><li><p>Independent Component Analysis (<strong>ICA</strong>)</p><p>ICA常用于source separation，PCA找的是正交的组件，而ICA则只需要找“独立”的组件即可</p></li><li><p>Linear Discriminant Analysis (<strong>LDA</strong>) [Alpaydin, Chapter 6.8]</p><p>LDA是supervised的方式</p></li></ul><h3 id="7-Matrxi-Factorization"><a href="#7-Matrxi-Factorization" class="headerlink" title="7. Matrxi Factorization"></a>7. Matrxi Factorization</h3><p>接下来用一个简单的推荐系统的例子来介绍下<strong>矩阵分解</strong>的思想。有时候存在两种object，它们之间会受到某种共同<strong>潜在因素</strong>(latent factor)的操控，如果我们找出这些潜在因素，就可以对用户的行为进行预测，这也是<strong>推荐系统</strong>常用的方法之一。</p><p>假设我们现在去调查每个人购买的手办数目，ABCDE代表5个人，每个人或者每个手办的动漫人物实际上都是有着傲娇的属性或天然呆的属性（老师是老二次元实锤）。我们可以用vector去描述人和公仔的属性，如果某个人的属性和某个公仔的属性是match的，即他们背后的vector很像(内积值很大)，这个人就会偏向于拥有更多这种类型的公仔。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200726095546.png" style="zoom:67%;"></p><p><strong>matrix expression</strong></p><p>但是，我们没有办法直接观察某个人背后这些潜在的属性，也不会有人在意一个肥宅心里想的是什么（肥宅大哭），我们同样也没有办法直接得到动漫人物背后的属性；我们目前有的，只是动漫人物和人之间的关系，即每个人已购买的公仔数目，我们要通过这个关系去推测出动漫人物与人背后的<strong>潜在因素(latent factor)</strong>。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200726095550.png" style="zoom:67%;"></p><p>我们可以把每个人的属性用vector $r^A$、$r^B$、$r^C$、$r^D$、$r^E$来表示，而动漫人物的属性则用vector $r^1$、$r^2$、$r^3$、$r^4$来表示，购买的公仔数目可以被看成是matrix $X$，对$X$来说，行数为人数，列数为动漫角色的数目。做一个假设：matrix $X$里的每个element，都是属于人的vector和属于动漫角色的vector的内积，比如，$r^A\cdot r^1≈5$，表示$r^A$和$r^1$的属性比较贴近，那A这个人就会买比较多凉宫春日的手办。</p><p>接下来就用下图所示的矩阵相乘的方式来表示这样的关系，其中$K$为latent factor的数量，这是未知的，需要你自己去调整选择，我们要找一组$r^A$~$r^E$和$r^1$~$r^4$，使得右侧两个矩阵相乘的结果与左侧的matrix $X$越接近越好，可以使用SVD的方法求解。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200726095553.png" style="zoom:67%;"></p><p><strong>prediction</strong></p><p>但有时候，部分的information可能是会missing的，这时候就难以用SVD精确描述，但我们可以使用梯度下降的方法求解，loss function如下：</p><script type="math/tex; mode=display">L=\sum\limits_{(i,j)}(r^i\cdot r^j-n_{ij})^2</script><p>其中$r^i$值的是人背后的latent factor，$r^j$指的是动漫角色背后的latent factor，我们要让这两个vector的内积与实际购买该公仔的数量$n_{ij}$越接近越好，这个方法的关键之处在于，计算上式时，可以跳过missing的数据，最终通过gradient descent求得$r^i$和$r^j$的值。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200726095556.png" style="zoom:67%;"></p><p>假设latent factor的数目等于2，则人的属性$r^i$和动漫角色的属性$r^j$都是2维的vector，这里实际进行计算后，把属性中较大值标注出来，可以发现：</p><ul><li>人：A、B属于同一组属性，C、D、E属于同一组属性</li><li><p>动漫角色：1、2属于同一组属性，3、4属于同一组属性</p></li><li><p>结合动漫角色，可以分析出动漫角色的第一个维度是天然呆属性，第二个维度是傲娇属性</p></li><li><p>接下来就可以预测未知的值，只需要将人和动漫角色的vector做内积即可</p></li></ul><p>这样就可以针对阿宅做一个简单的<strong>推荐系统</strong>了。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200726095559.png" style="zoom:67%;"></p><p><strong>more about matrix factorization</strong></p><p>实际上除了人和动漫角色的属性之外，可能还存在其他因素操控购买数量这一数值，因此我们可以将式子更精确地改写为：</p><script type="math/tex; mode=display">r^A\cdot r^1+b_A+b_1≈5</script><p>其中$b_A$表示A这个人本身有多喜欢买公仔，$b_1$则表示这个动漫角色本身有多受欢迎，这些内容是跟属性vector无关的，此时loss function被改写为：</p><script type="math/tex; mode=display">L=\sum\limits_{(i,j)}(r^i\cdot r^j+b_i+b_j-n_{ij})^2</script><p>当然你也可以加上一些regularization去对结果做约束。（有关Matrix Factorization和推荐系统更多内容的介绍，可以参考paper <a href="https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf" target="_blank" rel="noopener"><em>Matrix Factorization Techniques For Recommender Systems</em></a>；有关Matrix Factorization的理论知识，可以参考：<a href="https://ccjou.wordpress.com/" target="_blank" rel="noopener">線代啟示錄</a>）</p><p><strong>for Topic Analysis</strong></p><p>如果把matrix factorization的方法用在topic analysis上，就叫做<strong>LSA(Latent semantic analysis)，潜在语义分析</strong>。我们只需要把动漫人物换成文章，人换成词汇，表中的值从购买数量换成词频即可，table里面的值就是term frequency，把这个term frequency乘上一个weight代表说这个term本身有多重要。</p><p>Evaluation一个term的重要性的常用的方式是：inverse document frequency(计算每一个词汇在整个paper有多少比率的document涵盖这个词汇，假如说，每个词汇，每个document都有，那它的inverse document frequency就很小，代表着这个词汇的重要性是低的，假设某个词汇只有某一篇document有，那它的inverse document frequency就很大，代表这个词汇对于这篇文章的重要性是高的，这个词汇的含义与文章的语义关联性就比较高。)</p><p>在这个task里，做matrix factorization，就会找到每一个document背后的latent factor，它可能指的是topic(主题)，这个topic有多少是跟财经有关的，有多少是跟政治有关的。document1跟document2有比较多的“投资，股票”这样的词汇，那document1跟document2就有比较高的可能背后的latent factor是比较偏向“财经”的。我们可以用词汇的重要性给词频加权，在各种文章中出现次数越多的词汇越不重要，出现次数越少则越重要。这个场景下找出的latent factor可能会是主题(topic)，比如某个词汇或某个文档有多少比例是偏向于财经主题、政治主题…</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Unsupervised-Learning-PCA/QQ图片20200726101618.png" style="zoom:67%;"></p><p>Topic analysis的方法多如牛毛，但基本的思想是差不多的，常见的方法有pLSA（probability latent semantic analysis，概率潜在语义分析）和LDA（latent Dirchlet allocation，隐含狄利克雷分布）。注意这里的LDA和之前在5.3节提到的LDA是不一样的。</p><blockquote><p>pLSA 可以参考：<a href="https://zhuanlan.zhihu.com/p/31235789" target="_blank" rel="noopener">pLSA原理及其代码实现</a>；</p><p>LDA 可以参考：<a href="https://zhuanlan.zhihu.com/p/31470216" target="_blank" rel="noopener">一文详解LDA主题模型</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      Unsupervised learning（无监督学习）可以做的事大致可以分为Clustering（聚类），Dimension Reduction（降维）和Generation。本文先简单介绍了Clustering，然后主要从数学推导和理解component的含义这两个角度来介绍了Dimension Redunction中常用的一种方法PCA(Principe Component Analysis，主成分分析），最后简单介绍了Matrix Factorization。
    
    </summary>
    
    
      <category term="Deep Learning" scheme="http://nekomoon404.github.io/categories/Deep-Learning/"/>
    
    
      <category term="K-means" scheme="http://nekomoon404.github.io/tags/K-means/"/>
    
      <category term="HAC" scheme="http://nekomoon404.github.io/tags/HAC/"/>
    
      <category term="PCA" scheme="http://nekomoon404.github.io/tags/PCA/"/>
    
      <category term="NMF" scheme="http://nekomoon404.github.io/tags/NMF/"/>
    
      <category term="Matrix Factorization" scheme="http://nekomoon404.github.io/tags/Matrix-Factorization/"/>
    
  </entry>
  
  <entry>
    <title>ML笔记（10）Semi-supervised Learning</title>
    <link href="http://nekomoon404.github.io/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Semi-supervised-Learning/"/>
    <id>http://nekomoon404.github.io/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Semi-supervised-Learning/</id>
    <published>2020-07-25T07:31:35.000Z</published>
    <updated>2020-07-25T08:31:35.000Z</updated>
    
    <content type="html"><![CDATA[<p>我们之间讲的Learning方法基本都是Supervised Learning（监督学习），这篇文章主要介绍<strong>Semi-supervised Learning（半监督学习）</strong>。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Semi-supervised-Learning/QQ图片20200725153847.png" style="zoom: 80%;"></p><p>Supervised Learning：$(x^r,\hat y^r)$$_{r=1}^R$</p><ul><li>training data中，每一组data都有input $x^r$和对应的output $y^r$</li></ul><p>Semi-supervised Learning：$\{(x^r,\hat y^r)\}_{r=1}^R$} + $\{x^u\}_{u=R}^{R+U}$ </p><ul><li><p>training data中，部分data没有标签，只有input $x^u$ </p></li><li><p>通常遇到的场景是，无标签的数据量远大于有标签的数据量，即<strong>U&gt;&gt;R</strong></p></li><li><p>semi-supervised learning分为以下两种情况：</p><ul><li><p><strong>Transductive Learning</strong>（直推学习）: unlabeled data is the testing data</p><p>即把testing data当做无标签的training data使用，适用于事先已经知道testing data的情况(一些比赛的时候)</p><p>值得注意的是，这种方法使用的仅仅是testing data的feature，而不是label，因此不会出现“直接对testing data做训练而产生cheating的效果”</p></li><li><p><strong>Inductive Learning</strong>（归纳学习）: unlabeled data is not the testing data</p><p>即不把testing data的feature拿去给机器训练，适用于事先并不知道testing data的情况(更普遍的情况)</p></li></ul></li></ul><blockquote><p>半监督学习的情况，训练集为$\mathcal{D}=\{\pmb{X_{tr}},\pmb{y_{tr}}\}$，测试集为$\pmb{X_{tr}}$，此时，$\pmb{X_{un}}$与 $\pmb{X_{te}}$都是未标记的，但我们测试的$\pmb{X_{te}}$在训练时没有见过，这种情况是 inductive semi-supervised learning。</p><p>如果我们不管$\pmb{X_{te}}$的效果怎么样时，由于此时在训练的时候我们已经见过$\pmb{X_{un}}$（利用了$\pmb{X_{un}}$的特征信息)，这时就叫transductive semi-supervised learning。</p><p>简单来说，transductive和inductive的区别在于我们想要预测的样本，是不是我们在训练的时候已经见（用）过的。</p><p>通常transductive比inductive的效果要好，因为inductive需要从训练generalize到测试。</p><p>（摘自知乎回答：<a href="https://www.zhihu.com/question/68275921/answer/529156908" target="_blank" rel="noopener">如何理解 inductive learning 与 transductive learning?</a>）</p></blockquote><ul><li><p>为什么要做semi-supervised learning？</p><p>用机器学习解决实际问题时，很多情况我们是不缺data的 ，只是缺有label的data，就像你可以拍很多照片，但它们一开始都是没有标签的，而给data加label是要花费很大成本的。</p></li></ul><h3 id="1-Why-semi-supervised-learning-help？"><a href="#1-Why-semi-supervised-learning-help？" class="headerlink" title="1. Why semi-supervised learning help？"></a>1. Why semi-supervised learning help？</h3><p>那为什么semi-supervised learning会有帮助呢？<em>The distribution of the unlabeled data tell us something.</em> unlabeled data虽然只有input，但它的<strong>分布</strong>，却可以告诉我们一些事情。</p><p>假设我们现在要做分类的task，建一个猫跟狗的classifier，我们同时有一大堆猫跟狗的图片。这些图片是没有label的，并不知道哪些是猫哪些是狗。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Semi-supervised-Learning/QQ图片20200725153856.png" style="zoom:80%;"></p><p>在只有labeled data的情况下，红线是二元分类的分界线。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Semi-supervised-Learning/QQ图片20200725161724.png" style="zoom: 50%;"></p><p>但当我们加入unlabeled data的时候，由于<strong>特征分布</strong>发生了变化，分界线也随之改变。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Semi-supervised-Learning/QQ图片20200725153900.png" style="zoom: 80%;"></p><p>semi-supervised learning的使用往往伴随着假设，而该假设的合理与否，决定了结果的好坏程度；比如上图中的unlabeled data，它显然是一只狗，而特征分布却与猫被划分在了一起，很可能是由于这两张图片的背景都是绿色导致的。</p><h3 id="2-Semi-supervised-Learning-for-Generative-Model"><a href="#2-Semi-supervised-Learning-for-Generative-Model" class="headerlink" title="2. Semi-supervised Learning for Generative Model"></a>2. Semi-supervised Learning for Generative Model</h3><p>在监督学习中，我们已经讨论过概率生成模型了，假设class1和class2的分布分别为$mean_1=u^1,covariance_1=\Sigma$、$mean_2=u^2,covariance_2=\Sigma$的高斯分布，计算出Prior Probability后，再根据贝叶斯公式可以推得新生成的$x$所属的类别。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Semi-supervised-Learning/QQ图片20200725162916.png" style="zoom:80%;"></p><p>如果在原先的数据基础上加了unlabeled data(下图中绿色的点)，它就会影响最终的决定，你会发现原先的$u,\Sigma$显然是不合理的，新的$u,\Sigma$需要使得样本点的分布更接近下图虚线圆所标出的范围，除此之外，右侧的Prior Probability会给人一种比左侧大的感觉(右侧样本点”变多”了)。此时，unlabeled data对$P(C_1),P(C_2),u^1,u^2,\Sigma$都产生了一定程度的影响，划分两个class的decision boundary也会随之发生变化</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Semi-supervised-Learning/QQ图片20200725162923.png" style="zoom:80%;"></p><p>上面是比较直观的解释，接下来进行具体推导(假设做二元分类)：</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Semi-supervised-Learning/QQ图片20200725162930.png" style="zoom:80%;"></p><ul><li><p>先随机初始化一组参数：$\theta=\{P(C_1),P(C_2),u^1,u^2,\Sigma\}$</p></li><li><p>step1：利用初始model计算每一笔unlabeled data $x^u$属于class 1的概率$P_{\theta}(C_1|x^u)$</p></li><li><p>step2：update model</p><p>如果不考虑unlabeled data，则先验概率显然为属于class1的样本点数$N_1$/总的样本点数$N$，即$P(C_1)=\frac{N_1}{N}$</p><p>而考虑unlabeled data时，分子还要加上所有unlabeled data属于class 1的概率和，此时它们被看作小数，可以理解为按照概率一部分属于$C_1$，一部分属于$C_2$</p><script type="math/tex; mode=display">P(C_1)=\frac{N_1+\sum_{x^u}P(C_1|x^u)}{N}</script><p>同理，对于均值，原先的mean $u_1=\frac{1}{N_1}\sum\limits_{x^r\in C_1} x^r$加上根据概率对$x^u$求和再归一化的结果即可</p><script type="math/tex; mode=display">u_1=\frac{1}{N_1}\sum\limits_{x^r\in C_1} x^r+\frac{1}{\sum_{x^u}P(C_1|x^u)}\sum\limits_{x^u}P(C_1|x^u)x^u</script><p>剩余的参数同理，接下来就有了一组新的参数$\theta’$，于是回到step1-&gt;step2-&gt;step1循环</p></li><li><p>理论上该方法保证是可以收敛的，而一开始给$\theta$的初始值会影响收敛的结果，类似gradient descent。</p></li></ul><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Semi-supervised-Learning/QQ图片20200725162934.png" style="zoom:80%;"></p><p>以上的推导基于的基本思想是，把unlabeled data $x^u$看成是可以划分的，一部分属于$C_1$，一部分属于$C_2$，此时它的概率$P_{\theta}(x^u)=P_{\theta}(x^u|C_1)P(C_1)+P_{\theta}(x^u|C_2)P(C_2)$，也就是$C_1$的先验概率乘上$C_1$这个class产生$x^u$的概率+$C_2$的先验概率乘上$C_2$这个class产生$x^u$的概率。</p><p>实际上我们在利用极大似然函数更新参数的时候，就利用了该拆分的结果：</p><script type="math/tex; mode=display">logL(\theta)=\sum\limits_{x^r} logP_{\theta}(x^r)+\sum\limits_{x^u}logP_{\theta}(x^u)</script><h3 id="3-Low-density-Separation-Assumption"><a href="#3-Low-density-Separation-Assumption" class="headerlink" title="3. Low-density Separation Assumption"></a>3. Low-density Separation Assumption</h3><p>接下来介绍一种新的方法，它基于的假设是<strong>Low-density separation</strong>。通俗来讲，Low-density separation把这个世界看作是“非黑即白的”，在两个class的交界处data的密度(density)是很低的，它们之间会有一道明显的鸿沟，此时unlabeled data(下图绿色的点)就是帮助你在原本正确的基础上挑一条更好的boundary。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Semi-supervised-Learning/QQ图片20200725164031.png" style="zoom:80%;"></p><h4 id="3-1-Self-training"><a href="#3-1-Self-training" class="headerlink" title="3.1. Self-training"></a>3.1. Self-training</h4><p>low-density separation最具代表性也最简单的方法是<strong>self training</strong>，大致的流程是：</p><ul><li>先从labeled data去训练一个model $f^*$，训练方式没有限制；</li><li>然后用该$f^<em>$去对unlabeled data打上label，$y^u=f^</em>(x^u)$，也叫作pseudo label（伪标签）；</li><li>从unlabeled data中拿出一些data加到labeled data里，至于data的选取需要你自己设计算法来挑选；</li><li>回头再去训练$f^*$，循环即可。</li></ul><p>注：<strong>low-density separation对Regression是不适用的</strong>。Regression是output一个数值，那用$f^<em>$给unlabeled data打上label后，再取一部分加到原来的data里，对model $f^</em>$是不会产生影响的，这部分新的data的Loss是0 。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Semi-supervised-Learning/QQ图片20200725164034.png" style="zoom:80%;"></p><p>实际上，该方法与之前提到的generative model还是挺像的，区别在于：</p><ul><li>Self Training使用的是hard label：假设一笔data就是属于某一个class；</li><li>Generative Model使用的是soft label：假设一笔data可以按照概率划分，有多少几率属于class 1，有多少几率属于class 2等等。</li></ul><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Semi-supervised-Learning/QQ图片20200725164039.png" style="zoom:80%;"></p><p>如果我们使用的是neural network的做法，$\theta^<em>$是从labeled data中得到的一组参数，此时丢进来一个unlabeled data $x^u$，通过$f^</em>_{\theta^*}()$后得到$\left [\begin{matrix} 0.7\\ 0.3 \end{matrix}\right ]$，即它有0.7的概率属于class 1，0.3的概率属于class 2</p><ul><li>如果此时使用hard label，则$x^u$的label被转化成$\left [\begin{matrix}1\\ 0 \end{matrix}\right ]$</li><li>如果此时使用soft label，则$x^u$的label依旧是$\left [\begin{matrix} 0.7\\ 0.3 \end{matrix}\right ]$</li></ul><p>可以看到，<strong>在neural network里使用soft label是没有用的</strong>，如上面的例子中，unlabeled data $x^u$输入model得到的output是$\left [\begin{matrix} 0.7\\ 0.3 \end{matrix}\right ]$，那我们给$x^u$设的target（或者说给$x^u$新加的label）就是$\left [\begin{matrix} 0.7\\ 0.3 \end{matrix}\right ]$，那下次update model的时候，$x^u$的Loss就是0了，对参数$\theta^*$的更新毫无贡献；而如果我们用hard label，unlabeled data $x^u$输入model得到的output是$\left [\begin{matrix} 0.7\\ 0.3 \end{matrix}\right ]$，那我们给$x^u$设的target就是$\left [\begin{matrix} 1\\ 0 \end{matrix}\right ]$，那下次update model的时候，$x^u$的Loss即不为0，对参数更新是有贡献的。实际上low density separation就是通过强制分类来提升分类效果的方法。</p><h4 id="3-2-Entropy-based-Regularization"><a href="#3-2-Entropy-based-Regularization" class="headerlink" title="3.2. Entropy-based Regularization"></a>3.2. Entropy-based Regularization</h4><p>Entropy-based Regularization是low-density separation的进阶版，你可能会觉得hard label这种直接强制性打标签的方式有些太武断了，你如果用neural network，得到的output是一个distribution，我们用hard label去限制这个output一定是class 1或者class 2，但是我们之前做了Low-density separation的假设，即希望得到的distribution是很集中的，比如distribution集中在class 1，而在其他class上很小。</p><p>由于我们不知道unlabeled data $x^u$的label到底是什么，但如果通过entropy-based regularization得到的分布集中在某个class上的话，那这个model就是好的，而如果分布是比较分散的，那这个model就是不好的，那如何去评价我们得到的distribution是好还是坏呢，就可以用到Entropy-based regularization。                </p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Semi-supervised-Learning/QQ图片20200725164044.png" style="zoom: 80%;"></p><p>接下来的问题是，如何用数值的方法来evaluate distribution的集中(好坏)与否，要用到的方法叫entropy，一个distribution的entropy可以告诉你它的集中程度。输入unlabeled data $x^u$得到的output $y^u=f^<em>_{\theta^</em>}(x^u)$，其中$y^u$是一个<strong>概率分布(distribution)</strong>，那Entropy of $y^u$为：</p><script type="math/tex; mode=display">E(y^u)=-\sum\limits_{m=1}^5 y_m^u ln(y_m^u)</script><p>对上图中的第1、2种情况，算出的$E(y^u)=0$，而第3种情况，算出的$E(y^u)=-ln(\frac{1}{5})=ln(5)$，可见<strong>entropy越大，distribution就越分散，entropy越小，distribution就越集中</strong>。</p><p>我们的目标是在labeled data上分类要正确，在unlabeled data上，output的entropy要越小越好，此时就要修改loss function。</p><ul><li><p>对labeled data来说，它的output要跟正确的label越接近越好，用cross entropy表示如下：</p><script type="math/tex; mode=display">L=\sum\limits_{x^r} C(y^r,\hat y^r)</script></li><li><p>对unlabeled data来说，要使得该distribution(也就是output)的entropy越小越好：</p><script type="math/tex; mode=display">L=\sum\limits_{x^u} E(y^u)</script></li><li><p>两项综合起来，可以用weight来加权，以决定哪个部分更为重要一些</p><script type="math/tex; mode=display">L=\sum\limits_{x^r} C(y^r,\hat y^r) + \lambda \sum\limits_{x^u} E(y^u)</script></li></ul><p>可以发现该式长得很像之前讲过的L1/L2 Regularization，这也就是entropy-based regularization的名称由来。</p><h4 id="3-3-Semi-supervised-SVM"><a href="#3-3-Semi-supervised-SVM" class="headerlink" title="3.3. Semi-supervised SVM"></a>3.3. Semi-supervised SVM</h4><p>另一个很著名的半监督学习的方法是Semi-supervised SVM。（SVM在之后的课程才会讲到，这里先做一下简单的介绍）SVM要做的是，给你两个class的data，去找一个boundary：</p><ul><li>要有最大的margin，让这两个class分的越开越好</li><li>要有最小的分类错误</li></ul><p>对unlabeled data穷举所有可能的label，如下图中列举了三种可能的情况；然后对每一种可能的结果都去算SVM，再找出可以让margin最大，同时又minimize error的那种情况，如下图中用黑色方框标注的情况。</p><blockquote><p>SVM的基本想法是极大化划分超平面与两类样例之间的最小距离，即所谓的“Margin”，以增强算法的鲁棒性。</p><p>（摘自<a href="http://blog.zheng-xie.com/2016/07/21/large-margin-distribution-learning/" target="_blank" rel="noopener">机器学习中的“Margin”</a>）</p></blockquote><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Semi-supervised-Learning/QQ图片20200725164047.png" style="zoom:80%;"></p><blockquote><p>SVM paper：<a href="https://www.cs.cornell.edu/people/tj/publications/joachims_99c.pdf" target="_blank" rel="noopener">Thorsten Joachims, ”<em>Transductive</em> <em>Inference for Text Classification using Support Vector Machines”,</em> ICML, 1999</a></p></blockquote><p>当然这么做会存在一个问题，对于n笔unlabeled data，意味着即使在二元分类里也有$2^n$种可能的情况，数据量大的时候，几乎难以穷举完毕，上面给出的paper提出了一种approximate的方法，基本精神是：一开始你先得到一些label，然后每次改一笔unlabeled data的label，看看可不可以让你的objective function变大，如果变大就去改变该label。</p><h3 id="3-Smoothness-Assumption"><a href="#3-Smoothness-Assumption" class="headerlink" title="3. Smoothness Assumption"></a>3. Smoothness Assumption</h3><p>smoothness assumption的思想可以理解是：“近朱者赤，近墨者黑”，即使相似的$x$具有相同的$\hat y$，精确的定义是：</p><ul><li><p>x的分布是不平均的；</p></li><li><p>如果$x^1$和$x^2$在一个high density region上很接近的话，那么$\hat y^1$和$\hat y^2$就是相同的，也就是这两个点可以在样本点高密度集中分布的区域块中有一条可连接的路径，即 connected by a high density path。</p></li></ul><p>假设下图是data的分布，$x^1,x^2,x^3$是其中的三笔data，如果单纯地看$x$的相似度，显然$x^2$和$x^3$更接近一些，但对于smoothness assumption来说，$x^1$和$x^2$是处于同一块区域的，它们之间可以有一条相连的路径；而$x^2$与$x^3$之间则是“断开”的，没有high density path，因此$x^1$与$x^2$更“像”。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Semi-supervised-Learning/QQ图片20200725193926.png" style="zoom: 67%;"></p><p>以手写数字识别为例，对于最右侧的2和3以及最左侧的2，显然最右侧的2和3在pixel上相似度更高一些；但如果把所有连续变化的2都放进来，就会产生一种“不直接相连的相似”，根据Smoothness Assumption的理论，由于2之间有连续过渡的形态，因此第一个2和最后一个2是比较像的，而最右侧2和3之间由于没有过渡的data，因此它们是比较不像的；人脸识别的两个侧面的过渡也同理。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Semi-supervised-Learning/QQ图片20200725193934.png" style="zoom:67%;"></p><p>Smoothness Assumption在<strong>file classification（文件分类）</strong>上是非常有用的，假设对天文学(astronomy)和旅行(travel)的文章进行分类，它们各自有专属的词汇，此时如果unlabeled data与label data的词汇是相同或重合(overlap)的，那么就很容易分类；但在真实的情况下，unlabeled data和labeled data之间可能没有任何重复的words，因为世界上的词汇太多了，sparse的分布很难会使overlap发生。但如果收集到的unlabeled data足够多，就会以一种相似传递的形式，比如下图中$d_1$和$d_5$像，$d_5$和$d_6$像，$d_6$和$d_7$像，会propagation起来，建立起文档之间相似的桥梁。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Semi-supervised-Learning/QQ图片20200725193938.png" style="zoom:67%;"></p><p><strong>cluster and then label</strong></p><p>在具体实现上，有一种简单的方法是cluster and then label，也就是先把data分成几个cluster，划分class之后再拿去训练，但这种方法不一定会得到好的结果，因为它的假设是你可以把同一个class的样本点cluster在一起，而这其实是没那么容易的。</p><p>对图像分类来说，如果单纯用pixel的相似度来划分cluster，得到的结果一般都会很差，你需要设计一个很好的方法来描述image(类似Deep Autoencoder的方式来提取feature)，这样cluster才会有效果。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Semi-supervised-Learning/QQ图片20200725193942.png" style="zoom:67%;"></p><p><strong>Graph-based Approach</strong></p><p>之前讲的是比较直觉的做法，接下来引入Graph Structure来表达connected by a high density path这件事。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Semi-supervised-Learning/QQ图片20200725193945.png" style="zoom:67%;"></p><p>我们把所有的data points都建成一个graph，有时候建立vertex（顶点）之间的关系是比较容易的，比如网页之间的链接关系、论文之间的引用关系；但有时候需要你自己去寻找vertex之间的关系。Graph的好坏，对结果起着至关重要的影响，而如何build graph却是一件heuristic（启发式的，探索的）的事情，需要凭着经验和直觉来做。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Semi-supervised-Learning/QQ图片20200725193949.png" style="zoom:67%;"></p><ul><li><p>首先定义两个object $x^i,x^j$之间的相似度 $s(x^i, x^j)$</p><p>如果是基于pixel的相似度，performance可能会不太好；建议使用autoencoder提取出来的feature来计算相似度，得到的performance会好一些</p></li><li><p>算完相似度后，就可以建graph了，方式有很多种：</p><ul><li>k nearest neighbor：假设k=3，则每个point与相似度最接近的3个点相连</li><li>e-neighborhood：每个point与相似度超过某个特定threshold $e$的点相连</li></ul></li><li><p>除此之外，还可以给Edge特定的weight，让它与要连接起来的两个data point的相似度$s(x^i,x^j)$成正比</p><ul><li><p>建议用RBM function来确定相似度：$s(x^i,x^j)=\exp(-\gamma||x^i-x^j||^2 )$</p><p>这里$x^i,x^j$均为vector，计算它们的Euclidean Distance(欧几里得距离)，加上参数后再取exponential</p></li><li><p>至于加exponential，经验上来说通常是可以帮助提升performance的，在这里只有当$x^i,x^j$非常接近的时候，singularity才会大；只要距离稍微远一点，singularity就会下降得很快，变得很小</p></li><li><p>使用exponential的RBM function可以做到只有非常近的两个点才能相连，稍微远一点就无法相连的效果，避免了下图中跨区域相连的情况</p></li></ul></li></ul><p>graph-based approach的基本思想是，在graph上已经有一些labeled data，那么跟它们相连的point，属于同一类的概率就会上升，每一笔data都会去影响它的邻居，而graph带来的最重要的好处是，这个影响是会随着edges<strong>传递</strong>出去的，即使有些点并没有真的跟labeled data相连，也可以被传递到相应的属性。</p><p>比如下图中，如果graph建的足够好，那么从两个被分别label为蓝色和红色的点就可以传递出两张完整的图；从中我们也可以看出，如果想要让这种方法生效，收集到的data一定要足够多，否则可能传递到一半，graph就断掉了，information的传递就失效了。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Semi-supervised-Learning/QQ图片20200725193953.png" style="zoom:67%;"></p><p>介绍完了如何定性使用graph，接下来介绍一下如何定量使用graph。定量的使用方式是定义label的smoothness，<strong>我们期望smooth的值越小越好</strong>。下图中，edge上的数字是weight，$x^i$表达data，$y^i$表示data的label，计算smoothness的方式为：</p><script type="math/tex; mode=display">S=\frac{1}{2}\sum\limits_{i,j} w_{i,j}(y^i-y^j)^2</script><p>比如计算下面两个graph的smoothness：</p><script type="math/tex; mode=display">\begin{split}S_1 &=\frac{1}{2}\left[w_{1,2}(y^1-y^2)^2 +w_{1,3}(y^1-y^3)^2+ w_{2,3}(y^2-y^3)^2+w_{3,4}(y^3-y^4)^2\right]\\&=\frac{1}{2}\left[2*(1-1)^2 +3*(1-1)^2+ 1*(1-1)^2+1*(1-0)^2\right]=0.5\\S_2&=\frac{1}{2}\left[2*(0-1)^2 +3*(0-1)^2+ 1*(1-1)^2+1*(1-0)^2\right]=3\\\end{split}</script><p>则有$S_1&lt;S_2$，那么左边的graph比右边的graph要更smooth。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Semi-supervised-Learning/QQ图片20200725193957.png" style="zoom:67%;"></p><p>当然上面的式子还可以化简，如果把labeled data和unlabeled data的y组成一个(R+U)-dim vector，即</p><script type="math/tex; mode=display">y=\left [\begin{matrix} ...y^i...y^j\end{matrix} \right ]^T</script><p>于是smooth可以改写为：</p><script type="math/tex; mode=display">S=\frac{1}{2}\sum\limits_{i,j} w_{i,j}(y^i-y^j)^2=y^TLy</script><p>其中L为(R+U)×(R+U) matrix，成为<strong>Graph Laplacian</strong>， 定义为$L=D-W$</p><ul><li>$W$：把data point两两之间weight的关系建成matrix，代表了$x^i$与$x^j$之间的weight值</li><li>$D$：把$W$的每一个row上的值加起来放在该行对应的diagonal上即可，比如5=2+3,3=2+1,…</li></ul><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Semi-supervised-Learning/QQ图片20200725194000.png" style="zoom:67%;"></p><p>对$S=y^TLy$来说，$y$是label，是neural network的output，取决于neural network的parameters，因此要在原来仅针对labeled data的loss function中加上这一项，得到：</p><script type="math/tex; mode=display">L=\sum\limits_{x^r}C(y^r,\hat y^r) + \lambda S</script><p>其中的$\lambda S$实际上也是一个regularization term。那现在我们的训练目标是：</p><ul><li>labeled data的cross entropy越小越好(neural network的output跟真正的label越接近越好)</li><li>smooth S越小越好(neural network的output，不管是labeled还是unlabeled，都要符合Smoothness Assumption的假设)</li></ul><p>具体训练的时候，不一定只局限于neural network的output要smooth，可以对中间任意一个hidden layer加上smooth的限制，也可以使每一个hidden layer的output都是smooth。</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Semi-supervised-Learning/QQ图片20200725194004.png" style="zoom:67%;"></p><h3 id="4-Better-Representation"><a href="#4-Better-Representation" class="headerlink" title="4. Better Representation"></a>4. Better Representation</h3><p>Better Representation的思想可以理解是“去芜存菁，化繁为简”。（我们观察到的世界是比较复杂的，而在它的背后其实是有一些比较简单的东西，在操控着这个复杂的世界，所以只要你能够看透这个世界的假象，直指它的核心的话，就可以让training变得比较容易）举一个例子，在神雕侠侣中，杨过要在三招之内剪掉樊一翁的胡子，虽然胡子的变化是比较复杂的，但头的变化是有限的，杨过看透了这一件事情就可以把胡子剪掉。在这个例子中，樊一翁的胡子就是original representation，而他的头就是你要找的better representation。（李老师真是太博学了Σ(っ°Д°;)っ）</p><p><img src="/2020/07/25/ML%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Semi-supervised-Learning/QQ图片20200725204624.png" style="zoom:67%;"></p><p>算法具体思路和内容将在下一次的笔记Unsupervised Learning-Principal Component Analysis (PCA)中介绍。</p>]]></content>
    
    <summary type="html">
    
      本文主要介绍了Semi-supervised Learning（半监督学习）的概念，Semi-supervised Learning for Generative model，以及做Semi-supervised Learning时常用的两种假设：Low-density Separation Assumption和Smoothness Assumption。
    
    </summary>
    
    
      <category term="Machine Learning" scheme="http://nekomoon404.github.io/categories/Machine-Learning/"/>
    
    
      <category term="Semi-supervised learning" scheme="http://nekomoon404.github.io/tags/Semi-supervised-learning/"/>
    
      <category term="Low-density separation assumption" scheme="http://nekomoon404.github.io/tags/Low-density-separation-assumption/"/>
    
      <category term="Self-training" scheme="http://nekomoon404.github.io/tags/Self-training/"/>
    
      <category term="Entropy-based regularization" scheme="http://nekomoon404.github.io/tags/Entropy-based-regularization/"/>
    
      <category term="Smoothness assumption" scheme="http://nekomoon404.github.io/tags/Smoothness-assumption/"/>
    
      <category term="Graph-based approach" scheme="http://nekomoon404.github.io/tags/Graph-based-approach/"/>
    
  </entry>
  
  <entry>
    <title>DL笔记（9）Recurrent Neural Network(RNN)</title>
    <link href="http://nekomoon404.github.io/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/"/>
    <id>http://nekomoon404.github.io/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/</id>
    <published>2020-07-20T13:38:02.000Z</published>
    <updated>2020-07-23T13:38:02.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-Example-Application"><a href="#1-Example-Application" class="headerlink" title="1. Example Application"></a>1. Example Application</h3><p>先来看一个例子：Slot Filling（槽填充）。这是个NLP领域的知识点，这里作一下简单介绍，参考知乎文章<a href="https://zhuanlan.zhihu.com/p/93853430" target="_blank" rel="noopener">槽填充（Slot Filling）的定义、用途、意义及其他</a>。</p><blockquote><p>One way of making sense of a piece of text is to tag the words or tokens which carry meaning to the sentences. In the field of Natural Language Processing, this problem is known as <strong>Semantic Slot Filling</strong>.——<a href="https://link.zhihu.com/?target=https%3A//mc.ai/semantic-slot-filling-part-1/">mc.ai</a></p><p>槽填充是指从大规模的语料库中抽取给定实体（query）的被明确定义的属性（slot types）的值（slot fillers）。</p><p>填槽指的是为了让用户意图转化为用户明确的指令而补全信息的过程。</p><p>Slot Filling的用途或意义可以是：用于任务型对话；作为意图识别的关键字；作为下一步对话的提示信息。</p></blockquote><p>设想一个订票系统，它听到用户说：“ i would like to arrive Taipei on November 2nd”，你的系统有一些slot(如有一个slot是Destination，一个slot是time of arrival)，系统要自动知道这边的每一个词汇是属于哪一个slot，比如Taipei属于Destination这个slot，November 2nd属于time of arrival这个slot。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200720223600.png" style="zoom: 67%;"></p><p>这个问题当然可以使用一个feedforward neural network来解，叠一个feedforward neural network，input是一个词汇(把Taipei变成一个vector)输入到这个neural network。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200720224046.png" style="zoom:67%;"></p><p>以下是把词汇用向量来表示的方法：</p><p><strong>1-of-N encoding</strong></p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200720224050.png" style="zoom:67%;"></p><p><strong>Beyond 1-of-N encoding</strong></p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200720224055.png" style="zoom:67%;"></p><p>如果只是用1-of-N encoding来描述一个词汇的话会遇到一些问题，因为有很多词汇你可能都没有见过，所以需要在1-of-N encoding里面多加dimension，图中左边绿色条最后一个dimension代表other。不是在我们词言有的词汇就归类到other里面去(如Gandalf,Sauron归类到other里面去)。或者可以用每一个词汇的字母来表示它的vector，比如apple，apple里面有出现app、ppl、ple，那在这个vector里面对应到app,ple,ppl的dimension就是1,而其他都为0。</p><p>假设我们已经解决了把词汇表示为vector，然后把这个vector输入到feedforward neural network里，在这个task里面，我们希望output是一个probability distribution。这个probability distribution代表着我们现在input词汇属于每一个slot的几率，比如Taipei属于destination的几率和Taipei属于time of departure的几率。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200720224058.png" style="zoom:67%;"></p><p>但这会遇到一些feedforward neural network没办法解决的问题。假设现在有一个使用者说：“arrive Taipei on November 2nd”(arrive-other,Taipei-dest, on-other,November-time,2nd-time)。那现在有人说:”<strong>leave Taipei</strong> on November 2nd”，这时候Taipei就变成了“place of departure”，<strong>它应该是出发地</strong>而不是目的地。但是对于feedforward neural network来说，input一样的东西output就应该是一样的东西(input “Taipei”，output要么是destination几率最高，要么就是place of departure几率最高)，没有办法一会让出发地的几率最高，一会让它目的地几率最高。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200720224103.png" style="zoom:67%;"></p><p>那如果今天我们的neural network是有记忆力的，它记得看红色的Taipei之前它就已经看过arrive这个词汇；它记得看绿色的Taipei之前，它就已经看过leave这个词汇，那么它就可以根据上下文产生不同的output。如果让我们的neural network是有记忆力的话，它就可以解决在两句不同的话中，input相同的词汇，得到的output不同，这样一个问题。</p><h3 id="2-RNN"><a href="#2-RNN" class="headerlink" title="2. RNN"></a>2. RNN</h3><p>这种有记忆的neural network就叫做Recurrent Neural network，RNN（循环神经网络）。在RNN里面，每一次hidden layer的neuron产生output的时候，这些output会被存到memory里去(下图中用蓝色方块表示memory)。那下一次当有input时，这些neuron不只是考虑input$x_1,x_2$，还会考虑存到memory里的值$a_1,a_2$。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200720225712.png" style="zoom:67%;"></p><p>通过下面的例子来理解RNN的原理，设下图中的RNN中的neuron的weight都是1，bias都是0，若input sequence为$[1,1]^T,[1,1]^T,[2,2]^T$，给定memory中的初始值$a_1=a_2=0$，那么output sequence为：</p><ul><li>input $[1,1]^T$，$x_1=x_2=1$，$a_1=a_2=0$；hidden layer得到 $a_1=a_2=x_1+x_2+a_1+a_2=2$；output $y_1=y_2=a_1+a_2=4$；</li><li>input $[1,1]^T$，$x_1=x_2=1$，$a_1=a_2=2$；hidden layer得到 $a_1=a_2=6$；output $y_1=y_2=12$；</li><li>input $[2,2]^T$，$x_1=x_2=2$，$a_1=a_2=6$；hidden layer得到 $a_1=a_2=16$；output $y_1=y_2=32$；</li></ul><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200720225717.png" style="zoom:67%;"></p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200720225721.png" style="zoom:67%;"></p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200720225725.png" style="zoom:67%;"></p><p>需要注意的是：<strong>对于RNN，input sequence的顺序并不是independent的， 是会对输出的结果造成影响的</strong>，所以在RNN中我们要考虑input sequence的order。</p><p>那现在用RNN来处理Slot Filling这个问题的流程大致是这样的：顾客说”arrive Taipei on November 2nd”，arrive转换为vector输入到network；然后经过hidden layer得到$a^1$，它是hidden layer的输出，也是个vector；由$a^1$在output layer得到输出$y^1$，$y^1$是arrive属于每一个slot的几率。$a^1$会被存储到memory中，接下来Taipei转换为输入的vector $x^2$，<strong>hidden layer会同时考虑$a^1$和$x^2$</strong>，得到$a^2$，然后得到$y^2$，$y^2$是Taipei属于每个slot的几率。之后就以此类推。注意图中并不是三个network，而是同一个network在三个不同的时间点被使用，同样的weight用同样的颜色表示。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200720220120.png" style="zoom: 33%;"></p><p>这样就可以解决之前那个问题了，如果两次分别输入的是arrive Taipei和leave Taipei，由于arrive和leave的不同，导致hidden layer得到$a^1$不同，由于在输入Taipei时，hidden layer会同时考虑$a^1$和$x^2$，那两次得到的$y^2$就很会不同，从而把语义区分开。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200720220110.png" style="zoom:33%;"></p><p>当然RNN的架构是可以根据具体的需要来设计的，上图中的hidden layer只有一层，当然也可以做成Deep Recurrent Neural Network。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200720221809.png" style="zoom:33%;"></p><p><strong>Elman network &amp;Jordan network</strong></p><p>RNN有很多种变形，上面讲到的叫Elman Network，它是把hidden layer得到的值存起来，在下一个时间点再读出来；有另外一种RNN叫作Jordan Network，它每次存的是network的output值，在下一个时间点再读出来。（据说Jordan Network的效果可能好一下，理解是因为output y是有target的，我们清楚是把什么东西放进了memory；而hidden layer是没有target的，很难控制说它能学到什么hidden layer information）。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200720221813.png" style="zoom:33%;"></p><p><strong>Bidirectional neural network</strong></p><p>RNN还可以是双向的，上面讲的RNN，input一个句子，是从句首一直读到句尾。假设句子里的每一个词汇由$x_t$表示，RNN就是先读$x_t$，再读$x_{t+1}$，再读$x_{t+2}$。那它的读取方向也可以是反过来的，可以先读$x_{t+2}$，再读$x_{t+1}$，再读$x_t$。我们可以同时train一个正向的RNN和一个逆向的RNN，然后把这两个RNN的hidden layer得到的值拿出来，都接给一个output layer得到最后的$y_t$，比如正向的network在input$x_t$的时候hidden layer得到的值，跟逆向的network在input $x_t$时hidden layer得到值，都输入到output layer中得到$y_t$，然后以此类推得到$y_{t+1},y_{t+2}$。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200720232755.png" style="zoom:67%;"></p><p>用Bidirectional neural network的好处是，neural在产生output的时候，它看的范围是比较广的。如果你只有正向的network，再产生$y_t,y_{t+1}$的时候，你的network只看过$x_1$到$x_{t+1}$的input。但Bidirectional neural network，在产生$y_t,y_{t+1}$的时候，你的network不只看过$x_1$到$x_{t+1}$的input，它也看了从句尾$x_N$到$x_{t+1}$的input，就等于整个input的sequence。那对于第一节中讲到的slot filling的例子，你的network就等于看了整个sentence后，才决定每一个词汇的slot应该是什么。这样会比看sentence的一半还要得到更好的performance。</p><h3 id="3-LSTM"><a href="#3-LSTM" class="headerlink" title="3. LSTM"></a>3. LSTM</h3><h4 id="3-1-What-is-LSTM"><a href="#3-1-What-is-LSTM" class="headerlink" title="3.1 What is LSTM"></a>3.1 What is LSTM</h4><p>上面讲到的memory方式是最简单的，我们可以随时把值存到memory去，也可以把值读出来。但目前最常用的memory方式是<strong>Long Short-term Memory(LSTM，长时间的短期记忆)</strong>。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200720232759.png" style="zoom:67%;"></p><p>Long Short-term Memory有三个gate，当某个neural的output想要被写到memory cell里面的时候，必须通过一个<strong>input Gate</strong>，input Gate被打开的时候，你才能把值写到memory cell里面，而input Gate是打开还是关起来是neural network自己学的。这个cell输出的地方有一个<strong>output Gate</strong>，output Gate决定其他的neural可不可以从这个memory里面把值读出来，output Gate关闭时不能读出，打开时才可以把值读出来。跟input Gate一样，output Gate何时打开或关闭，是由network自己学到的。第三个gate叫做<strong>forget Gate</strong>，forget Gate决定什么时候memory cell要把过去记得的东西“忘掉”，即将memory存的值清0再去存新的值，当然forget Gate何时把存在memory的值忘掉，也是由network自己学到的。</p><p>那整个LSTM你可以看成，它有<strong>四个input 1个output</strong>，这四个input中，一个是想要被存在memory cell的值(但它不一定存的进去)还有操控input Gate的讯号，操控output Gate的讯号，操控forget Gate的讯号，最终只会得到一个output。</p><p>（冷知识：这个“-”应该在short-term中间，是长时间的短期记忆。想想我们之前看的Recurrent Neural Network，它的memory在每一个时间点都会被洗掉，只要有新的input进来，每一个时间点都会把memory 洗掉，所以的short-term是非常short的，但如果是Long Short-term Memory，它记得会比较久一点(只要forget Gate不要决定要忘记，它的值就会被存起来。)</p><p>下面来跟详细地看一下LSTM的memory cell的formulation。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200720232803.png" style="zoom:80%;"></p><p>假设要被存到cell的input是z，input gate的输入叫做$z_i$（一个scalar），forget gate的输入叫做$z_f$，output gate的输入叫做$z_o$，得到的output 记为$a$。假设cell里面有这四个输入之前，它里面已经存了值$c$。</p><p>假设要输入的部分为$z$，那三个gate分别是由$z_i,z_f,z_0$所操控的，<strong>每个gate里是activation function，通常会选择sigmoid function</strong>，选择sigmoid function的意义是它的值是介在0到1之间的。这个0到1之间的值代表了这个gate被打开的程度(如果这个f的output是1，表示为被打开的状态，反之代表这个gate是关起来的)。</p><p>z通过activation function得到$g(z)$，$z_i$通过input Gate的activation function得到$f(z_i)$，把$g(z)$乘以$f(z_i)$得到$g(z)f(z_i)$，$z_f$通过forget Gate的sigmoid function得到$f(z_f)$。接下来把存到memory里面的值$c$乘以$f(z_f)$得到$cf(z_f)$，然后加起来$c’=g(z)f(z_i)+cf(z_f)$，那么$c’$就是重新存到memory里面的值。</p><p>所以根据目前的运算，$f(z_i)$会cortrol$g(z)$可不可以make snese，假设$f(z_i)$为0，那$g(z)f(z_i)$就等于0，那$g(z)$就没什么用了，如果$f(z_i)$f等于1，就相当于是把$g(z)$当做输入) 。而$f(z_f)$则会决定要不要把存在memory的值洗掉，假设$f(z_f)$为1(forget gate 开启的时候)，这时$c$还会被记得，如果$f(z_f)$等于0(forget gate关闭的时候)，$cf(z_f)$等于0，原来的$c$相当于被洗掉了。然后把这个两个值加起来$c’=g(z)f(z_i)+cf(z_f)$。（forget gate的开关跟我们的直觉有些相反，那这个forget gate打开的时候代表的是记得，关闭的时候代表的是遗忘）。</p><p>$c’$通过另一个avtivation function得到$h(c’)$，将$h(c’)$乘以$f(z_o)$得到$a = h(c’)f(z_o)$，output gate受$f(z_o)$control，$f(z_o)$等于1的话，就说明$h(c’)$能通过，$f(z_o)$等于0的话，说明memory里面存在的值没有办法通过output gate被读取出来。</p><h4 id="3-2-LSTM-Example"><a href="#3-2-LSTM-Example" class="headerlink" title="3.2 LSTM - Example"></a>3.2 LSTM - Example</h4><p>下面通过一个例子来更直观地理解LSTM。假设我们的network里面只有一个LSTM的cell，input都是三维的vector，output都是一维的。三维的vector跟output还有memory的关系是：</p><ul><li>当第二个dimension $x_2$的值是1时，$x_1$的值就会被add到memory里；</li><li>当$x_2$的值是-1时，就会reset the memory;</li><li>当$x_3$的值为1时，才会把memory中的值output出来。</li></ul><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200720232807.png" style="zoom:80%;"></p><p>假设我们原来存到memory里面的值是0，当第二个input的$x_2$值是1，3会被存到memory里面去。第四个输入的$x_2$等于1，所以4会被add到memory里面去，memory中存的值变为7。第六个输入的$x_3$等于1，这时memory中的7会被输出。第七个dimension的$x_2$的值为-1，memory里面的值会被洗掉变为0。第八个dimension的$x_2$的值为1，所以把6存进去，下一个input的$x_3$的值为1，所以把6输出。</p><p>那接下来我们做一下实际的运算。下图是一个memory cell。cell的四个input是由：input的三维vector和bias（$x_1,x_2,x_3,1$）乘以不同的四组权重得到$z,z_i,z_f,z_o$，</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200722194341.png" style="zoom:80%;"></p><p>这些权重和bias用train data通过Gradient Descent的方式训练得到的。 这里假设我们已经知道这些值是多少了，并且假设$g(z)=z$和$h(c’)=c’$，三个Gate都是sigmoid function，memory中的$c$的初始值为0。</p><p>我们先来大致分析一下这个LSTM cell在运算时会发生什么。对于$z$，$x_1$乘以1，其他的元素乘以0，那就是直接把$x_1$当做输入。在input gate时，$x_2$乘以100，bias乘以-10，$x_2$值很小时，通常input gate是关闭的，若$x_2$的值较大，如大于1，$z_i$会是一个正值，代表input gate会被打开 。forget gate通常是会被打开的，既它平常会一直记得东西，只有当$x_2$的值为一个很大的负值时，$f(z_f)$接近0，才会把forget gate关起来。output gate平常是被关闭的，因为bias项乘-1得到一个很大的负值，那当$x_3$是一个很大的正值时，output Gate会打开。</p><p>那给定一组input sequence会得到什么样的输出呢，我们一步一步来看。</p><p><strong>（1）</strong> $\begin{bmatrix} x_1&amp;x_2&amp;x_3\end{bmatrix}^T=\begin{bmatrix} 3&amp; 1&amp; 0\end{bmatrix}^T$</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200722194400.png" style="zoom: 67%;"></p><p>$z=\begin{bmatrix}1 &amp;0&amp;0&amp;0\end{bmatrix}\cdot\begin{bmatrix} x_1\\x_2\\x_3\\1\end{bmatrix}=\begin{bmatrix}1 &amp;0&amp;0&amp;0\end{bmatrix}\cdot\begin{bmatrix} 3\\1\\0\\1\end{bmatrix} =3$；$g(z)=z=3$；</p><p>$z_i=\begin{bmatrix}0 &amp; 100 &amp;0 &amp; -10\end{bmatrix}\cdot\begin{bmatrix} x_1\\x_2\\x_3\\1\end{bmatrix}=\begin{bmatrix}0 &amp; 100 &amp;0 &amp; -10\end{bmatrix}\cdot\begin{bmatrix} 3\\1\\0\\1\end{bmatrix} =90$；$f(z_i)=\sigma(90)\approx1$；</p><p>$z_f=\begin{bmatrix}0 &amp; 100 &amp;0 &amp; 10\end{bmatrix}\cdot\begin{bmatrix} x_1\\x_2\\x_3\\1\end{bmatrix}=\begin{bmatrix}0 &amp; 100 &amp;0 &amp; 10\end{bmatrix}\cdot\begin{bmatrix} 3\\1\\0\\1\end{bmatrix} =110$；$f(z_f)=\sigma(110)\approx1$；</p><p>Memory：$c’=g(z)f(z_i)+cf(z_f)=3\cdot1+0\cdot1=3$；$h(c’)=c’=3$；</p><p>$z_o=\begin{bmatrix}0 &amp; 0 &amp;100 &amp; -10\end{bmatrix}\cdot\begin{bmatrix} x_1\\x_2\\x_3\\1\end{bmatrix}=\begin{bmatrix}0 &amp; 0 &amp; 100 &amp; -10\end{bmatrix}\cdot\begin{bmatrix} 3\\1\\0\\1\end{bmatrix} =-10$；$f(z_f)=\sigma(-10)\approx 0$；</p><p>Output：$a = h(c’)f(z_o)=3\cdot 0=0$</p><p><strong>（2）</strong>$\begin{bmatrix} x_1&amp;x_2&amp;x_3\end{bmatrix}^T=\begin{bmatrix} 4&amp; 1&amp; 0\end{bmatrix}^T$</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200722194404.png" style="zoom: 67%;"></p><p>$z=\begin{bmatrix}1 &amp;0&amp;0&amp;0\end{bmatrix}\cdot\begin{bmatrix} x_1\\x_2\\x_3\\1\end{bmatrix}=\begin{bmatrix}1 &amp;0&amp;0&amp;0\end{bmatrix}\cdot\begin{bmatrix} 4\\1\\0\\1\end{bmatrix} =4$；$g(z)=z=4$；</p><p>$z_i=\begin{bmatrix}0 &amp; 100 &amp;0 &amp; -10\end{bmatrix}\cdot\begin{bmatrix} x_1\\x_2\\x_3\\1\end{bmatrix}=\begin{bmatrix}0 &amp; 100 &amp;0 &amp; -10\end{bmatrix}\cdot\begin{bmatrix} 4\\1\\0\\1\end{bmatrix} =90$；$f(z_i)=\sigma(90)\approx1$；</p><p>$z_f=\begin{bmatrix}0 &amp; 100 &amp;0 &amp; 10\end{bmatrix}\cdot\begin{bmatrix} x_1\\x_2\\x_3\\1\end{bmatrix}=\begin{bmatrix}0 &amp; 100 &amp;0 &amp; 10\end{bmatrix}\cdot\begin{bmatrix} 4\\1\\0\\1\end{bmatrix} =110$；$f(z_f)=\sigma(110)\approx1$；</p><p>Memory：$c’=g(z)f(z_i)+cf(z_f)=4\cdot1+3\cdot1=7$；$h(c’)=c’=7$；</p><p>$z_o=\begin{bmatrix}0 &amp; 0 &amp;100 &amp; -10\end{bmatrix}\cdot\begin{bmatrix} x_1\\x_2\\x_3\\1\end{bmatrix}=\begin{bmatrix}0 &amp; 0 &amp; 100 &amp; -10\end{bmatrix}\cdot\begin{bmatrix} 4\\1\\0\\1\end{bmatrix} =-10$；$f(z_f)=\sigma(-10)\approx 0$；</p><p>Output：$a = h(c’)f(z_o)=7\cdot 0=0$</p><p><strong>（3）</strong>$\begin{bmatrix} x_1&amp;x_2&amp;x_3\end{bmatrix}^T=\begin{bmatrix} 2&amp; 0&amp; 0\end{bmatrix}^T$</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200722194408.png" style="zoom:67%;"></p><p>$z=\begin{bmatrix}1 &amp;0&amp;0&amp;0\end{bmatrix}\cdot\begin{bmatrix} x_1\\x_2\\x_3\\1\end{bmatrix}=\begin{bmatrix}1 &amp;0&amp;0&amp;0\end{bmatrix}\cdot\begin{bmatrix} 2\\0\\0\\1\end{bmatrix} =2$；$g(z)=z=2$；</p><p>$z_i=\begin{bmatrix}0 &amp; 100 &amp;0 &amp; -10\end{bmatrix}\cdot\begin{bmatrix} x_1\\x_2\\x_3\\1\end{bmatrix}=\begin{bmatrix}0 &amp; 100 &amp;0 &amp; -10\end{bmatrix}\cdot\begin{bmatrix} 2\\0\\0\\1\end{bmatrix} =-10$；$f(z_i)=\sigma(-10)\approx 0$；</p><p>$z_f=\begin{bmatrix}0 &amp; 100 &amp;0 &amp; 10\end{bmatrix}\cdot\begin{bmatrix} x_1\\x_2\\x_3\\1\end{bmatrix}=\begin{bmatrix}0 &amp; 100 &amp;0 &amp; 10\end{bmatrix}\cdot\begin{bmatrix} 2\\0\\0\\1\end{bmatrix} =10$；$f(z_f)=\sigma(10)\approx1$；</p><p>Memory：$c’=g(z)f(z_i)+cf(z_f)=2 \cdot 0 + 7 \cdot 1=7$；$h(c’)=c’=7$；</p><p>$z_o=\begin{bmatrix}0 &amp; 0 &amp;100 &amp; -10\end{bmatrix}\cdot\begin{bmatrix} x_1\\x_2\\x_3\\1\end{bmatrix}=\begin{bmatrix}0 &amp; 0 &amp; 100 &amp; -10\end{bmatrix}\cdot\begin{bmatrix} 2 \\ 0 \\0 \\1\end{bmatrix} =-10$；$f(z_f)=\sigma(-10)\approx 0$；</p><p>Output：$a = h(c’)f(z_o)=7\cdot 0=0$</p><p><strong>（4）</strong>$\begin{bmatrix} x_1&amp;x_2&amp;x_3\end{bmatrix}^T=\begin{bmatrix} 1&amp; 0&amp; 1\end{bmatrix}^T$</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200722194412.png" style="zoom:67%;"></p><p>$z=\begin{bmatrix}1 &amp;0&amp;0&amp;0\end{bmatrix}\cdot\begin{bmatrix} x_1\\x_2\\x_3\\1\end{bmatrix}=\begin{bmatrix}1 &amp;0&amp;0&amp;0\end{bmatrix}\cdot\begin{bmatrix} 1 \\0 \\1\\1\end{bmatrix} =1$；$g(z)=z=1$；</p><p>$z_i=\begin{bmatrix}0 &amp; 100 &amp;0 &amp; -10\end{bmatrix}\cdot\begin{bmatrix} x_1\\x_2\\x_3\\1\end{bmatrix}=\begin{bmatrix}0 &amp; 100 &amp;0 &amp; -10\end{bmatrix}\cdot\begin{bmatrix} 1 \\0 \\1 \\1\end{bmatrix} =-10$；$f(z_i)=\sigma(-10)\approx 0$；</p><p>$z_f=\begin{bmatrix}0 &amp; 100 &amp;0 &amp; 10\end{bmatrix}\cdot\begin{bmatrix} x_1\\x_2\\x_3\\1\end{bmatrix}=\begin{bmatrix}0 &amp; 100 &amp;0 &amp; 10\end{bmatrix}\cdot\begin{bmatrix} 1\\0\\1\\1\end{bmatrix} =10$；$f(z_f)=\sigma(10)\approx1$；</p><p>Memory：$c’=g(z)f(z_i)+cf(z_f)=1 \cdot 0 + 7 \cdot 1=7$；$h(c’)=c’=7$；</p><p>$z_o=\begin{bmatrix}0 &amp; 0 &amp;100 &amp; -10\end{bmatrix}\cdot\begin{bmatrix} x_1\\x_2\\x_3\\1\end{bmatrix}=\begin{bmatrix}0 &amp; 0 &amp; 100 &amp; -10\end{bmatrix}\cdot\begin{bmatrix} 1 \\ 0 \\1 \\1\end{bmatrix} =90$；$f(z_f)=\sigma(90)\approx 1$；</p><p>Output：$a = h(c’)f(z_o)=7\cdot 1= 7$</p><p><strong>（5）</strong>$\begin{bmatrix} x_1&amp;x_2&amp;x_3\end{bmatrix}^T=\begin{bmatrix} 3&amp; -1&amp; 0\end{bmatrix}^T$</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200722194416.png" style="zoom:67%;"></p><p>$z=\begin{bmatrix}1 &amp;0&amp;0&amp;0\end{bmatrix}\cdot\begin{bmatrix} x_1\\x_2\\x_3\\1\end{bmatrix}=\begin{bmatrix}1 &amp;0&amp;0&amp;0\end{bmatrix}\cdot\begin{bmatrix} 3 \-1 \\0\\1\end{bmatrix} =3$；$g(z)=z=3$；</p><p>$z_i=\begin{bmatrix}0 &amp; 100 &amp;0 &amp; -10\end{bmatrix}\cdot\begin{bmatrix} x_1\\x_2\\x_3\\1\end{bmatrix}=\begin{bmatrix}0 &amp; 100 &amp;0 &amp; -10\end{bmatrix}\cdot\begin{bmatrix} 3 \-1 \\0 \\1\end{bmatrix} =-110$；$f(z_i)=\sigma(-110)\approx 0$；</p><p>$z_f=\begin{bmatrix}0 &amp; 100 &amp;0 &amp; 10\end{bmatrix}\cdot\begin{bmatrix} x_1\\x_2\\x_3\\1\end{bmatrix}=\begin{bmatrix}0 &amp; 100 &amp;0 &amp; 10\end{bmatrix}\cdot\begin{bmatrix} 3 \-1 \\0\\1\end{bmatrix} =-90$；$f(z_f)=\sigma(-90)\approx 0$；</p><p>Memory：$c’=g(z)f(z_i)+cf(z_f)=3 \cdot 0 + 7 \cdot 0=0$；$h(c’)=c’=0$；</p><p>$z_o=\begin{bmatrix}0 &amp; 0 &amp;100 &amp; -10\end{bmatrix}\cdot\begin{bmatrix} x_1\\x_2\\x_3\\1\end{bmatrix}=\begin{bmatrix}0 &amp; 0 &amp; 100 &amp; -10\end{bmatrix}\cdot\begin{bmatrix} 3 \-1 \\0 \\1\end{bmatrix} =-10$；$f(z_f)=\sigma(-10)\approx 0$；</p><p>Output：$a = h(c’)f(z_o)=0\cdot 0= 0$</p><p>所以最终得到的output sequence为：$0,0,0,7,0$</p><h4 id="3-3-Replace-the-neurons-with-LSTM"><a href="#3-3-Replace-the-neurons-with-LSTM" class="headerlink" title="3.3 Replace the neurons with LSTM"></a>3.3 Replace the neurons with LSTM</h4><p>到这里你可能会想这个LSTM跟我们的neural network有什么样的关系呢[・ヘ・?]。可以这样来理解，在原来的neural network里会有很多的neuron，我们把input乘以不同的weight当做不同neuron的输入，每一个neuron都是一个function，输入一个值然后输出一个值。但是如果是LSTM的话，其实你只要把这一整个memory cell当成是一个neuron就好了。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200722194421.png" style="zoom: 67%;"></p><p>你做的事情其实就是原来简单的neuron换成LSTM，现在的input($x_1,x_2$)会乘以不同的weight当做LSTM的输入(假设我们这个hidden layer只有两个neuron)。input($x_1,x_2$)会乘以不同的weight当做底下的input $z$，乘以不同的weight操控input gate，乘以不同的weigh去操控forget gate，乘以不同的weight会去操控output gate。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200722221027.png" style="zoom:67%;"></p><p>在原来的neural network里每个neuron是有一个input一个output。而LSTM有四个input和一个output，对于LSTM来说，这四个input是不一样的。所以LSTM需要的参数量(假设你现在用的neural的数目跟LSTM是一样的)是一般neural network的四倍。</p><p>那这个LSTM跟Recurrent Neural Network的关系是什么呢，借助下面的图来理解一下。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200722221031.png" style="zoom: 80%;"></p><p>假设我们现在有一整排的LSTM cell，这些LSTM里面的memory都存了一个值，把所有的值接起来就变成了vector，写为 $c^{t-1}$。在时刻t，input一个vector $x^t$，这个vector首先会乘上一matrix，即经过一个linear transform变成一个vector $z$，$z$的dimension等于LSTM cell的数目，其中每一个元素分别是一个个cell的“底下”的input $z$。</p><p>同样的道理，$x^t$会乘上另外的一个transform得到$z^i$，然后这个$z^i$zi的dimension也跟cell的数目一样，$z^i$的每一个dimension会分别去操控这些cell的input gate，forget gate 跟output gate也都是一样的道理。所以我们把$x^t$乘以四个不同的transform得到四个不同的vector $z^f,z^i,z,z^o$，四个vector的dimension跟cell的数目一样，这四个vector合起来就会去操控这些memory cell运算（上小节中讲到的运算过程中的$z,z_i,z_f,z_o$是scalar，现在换成vector即可完成下图中的运算）。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200722221035.png" style="zoom: 80%;"></p><p>经过这一轮运算后memory中存放的是$c^t$，输出$y^t$，将这个process反复的进行，在下一个时间点input $x^{t+1}$，把$f(z)$跟input gate相乘，把forget gate跟存在memory里面的值相乘，然后将前面两个值再相加起来，在乘上output gate的值，然后得到下一个时间点的输出$y^{t+1}$。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200722221039.png" style="zoom:80%;"></p><p>但是这远远不是LSTM的最终形态 ∑(ﾟДﾟノ)ノ，LSTM会把上一个时间的$h^t$接进下一个时间的input，也就说下一个时间点操控这些gate的值不是只看input $x^{t+1}$，还看前一个时间点的$h^t$。LSTM还可以把上一时间的存在memory cell的值$c^t$接进下一时间的input，这叫做“peephole”，这样就同时考虑了$x^{t+1},h^t,c^t$，把这三个vector合在一起乘上不同的transform得到四个不同的vector再放进LSTM中运算。</p><p>当然LSTM也可以有很多层，即Multiple-layer LSTM。目前人们使用RNN，通常就是在用LSTM。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200722224341.png" style="zoom: 80%;"></p><p>Keras支持三种RNN：LSTM，GRU，SimpleRNN。GRU是LSTM稍微简化的版本，它只有两个gate，虽然少了一个gate，但是performance跟LSTM差不多，少了1/3的参数，比较不容易overfitting。文章第二节中讲的那种RNN就是simple RNN。</p><h3 id="4-How-to-train-RNN"><a href="#4-How-to-train-RNN" class="headerlink" title="4. How to train RNN"></a>4. How to train RNN</h3><h4 id="4-1-BPTT"><a href="#4-1-BPTT" class="headerlink" title="4.1 BPTT"></a>4.1 BPTT</h4><p>那如何训练一个RNN model呢，我们之前讲过如果要做learning的话，要定义一个cost function来evaluate model的好坏，选一个parameter让loss 最小。那在Recurrent Neural Network里面，要怎么定义这个loss呢，下面先举个比价直观的例子。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200722230111.png" style="zoom:67%;"></p><p>假设现在要做的是Slot Filling，train data是给一些sentence，sentence的label是其中的每个word分别属于哪个Slot。比如上图中这歌Training Sentence，告诉machine第一个word它是属于other slot，“Taipei是”Destination slot,”on”属于other slot，“November”和“2nd”属于time slot，</p><p>然后把“arrive”输入到RNN，RNN会得到一个output $y^1$，接下来$y^1$会和它的reference vector（other这个Slot的vector）来计算cross entropy。可以这样来定义reference vector，其长度等于slot的数目，某一个slot对应的vector中某一个dimension为1，其余为0。那我们就希望输入”arrive”后得到的$y^1$与”other”对应的reference vector越接近越好。</p><p>对于training RNN要注意的事是，我们<strong>不能把sentence的word顺序打散后输入到RNN中</strong>，而必须<strong>要按照原来的sequence order输入到RNN中</strong>，因为sequence order会影响memory中存的值，进而影响output $y$。</p><p>RNN的损失函数，即output和reference vector的entropy的和，就是要最小化的对象。这里也是用梯度下降来做，有了定义好的loss function $L$，要update这个neural network里面的某个参数$w$，就是计算$L$对$w$的偏微分，偏微分计算出来以后，就用梯度下降的方法去update里面的参数。在讲feedforward neural network的时候，可以用一个有效率的求梯度的方法，即Backpropagation（反向传播）。那Recurrent Neural Network领域，有开发一套Backpropagation的进阶版，叫做<strong>Backpropagation through time（BPTT）</strong>。它跟Backpropagation是很类似的，只是RNN它是在high sequence上运作，所以BPTT要考虑时间上的information。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200722230119.png" style="zoom: 80%;"></p><h4 id="4-2-Difficulty-in-training-RNN"><a href="#4-2-Difficulty-in-training-RNN" class="headerlink" title="4.2 Difficulty in training RNN"></a>4.2 Difficulty in training RNN</h4><p>不幸的是，RNN的training是比较困难的。一般在做training的时候，你会期待learning curve是像下图中蓝色这条线（纵轴是total loss，横轴是epoch的数目），即随着epoch的数目越来越多，随着参数不断的update，loss会慢慢的下降最后趋向收敛。但是不幸的是在训练Recurrent Neural Network的时候，你有时候会看到绿色这条线。如果是第一次train Recurrent Neural Network的人，看到绿色这条learning curve非常剧烈的抖动，到某个地方变成NaN，肯定会想这程序有bug啊(╬￣皿￣)。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200722230123.png" style="zoom:67%;"></p><p>Razvan分析了下RNN的性质，发现RNN的error surface的变化是非常陡峭的/崎岖的(error surface有一些地方非常的平坦，一些地方非常的陡峭，就像是悬崖峭壁一样)。这样会造成什么样的问题呢？假设橙色的点当做初始点，用Gradient Descent开始调整你的参数，updata参数时，可能会刚好跳过一个悬崖，这时loss会突然爆长，loss会非常上下剧烈的震荡)。更惨的情况是，如果在悬崖上之前的gradient会很小，那learning rate可能已经调的很大的，当下一步update时正好踩过悬崖，gradient爆长，很大的gradient乘上很大的learning rate结果参数就会update很多，参数就“飞”出去了。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200722230127.png" style="zoom:67%;"></p><p>作者是用工程的思想来解决了这个问题，这一招就是Clipping（当Gradient大于某一个threshold的时候，不要让它超过那个threshold，比如设定threshold为15，那当gradient大于15时，让gradient等于15。因为gradient不会太大，所以你要做Clipping的时候，就算是“踩着这个悬崖上”，也不飞出来，而是会updaye到一个比较近的地方，这样还可以继续做RNN的training。</p><p>为什么RNN会有这种奇特的特性呢。有人觉得是来自sigmoid function，我们之前讲Relu activation function的时候，讲过一个问题gradient vanish，这个问题是从sigmoid function来的，RNN会有很平滑的error surface是因为来自于gradient vanish，但其实问题并不是出在sigmoid function上，把RNN中的sigmoid function换成Relu， performance通常是比较差的，所以在train RNN时很少用Relu做activation function。</p><p>你应该会从BRTT的式子中更直观的看出为什么会有这个问题。当然也有更直观的方法来知道一个gradient的大小：把某一个参数做小小的变化，看它对network output的变化有多大，就可以估算出这个参数的gradient的大小。</p><p>举一个很简单的RNN例子，它只有一个neuron，这个neuron是linear。input没有bias，input的weight是1，output的weight也是1，transition的weight是w。也就是说从memory接到neuron的input的weight是w。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200722230131.png" style="zoom:67%;"></p><p>假设给neural network的input sequence是$1,0,0,0,\dots$，共1000个数，很容易计算出最后的output $y^{1000}$是$w^{999}$。现在假设$w$是要learn的参数，我们想要知道它的gradient，即当我们改变$w$的值时候，对neural的output有多大的影响。</p><p>现在假设$w=1$，那现在$y^{1000}=1$；当$w=1.01$时，$y^{1000}\approx 20000$，可见当$w \in (1, 1+\epsilon)$时，$w$有一点小小的变化，就会对output产生很大的影响，所以这时$w$有很大的gradient，那这时我们把learning rate设小一点就好了。</p><p>但当$w=0.99$时，那$y^{1000}\approx0$；把$w$做一个较大的变化，设$w=0.01$，则有$y^{1000}\approx0$。可见当$w\in(0,1-\epsilon)$时，gradient就突然变得非常非常的小，这个时候我们就需要一个很大的learning rate。这种gradient的突变，使得error surface很崎岖，设置learning rate很麻烦。</p><p>从这个例子可以看出RNN training的问题其实来自它把同样的东西在transition的时候反复使用。$w$变化时，它完全可能没有造成任何影响，而一旦造成影响，影响都是“天崩地裂”的。所以<strong>RNN不好训练的原因是来自于它有high sequence，同样的weight在不同的时间点被反复的使用</strong>，而不是来自activation function。</p><h4 id="4-3-Helpful-Techniques-for-RNN"><a href="#4-3-Helpful-Techniques-for-RNN" class="headerlink" title="4.3 Helpful Techniques for RNN"></a>4.3 Helpful Techniques for RNN</h4><p>有什么技巧可以帮助我们解决这个问题呢？其实广泛被使用的技巧就是LSTM，LSTM可以让你的error surface不要那么崎岖。它可以做到的事情是，它会把那些平坦的地方拿掉，解决gradient vanish的问题，但不能解决gradient explode的问题。有些地方还是非常的崎岖的，有些地方仍然是变化非常剧烈的，但是不会有特别平坦的地方。做LSTM时，error surface大部分地方变化的很剧烈，所以你可以放心的把learning rate设置的小一点，保证在learning rate很小的情况下进行训练。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200722230135.png" style="zoom:67%;"></p><p>那为什么LSTM 可以解决梯度消失的问题，避免gradient特别小呢？RNN跟LSTM在面对memory的时候，它处理的操作其实是不一样的。在RNN里面，在每一个时间点，memory里面的值都是会被洗掉，neuron的output都要memory里面去，所以在每一个时间点，memory里面的值都是会被覆盖掉。但是在LSTM里面不一样，它是把原来memory里面的值乘上一个值再把input的值加起来放到cell里面。所以它的memory input是相加的。</p><p>所以LSTM和RNN不同的是，RNN在每个时间点的值都会被format掉，所以只要这个影响被format掉它就消失了。但是在LSTM里面，一旦对memory造成影响，那影响一直会被留着，memory一旦有改变，只会把新的东西加进来，不会把原来的值洗掉，除非forget gate要把memory的值洗掉，所以它不会有gradient vanishing的问题。</p><p>那你可能会想现在有forget gate，仍然会把memory的值洗掉。其实LSTM的第一个版本就是为了解决gradient vanishing的问题，所以它是没有forget gate，后来的版本中才加入了forget gate。甚至现在有个说法是：在训练LSTM的时候要给forget gate特别大的bias，你要确保forget gate在多数的情况下都是开启的（即不会洗掉memory），只要少数的情况是关闭的（洗掉memory）。</p><p>还有另外一个版本用gate操控memory cell，叫做Gates Recurrent Unit(GRU)，LSTM有三个Gate，而GRU有两个gate，所以GRU需要的参数是比较少的。因为它需要的参数量比较少，它在training时是比较鲁棒的。如果在train LSTM时，你觉得overfitting的情况很严重，不妨可以试下GRU。GRU的思想就是：“旧的不去，新的不来”。它会把input gate跟forget gate联动起来，当input gate打开的时候，forget gate会自动的关闭(format存在memory里面的值)，当forget gate没有要format里面的值（即forget gate开启），input gate就会被关起来，也就是说你要把memory里面的值清掉，才能把新的值放进来。</p><p>还有其他的technique可以handle gradient vanishing的问题。比如说clockwise RNN或者说是Structurally Constrained Recurrent Network (SCRN)等等。有一个蛮有趣的paper是这样的：一般的RNN用identity matrix（单位矩阵）来initialized transformation weight+ReLU activaton function它可以得到很好的performance。刚才不是说用ReLU的performance会比较拉胯，一般train的方法initiaed weight是random，那ReLU跟sigmoid function来比的话，sigmoid performance 会比较好。但是用了identity matrix来initialized的话，用ReLU performance会比较好。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200722230139.png" style="zoom: 67%;"></p><h3 id="5-More-Applications"><a href="#5-More-Applications" class="headerlink" title="5. More Applications"></a>5. More Applications</h3><p>RNN有很多的application，前面举得那个solt filling的例子中，我们假设input跟output的数目是一样的，我们给input中的每一个word一个slot label。其实RNN可以做到更复杂的事情。</p><p>（下面老师举的例子基本都是NLP领域的，我还了解甚少，所以只根据老师上课讲的内容作一些简单的介绍，可能会有些纰漏。而且老师2020年的课程内容跳跃性挺大的，需要结合2017年的ML课程一起看，RNN这节课中有些知识点是在之前的2017年课程里讲到的，我需要看过之后再来对这篇笔记做一个补充更新）</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200722230143.png" style="zoom:67%;"></p><h4 id="5-1-Many-to-one"><a href="#5-1-Many-to-one" class="headerlink" title="5.1. Many to one"></a>5.1. Many to one</h4><p>RNN可以做到更复杂的事情，比如说input是一个sequence，output是一个vector，这种Many to one 的常见的应用有<strong>sentiment analysis（情感分析）</strong>。sentiment analysis现在有很广泛的应用，比如某家公司想要知道，他们的产品在网上的评价是positive 还是negative。他们可能会写一个爬虫，把跟他们产品有关的文章都爬下来。那这一篇一篇的看太累了，所以你可以用一个machine learning 的方法learn一个classifier去分类哪些document的评价是正向的，哪些document是负向的。那你就可以去train一个Recurrent Neural Network，input是character sequence，然后RNN把这个sequence读过一遍，在最后一个时间点，把hidden layer拿出来，在通过几个transform，然后你就可以得到最后的sentiment analysis（这是一个分类的问题，但是因为input是sequence，所以用RNN来处理）。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723140734.png" style="zoom: 67%;"></p><p>还可以用RNN来作<strong>key term extraction（关键词抽取）</strong>。key term extraction意思是给machine看一个文章，machine要预测出这篇文章有哪些关键词。如果你能够收集到一些training data(一些document，这些document都有label，哪些词汇是关键词，那就可以直接train一个RNN)，RNN把document当做input，通过Embedding layer，然后用RNN把这个document读过一次，然后把出现在最后一个时间点的output拿过来做attention，你可以把这样的information抽出来再丢到feedforward neural network得到最后的output。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723140739.png" style="zoom:67%;"></p><h4 id="5-2-Many-to-Many"><a href="#5-2-Many-to-Many" class="headerlink" title="5.2. Many to Many"></a>5.2. Many to Many</h4><h5 id="5-2-1-Output-is-shorter-Speech-Recognition"><a href="#5-2-1-Output-is-shorter-Speech-Recognition" class="headerlink" title="5.2.1. Output is shorter - Speech Recognition"></a>5.2.1. Output is shorter - Speech Recognition</h5><p>RNN的输入输出也可以是多对多的，比如input和output都是sequence，但是output sequence比input sequence短的时候，RNN可以处理这个问题。<strong>Speech Recognition（语音辨识）</strong>就是这样input sequence长，output sequence短的问题。比如在语音辨识这个任务里面input是acoustic sequence(说一句话，这句话就是一段声音讯号)。一般处理声音讯号的方式是，在这个声音讯号里面，每隔一小段时间，就把它用vector来表示。这个一小段时间是很短的(比如说，0.01秒)，那output sequence是character sequence。</p><p>如果你是原来的simple RNN(slot filling的那个RNN)，把这一串input丢进去，它只能做到告诉你每一个vector对应到哪一个character。比如对于一个中文的语音辨识系统，那你的output target理论上就是这个世界上所有可能中文的词汇，常用的可能是八千个，那你RNN classifier的数目可能就是八千个。虽然很大，但也是有办法做的。但是充其量只能做到：每一个声音的vector会得到一个character。每一个input对应的时间间隔是很小的(0.01秒)，所以通常是好多个vector对应到同一个character，那对一句内容是“好棒”的语音，辨识结果可能为“好好好棒棒棒棒棒”，那这显然不是语音辨识正确的结果。为了解决这个问题有一招叫做“<strong>Trimming</strong>”(修剪，切除的意思，这里指把重复的东西拿掉)，就变成“好棒”。但这样也会有一个较严重的问题，因为它没有辨识一些有含义的叠词，比如“好棒棒”（老师说“好棒棒”是贬义的，好机车哦）。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723140743.png" style="zoom:67%;"></p><p>那要怎么把“好棒”跟“好棒棒”分开来呢，有一招叫做<strong>Connectionist temporal classification（CTC）</strong>，主要是解决神经网络label 和output 不对齐的问题（Alignment problem）。它的思想可以这样理解：在output时候不只是output所有中文的character，还会output一个符号，叫做”null””(没有任何东西)。所以我今天input一段acoustic feature sequence,它的output是“好 null null 棒 null null null null”，然后我就把“null”的部分拿掉，它就变成“好棒”。如果我们输入另外一个sequence，它的output是“好 null null 棒 null 棒 null null”，然后把“null”拿掉，所以它的output就是“好棒棒”。这样就可以解决叠字的问题了。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723140747.png" style="zoom:67%;"></p><p>CTC在做training的时候，你的train data就会告诉这一串acoustic features对应到这一串character sequence，但它不会告诉你说“好”是对应第几个character 到第几个character。这时可以穷举所有可能的alignments。简单来说就是，我们不知道“好”对应到那几个character，“棒”对应到哪几个character。假设我们所有的状况都是可能的。可能第一个是“好 null 棒 null null null”，可能是“好 null null 棒 null null”，也可能是“好 null null null 棒 null”。我们不知道哪个是对的，那假设全部都是对的。在training的时候，全部都当做是正确的，然后一起train。当然也有更巧妙的算法可以解决这个问题，这里就不细讲了。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723140751.png" style="zoom:67%;"></p><p>在做英文辨识的时候，你的RNN output target就是character(英文的字母+空白)。直接output字母，然后如果字和字之间有boundary，就自动有空白。看下面的例子，第一个frame是output h，第二个frame是output null，第三个frame是output null，第四个frame是output I等等。如果你看到output是这样子话，那最后把“null”的地方拿掉，那这句话的辨识结果就是“HIS FRIEND’S”。你不需要告诉machine说：”HIS”是一个词汇，“FRIEND’s”是一个词汇,machine通过training data会自己学到这件事情。</p><p>据说Google的语音辨识系统已经全面换成CTC。如果你用CTC来做语音辨识的话，就算是有某一个词汇(比如是：英文中人名，地名)在training data中从来没有出现过，machine也是有机会把它辨识出来。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723140756.png" style="zoom:67%;"></p><h5 id="5-2-2-No-limitation-Sequence-to-sequence-learning"><a href="#5-2-2-No-limitation-Sequence-to-sequence-learning" class="headerlink" title="5.2.2. No limitation - Sequence to sequence learning"></a>5.2.2. No limitation - Sequence to sequence learning</h5><p>RNN还有一个应用叫做<strong>sequence to sequence learning</strong>，在sequence to sequence learning里面，RNN的input跟output都是sequence(但是两者的长度是不一样的)。刚在在CTC时，input比较长，output比较短。在这边我们要考虑的是不确定input跟output谁比较长谁比较短。</p><p>比如做machine translation（机器翻译），input英文word sequence把它翻译成中文的character sequence。那我们并不知道说，英文跟中文谁比较长谁比较短(有可能是output比较长，output比较短)。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723140801.png" style="zoom:67%;"></p><p>假如现在input一个 “machine learning” ，然后用RNN读过去，然后在最后一个时间点，这个memory里面就存了所有input sequence的information。接下来你让machine “吐”一个character(机)，然后就让它output下一个character，把之前的output出来的character当做input，再把memory里面的值读进来，它就会output “器”。那这个“机”怎么接到这个地方呢，有很多支支节节的技巧，还有很多不同的变形。在下一个时间input “器”，output“学”，然后output“习”，然后一直output下去，machine没办法知道它何时要停下来。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723140804.png" style="zoom:67%;"></p><p>要怎么告诉machine何时停止呢？你可以多加一个symbol “===”，代表停止，那现在manchine不只是output可能的character，它还有一个可能的output 是“===”。这样我们的utput sequence中“习”后面是“===”(断)的话，就停下来了。那这中方法也是可以train的起来的。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723140814.png" style="zoom:67%;"></p><p>还有篇papre是这样做的，对于sequence to sequence learning，我们原来是input 某种语言的文字，output是翻译成另外一种语言的文字(假设是做机器翻译的话)。那我们有没有可能直接input某种语言的声音讯号，output另外一种语言的文字呢？我们完全不做语音辨识。比如说你要把英文句子的语音翻译成中文句子的文本，你就可以收集一大堆英文句子的语音，以及它对应的中文翻译，完全不要做语音辨识，直接把英文的声音讯号丢到这个model里面去，看它能不能output正确的中文。这一招居然是行得通的。假设你今天要把台语转成英文，但是台语的语音辨识系统不好做，因为台语根本就没有standard文字系统，所以这项技术可以成功的话，未来你在训练台语转英文语音辨识系统的时候，你只需要收集台语的声音讯号跟它的英文翻译就可以刻了。你就不需要台语语音辨识的结果，你也不需要知道台语的文字，也可以做这件事。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723140819.png" style="zoom:67%;"></p><p><strong>Beyond Sequence</strong></p><p>利用sequence to sequence的技术，甚至可以做到Beyond Sequence。这个技术也被用到<strong>syntactic parsing（句法分析）</strong>。synthetic parsing是指，让machine看一个句子，它要得到这个句子的结构树，得到一个树状的结构。过去你可能要用structured learning的技术能够解这个问题，但是现在有了 sequence to sequence learning的技术以后，只要把这个树状图描述成一个sequence（具体看图中 john has a dog）。你就可以直接learn 一个sequence to sequence model，它的output就是syntactic parsing tree。这个是可以train的起来的，performance也很好。你可能会担心machine的output的sequence不符合文法结构，比如它记得加左括号，却忘记加右括号，神奇的地方就是LSTM不会忘记右括号。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723140823.png" style="zoom:67%;"></p><p><strong>Sequence - to - sequence    Auto - encoder - Text</strong></p><p>当我们要将一个document表示成一个vector时，往往会用bag-of-word的方法，用这个方法的时候，往往会忽略掉 word order information。举例来说，有一个word sequence是“white blood cells destroying an infection”，另外一个word sequence是：“an infection destroying white blood cells”，这两句话的意思完全是相反的。但是用bag-of-word的方法来描述的话，它们的bag-of-word完全是一样的。虽然这两个word sequence里面有完全一摸一样的六个词汇，但因为词汇的order是不一样的，所以他们的意思一个变成positive，一个变成negative，它们的意思是很不一样的。那现在我们可以用sequence to sequence Auto-encoder这种做法来考虑word sequence order的情况下，把一个document变成一个vector。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723140828.png" style="zoom:67%;"></p><p>我们可以input一个word sequence，通过Recurrent Neural Network变成一个invalid vector，然后把这个invalid vector当做decoder的输入，然后让这个decoder，找回一模一样的句子。如果今天Recurrent Neural Network可以做到这件事情的话，那Encoding这个vector就代表这个input sequence里面重要的information。在trian Sequence-to-sequence Auto-encoder的时候，不需要label data，你只需要收集大量的文章，然后直接train下去就好了。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723172010.png" style="zoom:67%;"></p><p>Sequence-to-sequence 还有另外一个版本叫skip thought，如果用Sequence-to-sequence的，输入输出都是同一个句子，如果用skip thought的话，输出的目标就会是下一个句子，用sequence-to-sequence得到的结果通常容易表达，如果要得到语义的意思的，那么skip thought会得到比较好的结果。这个结构甚至可以是hierarchical，每一个句子都先得到一个vector（Mary was hungry得到一个vector，she didn’t find any food得到一个vector），然后把这些vector加起来，然后变成一个整个 document high label vector，在让这整个vector去产生一串sentence vector，在根据每一个sentence vector再去解回word sequence。这是一个四层的LSTM(从word 变成sentence sequence ，变成document lable，再解回sentence sequence，再解回word sequence。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723172010.png" style="zoom:67%;"></p><p><strong>Sequence - to - sequence    Auto - encoder - Speech</strong></p><p>这种Sequence to sequence  Auto encoder的方法也可以用到语音上，在语音上，它可以把一段audio segment变成一个fixed length vector。比如说，左边有一段声音讯号，长长短短都不一样，那你把他们变成vector的话，可能dog跟dogs比较接近，never和ever比较接近，可以称之为audio auto vector。一般的auto vector它是把word变成vector，这里是把一段声音讯号变成一个vector。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723172015.png" style="zoom:67%;"></p><p>这个东西有什么用呢？它可以做很多的事。比如可以拿来做语音的搜寻，假设你有一个声音的data base(比如说，上课的录音，你想要找跟美国白宫有关的东西，然后你说一句话-“美国白宫”，machine不需要做语音辨识，直接比对声音讯号的相似度，machine就可以从data base里面把提到“美国白宫”的部分找出来)。它的实现过程可以是这样的：你先把一个audio data base做segmentation，切成一段一段的。然后每一个段用刚才讲的audio segment to vector这个技术，通通变成vector。然后现再输入一个spoken query，可以通过audio segment to vector技术也变成vector，接下来计算它们的相似程度，找出最相似的就是要搜寻的结果。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723172019.png" style="zoom:67%;"></p><p>那么如何把一个audio segment变成一个vector呢？把audio segment抽成acoustic features，然后把它输入到RNN里面去，这个RNN的角色就是Encoder，它读过acoustic features之后，最后一个时间点它存在memory里面的值就代表了input声音讯号的information。它存到memory里面的值是一个vector，这个其实就是我们要拿来表示整段声音讯号的vector。</p><p>但是只要RNN Encoder没有办法去train，同时你还要train一个RNN Decoder。Decoder的作用是把Encoder得到的值存到memory里面的值，拿进来当做input，然后产生一个acoustic features sequence。然后希望这个$y_1$跟$x_1$越接近越好。然后再根据$y_1$产生$y_2$，以此类推。今天训练的target$y_1,y_2,y_3,y_4$跟$x_1,x_2,x_3,x_4$越接近越好。在训练的时候，RNN Encoder跟RNN Decoder是一起train的。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723172023.png" style="zoom:67%;"></p><p>我们在实验上得到一些有趣的结果，下图中的每个点其实都是一段声音讯号，你把声音讯号用刚才讲的 Sequence-to-sequence Auto-encoder技术变成平面上一个vector。发现说：fear这个位置在左上角，near的位置在右下角，他们中间这样的关系(fame在左上角，name在右下角)。发现把fear的开头f换成n，跟fame的开头f换成n，它们的word vector的变化方向是一样的。现在这个技术还没有把语义加进去。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723172031.png" style="zoom:67%;"></p><p>我们可以用Sequence-to-sequence Auto-encoder来做很多有意思的工作，比如训练一个chat-bot(聊天机器人)。你可以收集很多的对话，比如说电影的台词，在电影中有一个台词是“How are you”，另外一个人接“I am fine”。那就告诉machine说这个sequence to sequence learning当它input是“How are you”的时候，这个model的output就要是“I am fine”。你可以收集到这种data，然后就让machine去 train。这里我们就收集了四万句和美国总统辩论的句子，然后让machine去学这个sequence to sequence这个model。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723172035.png" style="zoom:67%;"></p><h4 id="5-3-Attention-based-Model"><a href="#5-3-Attention-based-Model" class="headerlink" title="5.3. Attention - based Model"></a>5.3. Attention - based Model</h4><p>现在除了RNN以外，还有另外一种有用到memory的network，叫做<strong>Attention-based Model</strong>（基于注意力的模型），这个可以想成是RNN的进阶的版本。我们知道人的大脑有非常强的记忆力，所以你可以记得非常非常多的东西。比如说，你现在同时记得早餐吃了什么，同时记得10年前夏天发生的事，同时记得在这几门课中学到的东西。那当然有人问你说什么是deep learning的时候，那你的脑中会去提取重要的information，然后再把这些information组织起来，产生答案。但是你的脑中会自动忽略那些无关的事情，比如说，10年前夏天发生的事情等等。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723174945.png" style="zoom:67%;"></p><p>其实machine也可以做到类似的事情，machine也可以有很大的记忆的容量。它可以有很大的data base，在这个data base里面，每一个vector就代表了某种information被存在machine的记忆里面。当你输入一个input的时候，这个input会被丢进一个中央处理器，这个中央处理器可能是一个DNN/RNN，那这个中央处理器会操控一个Reading Head Controller，这个Reading Head Controller会去决定这个reading head放的位置。machine再从这个reading head 的位置去读取information，然后产生最后的output。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723174950.png" style="zoom:67%;"></p><p>这个model还有一个2.0的版本，它会去操控writing head controller。这个writing head controller会去决定writing head 放的位置。然后machine会去把它的information通过这个writing head写进它的data base里面。所以，它不仅有读的功能，还可以discover出来的东西写入它的memory里面去。这个就是大名鼎鼎的<strong>Neural Turing Machine（神经图灵机）</strong>。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723174954.png" style="zoom:67%;"></p><p><strong>Reading Comprehension</strong></p><p>Attention-based Model 常常用在<strong>Reading Comprehension（阅读理解）</strong>里面。所谓Reading Comprehension就是让machine读一堆document，然后把这些document里面的内容(每一句话)变成一个vector。每一个vector就代表了每一句话的语义。比如你现在想问machine一个问题，然后这个问题被丢进中央处理器里面，那这个中央处理器去控制一个reading head controller，去决定现在在这个data base里面哪些句子是跟中央处理器有关的。假设machine发现这个句子是跟现在的问题是有关的，就把reading head放到这个地方，把information 读到中央处理器中。读取information这个过程可以是重复数次,也就是说machine并不会从一个地方读取information，它先从这里读取information以后，它还可以换一个位置读取information。它把所有读到的information收集起来，最后给你一个最终的答案。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723174958.png" style="zoom:67%;"></p><p>下图是在baby corpus上的结果，baby corpus是一个Q&amp;A的一个简单的测试。我们需要做的事就是读过这五个句子，然后说：what color is Grey?，得到正确的答案。那你可以从machine attention的位置(也就是reading head 的位置)看出machine的思路。图中蓝色代表了machine reading head 的位置，Hop1，Hop2，Hop3代表的是时间，在第一个时间点，machine先把它的reading head放在“greg is a frog”，把这个information提取出来。接下来提取“brian is a frog” information ，再提取“brian is yellow”information。最后它得到结论说：greg 的颜色是yellow。这些事情是machine自动learn出来的，machine attention在哪个位置，这些通过neural network学到该怎么做，要先看哪个句子，再看哪个句子，这些都是machine自动去决定的。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723175909.png" style="zoom:67%;"></p><p><strong>Visual Question Answering</strong></p><p>Attention-Based model也可以做<strong>Visual Question Answering（VQA）</strong>，比如让machine看下面的那张图片，问它这是什么，要它可以正确回答说是香蕉。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723175915.png" style="zoom:67%;"></p><p>这个Visual Question Answering可以这样来实现：先让machine看一张图，然后通过CNN你可以把这张图的一小块region用一小块的vector来表示。接下来，输入一个query，这个query被丢到中央处理器中，这个中央处理器去操控reading head controller，这个reading head controller决定读取的位置（是跟现在输入的问题是有关系的），这个读取的process可能要好几个步骤，machine会分好几次把information读到中央处理器，最后得到答案。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723175920.png" style="zoom:67%;"></p><p><strong>Speech Question Answering</strong></p><p>Attention-Based model也可以做Speech Question Answering 。比如说：在语音处理实验上我们让machine做TOEFL Listening Comprehension Test 。让machine听一段声音，然后问它问题，从四个选项里面，machine选择出正确的选项，那machine做的事情其实是跟人类考生做的是一样的。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723175924.png" style="zoom:67%;"></p><p>那用的Model Architecture跟我们上面讲到的其实大同小异，你让machine先读一个question，然后把question做语义的分析得到question的语义，声音的部分是让语音辨识先转成文字，在把这些文字做语义的分析，得到这段文字的语义。那machine了解question的语义然后就可以做attention，决定在audio story里面哪些部分是回答问题有关的。这就像画重点一样，machine画的重点就是答案，它也可以回头去修正它产生的答案。经过几个process以后，machine最后得到的答案跟其他几个选项计算相似度，然后看哪一个想项的相似度最高，它就选那一个选项。那整个test就是一个大的neural network，语音辨识，question semantic部分和audio semantic部分都是neural network，它们都是可以训练的。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723175929.png" style="zoom:67%;"></p><p>下图是五种naive的方法得到的结果方法，也就是完全不管文章的内容，直接看问题跟选项就猜答案。random 的正确率是25 percent，有两个方法要比25%要好的：每次都选最短的那个选项就会得到35%的正确率；如果分析四个选项的semantic，用sequence-to-sequence autoencoder，去把一个选项的semantic找出来，然后再去看某个选项和另外三个选项的相似度，每次都选择相似度最高的那个选项，这样做正确率有36%左右。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723175934.png" style="zoom:67%;"></p><p>另外还可以用memory network的方法，可以得到39.2 %正确率；如果用我们上面讲到的那个model的话，可以做到48.8%正确率。</p><p><img src="/2020/07/20/ML%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Recurrent-Neural-Network-RNN/QQ图片20200723175941.png" style="zoom:67%;"></p><p>（后面还有一部分内容是比较RNN和Structured learning，这部分等我学习了Structured learning后再来补充。）</p>]]></content>
    
    <summary type="html">
    
      本文从一个例子-Slot Filling出发，介绍了Recurrent Neural Network(RNN，循环神经网络)的基本概念和作用，RNN的几种变形，其中重点介绍了Long Short-term Memory(LSTM），以及如何训练RNN，和RNN在NLP领域的一些具体应用。
    
    </summary>
    
    
      <category term="Deep Learning" scheme="http://nekomoon404.github.io/categories/Deep-Learning/"/>
    
    
      <category term="RNN" scheme="http://nekomoon404.github.io/tags/RNN/"/>
    
      <category term="Bidirectional RNN" scheme="http://nekomoon404.github.io/tags/Bidirectional-RNN/"/>
    
      <category term="LSTM" scheme="http://nekomoon404.github.io/tags/LSTM/"/>
    
      <category term="BPTT" scheme="http://nekomoon404.github.io/tags/BPTT/"/>
    
      <category term="Sequence to sequence learning" scheme="http://nekomoon404.github.io/tags/Sequence-to-sequence-learning/"/>
    
      <category term="Attention-based model" scheme="http://nekomoon404.github.io/tags/Attention-based-model/"/>
    
  </entry>
  
  <entry>
    <title>DL笔记（8）Optimization for Deep Learning</title>
    <link href="http://nekomoon404.github.io/2020/07/12/ML%E7%AC%94%E8%AE%B0%EF%BC%888%EF%BC%89Optimization-for-Deep-Learning/"/>
    <id>http://nekomoon404.github.io/2020/07/12/ML%E7%AC%94%E8%AE%B0%EF%BC%888%EF%BC%89Optimization-for-Deep-Learning/</id>
    <published>2020-07-12T01:57:18.000Z</published>
    <updated>2020-07-12T11:57:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>Background Konwledge:</p><ul><li>$\mu$-strong convexity</li><li>Lipschitz continuity</li><li>Bregman proximal inequality</li></ul><p>这一节课会比较概念上的讲解Optimization for Deep Learning这个主题，不会去详细证明每个算法在某些情况能达到convergence。</p><p>明确几个Notations：</p><ul><li>$\theta_t$：model parameters at time step $t$</li><li>$\nabla L(\theta_t) $ or $g_t$：gradient at $\theta_t$, used to compute $\theta_{t+1}$</li><li>$m_{t+1}$：momentum accumulated form time step 0 to time step t, which is used to compute $\theta_{t+1}$（可以理解为momentum记录了time step 0到t的梯度信息）</li></ul><p>我们先要考虑对一个神经网络做Optimization是要做什么，就是要找到一组参数$\theta$使得training data中所有的x算出来的loss之和最小，即让神经网络越贴近训练资料越好，把一个$x_t$输入到神经网络中得到的$y_t$越接近$\hat y_t$越好；或者如果用特定的$x$，那我们就是要找在loss surface上的最小值。</p><p><img src="/2020/07/12/ML%E7%AC%94%E8%AE%B0%EF%BC%888%EF%BC%89Optimization-for-Deep-Learning/QQ图片20200712103851.png" style="zoom: 50%;"></p><p>On-line vs Off-line</p><ul><li>On-line: one pair of  $(x_t, \hat y_t)$ at a time step</li></ul><p><img src="/2020/07/12/ML%E7%AC%94%E8%AE%B0%EF%BC%888%EF%BC%89Optimization-for-Deep-Learning/QQ图片20200712104522.png" style="zoom:50%;"></p><ul><li>Off-line: pour all $(x_t,\hat y_t)$ into the model at every time step</li></ul><p><img src="/2020/07/12/ML%E7%AC%94%E8%AE%B0%EF%BC%888%EF%BC%89Optimization-for-Deep-Learning/QQ图片20200712104525.png" style="zoom:50%;"></p><p>显然Off-line learning的训练方式会更好，我们一次可以看到所有的training data，但由于电脑硬件的限制等因素Off-line实际实施起来却有困难。但<strong>这节课</strong>中我们先暂且抛开这些因素，<strong>只关注Off-line的cases</strong>。</p><p>回顾之前讲过的几种优化算法（具体可以看之前的笔记）：</p><ul><li><p>SGD（Stochastic Gradient Descent，随机梯度下降）</p></li><li><p>SGD with momentum</p></li><li>Adagrad</li><li>RMSProp</li><li>Adam</li></ul><p>来看一下提出这些方法的时间：</p><p><img src="/2020/07/12/ML%E7%AC%94%E8%AE%B0%EF%BC%888%EF%BC%89Optimization-for-Deep-Learning/QQ图片20200712110246.png" style="zoom: 50%;"></p><p>Optimizers: Real Application</p><p>大家听过的很多著名的深度学习模型，比如NLP领域的BRET（Bidirectional Encoder Representation from Transformers，是一个预训练的语言表征模型），Transformer（sequence to sequence模型），Tacotron（端到端语言合成模型）；Big-GAN（图像生成模型）；MAML（Model-Agnostic Meta-Learning）都是用ADAM训练出来的。又如CV领域的YOLO（目标检测），Mask R-CNN（对象实例分割框架），ResNet（深度残差网络，用于图片分类）则是用到SGDM 。</p><p>那这些很知名的model都是用这些14年以前提出的optimizer来训练的呢，可以说是因为ADAM和SGDM已经做得非常好了，后面提出的optimizer都是去填补它们俩中间的空白，并没有很明显的超越，如下面几张图中的例子。</p><p><img src="/2020/07/12/ML%E7%AC%94%E8%AE%B0%EF%BC%888%EF%BC%89Optimization-for-Deep-Learning/QQ图片20200712114514.png" style="zoom:50%;"></p><p><img src="/2020/07/12/ML%E7%AC%94%E8%AE%B0%EF%BC%888%EF%BC%89Optimization-for-Deep-Learning/QQ图片20200712114520.png" style="zoom:50%;"></p><p>Adam和SGDM是有一定的差别的：</p><p><img src="/2020/07/12/ML%E7%AC%94%E8%AE%B0%EF%BC%888%EF%BC%89Optimization-for-Deep-Learning/QQ图片20200712114523.png" style="zoom:50%;"></p><p>Adam的generalization能力比较差，在testing data上的落差比较大；而SGDM的generalization能力比较好，在testing data上的落差比较小。</p><p>先来直观地理解一下generalization gap，上图中的黑色实线是Training loss function，红色虚线是Testing function，因为Training data和Testing data的分布有差异，所以它们的loss function可能会有点像，但也有差距。有两个值相同的Minimum，如果找到一个比较平坦的Minimum，那两个function在这里都比较平坦，差距会比较小；如果找到一个比较sharp的Minimum，两个function在这里都比价陡，差距会比较大。那造成Adam和SGDM在generalization上的差异的一个可能的原因就是Adam比较会找到Sharp Minimum，而SGDM比较会找到Flat Minimum，当然也还有其他的原因。</p><p>既然Adam比较快，SGDM比较稳，而且可以收敛到比较小的值，那就有人提出将这两种方法结合—SWATS。训练的前半部分用Adam，后半部分用SGDM，但论文中Adam和SGDM切换的点的设置并不是很科学。</p><p><img src="/2020/07/12/ML%E7%AC%94%E8%AE%B0%EF%BC%888%EF%BC%89Optimization-for-Deep-Learning/QQ图片20200712120155.png" style="zoom:50%;"></p><p>那我们有没有办法来修正Adam，让Adam像SGDM一样收敛的又稳又好呢。先来考虑Adam存在什么问题，</p><p>首先我们假设公式中的$\beta_1=0$，只关注adaptive learning rate，即分母$v_t$那一项的影响。设$\beta_2=0.999$，那$v_t$会受到gradient的影响大概就有$1/(1-0.999)=1000$个step那么久。论文[<a href="https://openreview.net/pdf?id=ryQu7f-RZ" target="_blank" rel="noopener">Reddi, et al., ICLR’18</a>里写到在training的最后阶段，大部分的gradient都会很小，且对descent的方向不能提供什么有用的信息。只有某几个minibatch的gradient会很大，会较明确地告诉参数应该往哪个方向update。那基于这一事实，在做Adam的时候会出现问题呢。</p><p><img src="/2020/07/12/ML%E7%AC%94%E8%AE%B0%EF%BC%888%EF%BC%89Optimization-for-Deep-Learning/QQ图片20200712145501.png" style="zoom:50%;"></p><p>假设已经training了10W个step，10W之后的几个step的gradient都很小，比如说都是1；直到过了1000个step后突然出现一个很大的gradient，如100000；下一个step，gradient会变得很小，比如1。</p><p>考虑第100000个step，由于我们假设$\beta_1=0$，那$m_t$就等于gradient的大小；假设前面在这之前的step的gradient有很多1，这时分母$\sqrt{\hat v_t}+\varepsilon$也是1 ，那这一步的movement就是$\eta$；之后几个step也是如此。当gradient为100000的step，$m_t=g_t=10^5$，$\sqrt{\hat v_t}+\varepsilon=\sqrt{0.001\cdot(10^5)^2}=10^{3.5}$，那movement就是$10\sqrt{10}\eta$。到下一个step，gradient=1，movement=$10^{-3.5}\eta$。那这会发生什么问题呢？</p><p><img src="/2020/07/12/ML%E7%AC%94%E8%AE%B0%EF%BC%888%EF%BC%89Optimization-for-Deep-Learning/QQ图片20200712145337.png" style="zoom:50%;"></p><p>可以看到前面这1000个step它们提供的movement是$1000\eta$，而之后这个gradient=10W的真正有意义的step，它只会移动$10\sqrt{10}\eta \approx 30\eta$，可见真正提供比较多信息的gradient它在update的时候只能造成很小的影响。当前面gradient比较小的时候，network可能不知道后面会出现有很大的gradient，就以为现在的gradient已经不错了，结果造成了不好的影响。并且movement的大小是有上限的，为$\sqrt{\frac{1}{1-\beta_2}}\eta$。所以当大部分的gradient都很小，真正有意义的gradient的作用就会受影响。</p><p><img src="/2020/07/12/ML%E7%AC%94%E8%AE%B0%EF%BC%888%EF%BC%89Optimization-for-Deep-Learning/QQ图片20200712145340.png" style="zoom: 67%;"></p><p>作者提处的方法叫<strong>AMSGrad</strong>，目标就是减小这些无意义的gradient的影响，做法是令$\hat v_t=\max(\hat v_{t-1},v_t)$。上面的例子来说明就是，假设在10W步之前出现过很大的gradient，但走到10W步这里已经忘了，给很小的gradient的step也走的比较大，那后面遇到很大的gradient反而会走的很小。作者的思路就是通过max operation来记住过去最大的$v_t$。</p><p>记得之前我们有讲过Adagrad的表达式，$w^{t+1}=w^t-\frac{\eta}{\sqrt{\sum\limits_{i=0}^t(g^i)^2}}\cdot g^t$，它会因为分母一直变大，导致learning rate一直减小，这是要解决的问题。那到AMSGrad这里反而后绕了回来，让分母变大，那可能AMSGrad并不是一个很好的解法。</p><p>下面来看另外一篇论文<a href="https://openreview.net/pdf?id=Bkg3g2R9FX" target="_blank" rel="noopener">[Luo, et al., ICLR’19]</a>提供的解决思路。</p><p><img src="/2020/07/12/ML%E7%AC%94%E8%AE%B0%EF%BC%888%EF%BC%89Optimization-for-Deep-Learning/QQ图片20200712145344.png" style="zoom: 67%;"></p><p>AMSGrad只考虑了解决learning rate很大的情况，这篇论文的作者的方法<strong>AdaBound</strong>，也考虑在gradient很大的时候，让learning rate不会很小。他将$\frac{\eta}{\sqrt{\hat v_t}+\varepsilon}$做了一个clip（将这一项的值限制在一个最小值和最大值之间），但这个有点经验公式的意味，且这个最小值和最大值和loss并没有什么关系，不太符合我们做Adaptive learning rate的期望。</p><p><img src="/2020/07/12/ML%E7%AC%94%E8%AE%B0%EF%BC%888%EF%BC%89Optimization-for-Deep-Learning/QQ图片20200712145348.png" style="zoom: 67%;"></p><p>那我们现在换个角度，来看一看对SGDM可以做哪些调整。SGDM的优点是稳定，收敛得好，但它运算得很慢，造成这的原因是它每次update的时候用的是固定的learning rate，而不想Adaptive leaning rates的算法那样可以动态地调整learning rates的大小。</p><p><img src="/2020/07/12/ML%E7%AC%94%E8%AE%B0%EF%BC%888%EF%BC%89Optimization-for-Deep-Learning/QQ图片20200712145428.png" style="zoom:67%;"></p><p>然而SGDM是无法做到learning rate的，那可不可以帮SGDM找一个最佳的learning rate呢，这个learning rate收敛得比较快，让SGDM的结果比较接近Adam。</p><p>我们在调learning rate的时候常会有这样的经验，当learning rate最小或最大的时候，结果都不会太好；一定是当learning rate适中的时候会得到较好的performance。</p><p><img src="/2020/07/12/ML%E7%AC%94%E8%AE%B0%EF%BC%888%EF%BC%89Optimization-for-Deep-Learning/QQ图片20200712145436.png" style="zoom: 67%;"></p><p>在论文<a href="https://arxiv.org/abs/1506.01186" target="_blank" rel="noopener">[Smith, WACV’17]</a>里面，作者提出了Cyclical LR，让learning rate在大小大小地周期性变化。learning rate大的时候就相当于做一个forward的动作，learning rate小的时候就相当于做一个fine tune或者是收敛的动作。通常我们在做的时候，learning rate会不断变小，这里让Learning rate变大其实是鼓励这个model“不要满足现状”，在适当的时候做更多尝试。这里有一些参数要决定：step size，以及最大和最小的learning rate。</p><p><img src="/2020/07/12/ML%E7%AC%94%E8%AE%B0%EF%BC%888%EF%BC%89Optimization-for-Deep-Learning/QQ图片20200712145440.png" style="zoom:67%;"></p><p>下面是一个很类似的做法SGDR<a href="https://arxiv.org/abs/1608.03983" target="_blank" rel="noopener">[Loshchilov,et al., ICLR‘17]</a>，只是调整learning rate的方法不一样。</p><p><img src="/2020/07/12/ML%E7%AC%94%E8%AE%B0%EF%BC%888%EF%BC%89Optimization-for-Deep-Learning/QQ图片20200712145445.png" style="zoom:67%;"></p><p>另一个方法One-cycle LR的思想是只做一个cycle，分为三个阶段：warm up—learning rate逐渐增大，直到找到一个还不错的minima附近；annealing—learning rate逐渐减小；fine-tuning—收敛。</p><p><img src="/2020/07/12/ML%E7%AC%94%E8%AE%B0%EF%BC%888%EF%BC%89Optimization-for-Deep-Learning/QQ图片20200712145448.png" style="zoom:67%;"></p><p>那你可能会想Adam需要这样的三个过程嘛，比如Adam需要warm up嘛，有人也做了这方面的研究</p>]]></content>
    
    <summary type="html">
    
      本文分别介绍了Adam和SGDM这两种Optimizers的几种改进的优化方法。
    
    </summary>
    
    
      <category term="Deep Learning" scheme="http://nekomoon404.github.io/categories/Deep-Learning/"/>
    
    
      <category term="Adam" scheme="http://nekomoon404.github.io/tags/Adam/"/>
    
      <category term="AMSGrad" scheme="http://nekomoon404.github.io/tags/AMSGrad/"/>
    
      <category term="AdaBound" scheme="http://nekomoon404.github.io/tags/AdaBound/"/>
    
      <category term="SGDM" scheme="http://nekomoon404.github.io/tags/SGDM/"/>
    
      <category term="Cyclical LR" scheme="http://nekomoon404.github.io/tags/Cyclical-LR/"/>
    
  </entry>
  
  <entry>
    <title>DL笔记（7）Tips for Deep Learning</title>
    <link href="http://nekomoon404.github.io/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/"/>
    <id>http://nekomoon404.github.io/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/</id>
    <published>2020-07-11T08:55:52.000Z</published>
    <updated>2020-07-11T10:55:52.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-Recipe-of-Deep-Learning"><a href="#1-Recipe-of-Deep-Learning" class="headerlink" title="1. Recipe of Deep Learning"></a>1. Recipe of Deep Learning</h3><p>回顾之前讲过的Deep Learning的三个步骤：</p><ul><li>define the function set(network structure) </li><li>goodness of function(loss function — cross entropy)</li><li>pick the best function(gradient descent — optimization)</li></ul><p>做完这些步骤以后会得到一个更好的neural network，那接下来我们要做什么事情呢？</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711170051.png" style="zoom:50%;"></p><p><strong>Good Results on Training Data？</strong></p><p>要做的第一件事是，<strong>提高model在training set上的正确率</strong>。</p><p>先检查training set的performance其实是deep learning一个非常unique的地方，如果使用的是k-nearest neighbor或decision tree这类非deep learning的方法，做完以后其实不用去检查training set的结果，因为在training set上的performance正确率就是100。Deep Learning的model里这么多参数，但实际上<strong>Deep Learning不容易出现overfitting</strong>，<strong>overfitting是指在training set上performance很好，但在testing set上performance没有那么好</strong>。像k nearest neighbor，decision tree这类方法，它们在training set上正确率都是100，是非常容易overfitting的；而对deep learning来说，overfitting往往不会是你遇到的第一个问题。</p><p>因为deep learning并不是像k nearest neighbor这种方法一样，一训练就可以得到非常好的正确率，它有可能在training set上没有办法给一个很好的正确率，所以，这个时候要回头<strong>去检查在前面的step里面要做什么样的修改</strong>，使得模型在training set上可以得到较高的正确率。</p><p><strong>Good Results on Testing Data？</strong></p><p>接下来要做的事是，<strong>提高model在testing set上的正确率</strong>。</p><p>假设现在已经在training set上得到好的performance了，那接下来就把model apply到testing set上，我们最后真正关心的，是testing set上的performance。如果得到的结果不好，这时就是Overfitting了，也就是在training set上得到好的结果，却在testing set上得到不好的结果。</p><p>那你要回过头试着解决overfitting，但有时候你加了新的technique，想要overcome overfitting这个problem的时候，其实反而会让training set上的结果变坏；所以你在做完这一步的修改以后，要先回头去检查新的model在training set上的结果，如果这个结果变坏的话，你就要从头对network training的process做一些调整，那如果你同时在training set还有testing set上都得到好结果的话，你就成功了，最后就可以把你的系统真正用在application上面了。</p><p><strong>Do not always blame overfitting</strong></p><p><strong>不要看到不好的performance就归责于overfitting</strong>。先看右边testing data的图，横坐标是model做gradient descent所update的次数，纵坐标则是error rate(越低说明model表现得越好)，黄线表示的是20层的neural network，红色表示56层的neural network。发现56层network的error rate比较高，它的performance比较差，而20层network的performance则是比较好的，有些人看到这就会马上得到一个结论：56层的network参数太多了，56层果然没有必要，这个是overfitting。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711170059.png" style="zoom:50%;"></p><p>但是检查一下模型在training set上的performance，如上面左边的图，在training set上20层的network本来就要比56层的network表现得更好，所以testing set得到的结果并不能说明56层的case就是发生了overfitting。</p><p>在做neural network training的时候，有太多的问题会让training set表现的不好，比如local minimum的问题，saddle point的问题，有plateau的问题…所以这个56层的neural network有可能在train的时候就卡在了一个local minimum的地方，于是得到了一个差的参数，但这并不是overfitting，而是在training的时候就没有train好。有人认为这个问题叫做underfitting，但underfitting的本意应该是指这个model的complexity不足，这个model的参数不够多，所以它的能力不足以解出这个问题；但这个56层的network，它的参数是比20层的network要来得多的，所以它明明有能力比20层的network要做的更好，却没有得到理想的结果，这种情况不应该被称为underfitting，其实就只是<strong>没有train好</strong>而已。</p><p>当你在deep learning的文献上看到某种方法的时候，永远要想一下，这个方法是要解决什么样的问题：</p><ul><li>在training set上的performance不够好</li><li>在testing set上的performance不够好</li></ul><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711171746.png" style="zoom:50%;"></p><p>当只有一个方法propose(提出)的时候，它往往只针对这两个问题的其中一个来做处理，比如dropout的方法，它是在testing data的结果不好时用，如果你的问题只是training的结果不好，那去apply dropout只会越train越差。所以我们<strong>必须要先想清楚现在的问题到底是什么，然后再根据这个问题去找针对性的方法</strong>，而不是病急乱投医，甚至是盲目诊断。下面我们分别从Training data和Testing data两个问题出发，来讲述一些针对性优化的方法。</p><h3 id="2-Good-Results-on-Training-Data？"><a href="#2-Good-Results-on-Training-Data？" class="headerlink" title="2. Good Results on Training Data？"></a>2. Good Results on Training Data？</h3><p>这一章主要介绍如何在Training data上得到更好的performance，分为两个模块，<strong>New activation function</strong>和<strong>Adaptive Learning Rate</strong>。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711172438.png" style="zoom:50%;"></p><h4 id="2-1-New-activation-function"><a href="#2-1-New-activation-function" class="headerlink" title="2.1. New activation function"></a>2.1. New activation function</h4><p><strong>activation function</strong></p><p>如果你今天的training结果不好，很有可能是因为你的network架构设计得不好。可能你用的activation function是对training比较不利的，那就要尝试着换一些新的activation function，也许可以带来比较好的结果。在1980年代，比较常用的activation function是sigmoid function，如果现在我们使用sigmoid function，你会发现network越deeper不一定imply better，下图是在MNIST手写数字识别上的结果，当layer越来越多的时候，accuracy一开始持平，后来就会逐渐降低，在layer是9层、10层的时候，整个结果就崩溃了。但注意9层、10层的情况并不能被认为是因为参数太多而导致overfitting，实际上这张图就只是training set的结果。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711172512.png" style="zoom:50%;"></p><h5 id="2-1-1-Vanishing-Gradient-Problem"><a href="#2-1-1-Vanishing-Gradient-Problem" class="headerlink" title="2.1.1. Vanishing Gradient Problem"></a>2.1.1. Vanishing Gradient Problem</h5><p>上面这个问题的原因不是overfitting，而是Vanishing Gradient(梯度消失)，解释如下：当你把network叠得很深的时候，在靠近input的地方，loss function对这些参数的微分（即梯度）是比较小的；而在比较靠近output的地方，它对loss的微分值会是比较大的。</p><p>因此当你设定同样learning rate的时候，靠近input的地方，它参数的update是很慢的；而靠近output的地方，它参数的update是比较快的。所以在靠近input的地方，参数几乎还是random的时候，output就已经根据这些random的结果找到了一个local minima，然后就converge(收敛)了。这时loss下降的速度变得很慢，你就会觉得gradient已经接近于0了，于是把程序停掉了，由于这个converge，是几乎base on random的参数，所以model的参数并没有被训练充分，那在training data上得到的结果肯定是很差的。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711172515.png" style="zoom:50%;"></p><p>如果把Backpropagation的式子写出来，就可以很轻易地发现用sigmoid function会导致这件事情的发生；或者其实从直觉上来想也可以了解这件事情发生的原因：某一个参数$w$对total loss $l$的偏微分，即gradient $\frac{\partial l}{\partial w}$，它的含义可以理解为：当把这个参数做小小的变化的时候，它对loss的影响有多大；那我们就把第一个layer里的某一个参数$w$加上$\Delta w$，看看它对network的output和target之间的loss有什么样的影响。</p><p>$\Delta w$通过sigmoid function之后，得到output是会变小的，改变某一个参数的weight，会对某个neuron的output值产生影响，但是这个<strong>影响是会随着层数的递增而衰减的</strong>，sigmoid function的形状如下所示，它会把负无穷大到正无穷大之间的值都硬压到0~1之间，把较大的input压缩成较小的output。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711174126.png" style="zoom:50%;"></p><p>因此即使$\Delta w$值很大，但每经过一个sigmoid function就会被缩小一次，所以network越深，$\Delta w$被衰减的次数就越多，直到最后，它对output的影响就是比较小的，相应的也导致input对loss的影响会比较小，于是靠近input的那些weight对loss的gradient $\frac{\partial l}{\partial w}$远小于靠近output的gradient。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711174130.png" style="zoom:50%;"></p><p>那如何解决这个问题呢？比较早年的做法是去train RBM（Restricted Boltzmann Machine，受限玻尔兹曼机），它的思想是：先把第一个layer train好，再去train第二个，然后再第三个…所以最后你在做Backpropagation的时候，尽管第一个layer几乎没有被train到，但一开始在做pre-train的时候就已经把它给train好了，这样RBM就可以在一定程度上解决问题。但其实改一下activation function可能就可以handle这个问题了。</p><h5 id="2-1-2-ReLU"><a href="#2-1-2-ReLU" class="headerlink" title="2.1.2. ReLU"></a>2.1.2. ReLU</h5><p>现在比较常用的activation function叫做<strong>Rectified Linear Unit(整流线性单元函数，又称修正线性单元)</strong>，它的缩写是<strong>ReLU</strong>，该函数形状如下图所示，$z$为input，$a$为output，如果input&gt;0则output = input，如果input&lt;0则output = 0。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711183302.png" style="zoom:50%;"></p><p><strong>选择ReLU作为activation function的理由</strong>如下：</p><ul><li>跟sigmoid function比起来，ReLU的运算快很多；</li><li>ReLU的想法结合了生物上的观察( Pengel的paper )；</li><li>无穷多bias不同的sigmoid function叠加的结果会变成ReLU；</li><li>ReLU可以处理Vanishing gradient的问题( the most important thing )；</li></ul><p><strong>handle Vanishing gradient problem</strong></p><p>下图是以ReLU作为activation function的neuron组成的network，它的output要么等于0，要么等于input。当output=input的时候，这个activation function就是linear的；而output=0的neuron对整个network是没有任何作用的，因此可以把它们从network中拿掉。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711183307.png" style="zoom:50%;"></p><p>拿掉所有output为0的neuron后如下图所示，此时整个network就变成了一个瘦长的<strong>linear</strong> network，linear的好处是，output=input，不会像sigmoid function一样使input产生的影响逐层递减。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711183312.png" style="zoom:50%;"></p><p>Q：这里就会有一个问题，我们之所以使用deep learning，就是想要一个non-linear、比较复杂的model，而使用ReLU不就会让它变成一个linear function吗？这样得到的function不是会变得很弱吗？</p><p>A：其实，<strong>使用ReLU之后的network整体来说还是non-linear的</strong>，如果你对input做小小的改变，不改变neuron的operation region的话，那network就是一个linear function；但是，如果你对input做比较大的改变，导致neuron的operation region被改变的话，比如从output=0转变到了output=input，network整体上就变成了non-linear function。（这里的region是指input z<0和input z>0的两个范围）</0和input></p><p>Q：还有另外一个问题，我们对loss function做gradient descent，要求neural network是可以做微分的，但ReLU是一个分段函数，它是不能微分的(至少在z=0这个点是不可微的)，那该怎么办呢？</p><p>A：在实际操作上，当region的范围处于z&gt;0时，微分值gradient就是1；当region的范围处于z&lt;0时，微分值gradient就是0；当z为0时，就不要管它，相当于把它从network里面拿掉</p><p><strong>ReLU-variant</strong></p><p>其实ReLU还存在一定的问题，比如当input&lt;0的时候，output=0，此时微分值gradient也为0，你就没有办法去update参数了，那我们可以让input&lt;0的时候，微分后还能有一定的值，比如令$a=0.01z$，这个函数叫做<strong>Leaky ReLU</strong>。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711183315.png" style="zoom:50%;"></p><p>那自然可以想到我们也可以把$z$前的系数当作参数来训练，这就是<strong>Parametric ReLU</strong>，令$a=\alpha \cdot z$，其中$\alpha$并不是固定的值，而是network的一个参数，它可以通过training data学出来，甚至每个neuron都可以有不同的$\alpha$值。</p><p>又有人想，activation function为什么一定要是ReLU这样子呢，于是就有了一个更进阶的想法—<strong>Maxout network</strong>。</p><h5 id="2-1-3-Maxout"><a href="#2-1-3-Maxout" class="headerlink" title="2.1.3. Maxout"></a>2.1.3. Maxout</h5><p>Maxout的思想是，让network去学习它的activation function，那Maxout network就可以学出ReLU，也可以学出其他的activation function，这一切都是由training data来决定的。假设现在有input $x_1,x_2$，它们乘上几组不同的weight分别得到5,7,-1,1，这些值本来是不同neuron的input；但在Maxout network里，我们事先决定好将某几个“neuron”的input分为一个group，比如5,7分为一个group，然后在这个group里选取一个最大值7作为output。</p><p>这个过程就好像在一个layer上做Max Pooling一样，它和原来的network不同之处在于，它把原来几个“neuron”的input按一定规则组成了一个group，然后<strong>并没有使它们通过activation function，而是选取其中的最大值当做这几个“neuron”的output</strong>。</p><p>当然，实际上原来的”neuron“早就已经不存在了，这几个被合并的“neuron”应当被看做是一个新的neuron（下图中红框框住的部分），这个新的neuron的input是原来几个“neuron”的input组成的vector，output则取input的最大值，而并非由activation function产生。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711195917.png" style="zoom:50%;"></p><p>在实际操作上，几个element被分为一个group是由你自己决定的，它就是network structure里一个需要被调的参数，不一定要跟上图一样两个分为一组。</p><p><strong>Maxout -&gt; RELU</strong></p><p>Maxout是如何能学习出ReLU这个activation function的呢？</p><p>下图左上角是一个ReLU的neuron，它的input $x$会乘上neuron的weight $w$，再加上bias $b$，然后通过activation function-ReLU，得到output $a$。</p><ul><li>neuron的input为$z=wx+b$，为下图左下角的紫线；</li><li>neuron的output为$a=z\ (z&gt;0);\ a=0\ (z&lt;0)$，为下图左下角的绿线。</li></ul><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711195922.png" style="zoom:50%;"></p><p>如果我们使用的是上图右上角所示的Maxout network，假设$z_1$的参数w和b与ReLU的参数一致，而$z_2$的参数w和b全部设为0，然后做Max，选取$z_1,z_2$较大值作为a：</p><ul><li>neuron的input为$\begin{bmatrix}z_1 \ z_2 \end{bmatrix}$<ul><li>$z_1=wx+b$，为上图右下角紫线</li><li>$z_2=0$，为上图右下角红线</li></ul></li><li>neuron的output为$\max{\begin{bmatrix}z_1 \ z_2 \end{bmatrix}}$，为上图右下角绿线</li></ul><p>你会发现，此时ReLU和Maxout所得到的output是一模一样的，它们是相同的activation function。</p><p><strong>Maxout -&gt; More than ReLU</strong></p><p>除了ReLU，Maxout还可以实现更多不同的activation function。比如$z_2$的参数w和b不是0，而是$w’,b’$，此时</p><ul><li>neuron的input为$\begin{bmatrix}z_1 \ z_2 \end{bmatrix}$<ul><li>$z_1=wx+b$，为下图右下角紫线</li><li>$z_2=w’x+b’$，为下图右下角红线</li></ul></li><li>neuron的output为$\max{\begin{bmatrix}z_1 \ z_2 \end{bmatrix}}$，为下图右下角绿线</li></ul><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711195926.png" style="zoom:50%;"></p><p>这个时候你得到的activation function的形状(绿线形状)，是由network的参数$w,b,w’,b’$决定的，因此它是一个<strong>Learnable Activation Function</strong>，具体的形状可以根据training data去generate出来。</p><p><strong>property</strong></p><p><strong>Maxout可以实现任何piecewise linear convex activation function(分段线性凸激活函数)</strong>，其中这个activation function被分为多少段，取决于你把多少个element z放到一个group里，下图分别是2个element一组和3个element一组的activation function的不同形状。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711195930.png" style="zoom:50%;"></p><p><strong>How to train Maxout</strong></p><p>接下来我们要面对的是，怎么去train一个Maxout network，如何解决Max不能微分的问题。假设在下面的Maxout network中，红框圈起来的部分为每个neuron的output。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711195933.png" style="zoom:50%;"></p><p>其实Max operation就是linear的operation，只是它仅接在前面这个group里的某一个element上，因此我们可以<strong>把那些并没有被Max连接到的element拿掉</strong>，从而得到一个比较细长的linear network。</p><p>那么可以理解为，实际上我们真正训练的并不是一个含有max函数的network，而是一个化简后如下图所示的linear network；当我们还没有真正开始训练模型的时候，此时这个network含有max函数无法微分，但是只要输入data，network就会根据这些data确定具体的形状，此时max函数的问题已经被实际数据给解决了，所以我们完全可以根据training data使用Backpropagation的方法去训练被network留下来的参数。</p><p>所以我们担心的max函数无法微分，它只是理论上的问题；<strong>在具体的实践上，完全可以先根据data把max函数转化为某个具体的函数，再对这个转化后的thiner linear network进行微分</strong></p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711201534.png" style="zoom:50%;"></p><p>这个时候你也许会有一个问题，如果按照上面的做法，那岂不是只会train留在network里面的那些参数，剩下的参数该怎么办？那些被拿掉的直线(weight)岂不是永远也train不到了吗？</p><p>其实这也只是个理论上的问题，在实际操作上，每个linear network的structure都是由input的那一笔data来决定的，当input不同data的时候，得到的network structure是不同的，留在network里面的参数也是不同的，<strong>由于我们有很多笔training data，所以network的structure在训练中不断地变换，实际上最后每一个weight参数都会被train到</strong>。</p><p>所以，我们回到Max Pooling的问题上来，由于Max Pooling跟Maxout是一模一样的operation，那么<strong>Max Pooling有关max函数的微分问题就可以采用跟Maxout一样的方案来解决</strong>，至此我们已经解决了CNN部分的第一个问题—New activation function。</p><h4 id="2-2-Adaptive-learning-rate"><a href="#2-2-Adaptive-learning-rate" class="headerlink" title="2.2. Adaptive learning rate"></a>2.2. Adaptive learning rate</h4><h5 id="2-2-1-Review-Adagrad"><a href="#2-2-1-Review-Adagrad" class="headerlink" title="2.2.1. Review - Adagrad"></a>2.2.1. Review - Adagrad</h5><p>回顾之前学过的梯度下降中的一个Tip: Adagrad，它让每一个parameter都要有不同的learning rate。Adagrad的思想是，假设我们考虑两个参数$w_1,w_2$，如果在$w_1$这个方向上，gradient都比较小，那它是比较平坦的，于是就给它比较大的learning rate；而在$w_2$这个方向上，gradient都比较大，那它是比较陡峭的，于是给它比较小的learning rate。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711202224.png" style="zoom:50%;"></p><p>但我们实际面对的问题，很有可能远比Adagrad所能解决的问题要来的复杂，回顾之前学的Linear Regression，我们做optimization的对象，也就是loss function，它是convex的；但实际上我们在做deep learning的时候，这个loss function可以是任何形状。</p><h5 id="2-2-2-RMSProp"><a href="#2-2-2-RMSProp" class="headerlink" title="2.2.2. RMSProp"></a>2.2.2. RMSProp</h5><p><strong>learning rate</strong></p><p>Deep learning的loss function可以是任何形状，对convex loss function来说，在每个方向上它会一直保持平坦或陡峭的状态，所以你只需要针对平坦的情况设置较大的learning rate，对陡峭的情况设置较小的learning rate即可。但在下图的情况中，即使是在同一个方向上(如w1方向)，loss function也有可能一会儿平坦一会儿陡峭，所以就需要我们随时根据gradient的大小来快速地调整learning rate。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711202228.png" style="zoom:50%;"></p><p>这个问题可以通过Adagrad的进阶版——<strong>RMSProp</strong>来解决。（RMSprop并不是在paper里提出来的，而是Hinton在他的网课里提出来的一个方法）</p><p><strong>how to do RMSProp</strong></p><p>RMSProp的做法如下：</p><p>learning rate依旧设置为一个固定的值 $\eta$ 除掉一个变化的值 $\sigma$，这个$\sigma$等于上一个$\sigma$和当前梯度$g$的<strong>加权方均根</strong>（特别的是，在第一个时间点，$\sigma^0$就是第一个算出来的gradient值$g^0$），即：</p><script type="math/tex; mode=display">w^{t+1}=w^t-\frac{\eta}{\sigma^t}g^t \\\sigma^t=\sqrt{\alpha(\sigma^{t-1})^2+(1-\alpha)(g^t)^2}</script><p>这里的$\alpha$值是可以自由调整的，RMSProp跟Adagrad不同之处在于，Adagrad的分母是对过程中所有的gradient取平方和开根号，也就是说Adagrad考虑的是整个过程平均的gradient信息；而RMSProp虽然也是对所有的gradient进行平方和开根号，但是它<strong>用$\alpha$来调整对不同gradient的权重</strong>，比如你把α的值设的小一点，意思就是你更倾向于相信新的gradient所告诉你的error surface的平滑或陡峭程度，而比较无视于旧的gradient所提供给你的information。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711202232.png" style="zoom:50%;"></p><p>所以当做RMSProp的时候，你可以给现在已经看到的gradient比较大的weight，给过去看到的gradient比较小的weight，来调整对gradient信息的使用程度。</p><h5 id="2-2-3-Momentum"><a href="#2-2-3-Momentum" class="headerlink" title="2.2.3. Momentum"></a>2.2.3. Momentum</h5><p><strong>optimization - local minima？</strong></p><p>除了learning rate的问题以外，在做deep learning的时候，也会出现卡在local minimum、saddle point或是plateau的地方，很多人都会担心，deep learning这么复杂的model，可能会非常容易在这些地方“卡住”。但其实Yann LeCun在07年的时候，就提出了这样的观点：我们<strong>不需要太担心local minima的问题</strong>，因为一旦出现local minima，它就必须在每一个dimension都是下图中这种山谷的低谷形状，假设山谷的低谷出现的概率为p，由于我们的network有非常多的参数，比如有1000个参数，每一个参数都要位于山谷的低谷之处，这件事发生的概率为$p^{1000}$，当你的network越复杂，参数越多，这件事发生的概率就越低。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711202237.png" style="zoom:50%;"></p><p>所以在一个很复杂的neural network里，其实并没有那么多的local minima，所以当算法运行到一个你觉得是local minima的地方被卡住了，那它八成就是global minima，或者是很接近global minima的地方。</p><p><strong>where is Momentum from</strong></p><p>有一个heuristic(启发性)的方法可以稍微处理一下上面所说的“卡住”的问题，它的灵感来自于物理中的惯性的概念。如果是在现实世界中，在有一个球从左上角滚下来，它会滚到plateau的地方、local minima的地方，但是由于惯性它还会继续往前走一段路程，假设前面的坡没有很陡，这个球就很有可能翻过山坡，走到比local minima还要好的地方。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711202242.png" style="zoom:50%;"></p><p>所以我们可以按照这个思路，把“<strong>惯性</strong>项”加到gradient descent里面，这就叫做<strong>Momentum</strong>。</p><p><strong>how to do Momentum</strong></p><p>当我们在gradient descent里加上Momentum的时候，每一次update的方向，不再只考虑gradient的方向，还要考虑上一次update的方向，这里用变量$v$去记录前一个时间点update的方向。</p><p>随机选一个初始值$\theta^0$，初始化$v^0=0$，接下来计算$\theta^0$处的gradient，我们要移动的方向是由前一个时间点的移动方向$v^0$和gradient的反方向$\nabla L(\theta^0)$来决定的，即</p><script type="math/tex; mode=display">v^1=\lambda v^0-\eta \nabla L(\theta^0)</script><p>注：这里的<strong>$\lambda$也是一个可以调整的参数，它表示惯性对前进方向的影响有多大</strong>。</p><p>接下来我们第二个时间点要走的方向$v^2$，它是由第一个时间点移动的方向$v^1$和gradient的反方向$\nabla L(\theta^1)$共同决定的；$\lambda v$是图中的绿色虚线，它代表由于上一次的惯性想要继续走的方向；$\eta \nabla L(\theta)$是图中的红色虚线，它代表这次gradient告诉你所要移动的方向；它们的矢量和就是这一次真实移动的方向，为蓝色实线</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711202245.png" style="zoom:50%;"></p><p>我们还可以用另一种方法来理解Momentum，其实你在<strong>每一个时间点移动的步伐$v^i$，包括大小和方向，就是过去所有gradient的加权和</strong>。</p><p>具体推导如下图所示，第一个时间点移动的步伐$v^1$是$\theta^0$处的gradient加权，第二个时间点移动的步伐$v^2$是$\theta^0$和$\theta^1$处的gradient加权和…以此类推；由于$\lambda$的值小于1，因此该加权意味着越是之前的gradient，它的权重就越小，即你更在意的是现在的gradient，但是过去的所有gradient也要对你现在update的方向有一定程度的影响，这就是Momentum。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711202250.png" style="zoom:50%;"></p><p>当然也可以从直觉上来想一下加入Momentum之后是怎么运作的。下图中，红色实线是gradient建议我们走的方向，直观上看就是根据坡度要走的方向；绿色虚线是Momentum建议我们走的方向，实际上就是上一次移动的方向；蓝色实线则是最终真正走的方向。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711202254.png" style="zoom:50%;"></p><p>如果我们今天走到local minimum的地方，此时gradient是0，但是Momentum，它指向右侧就是告诉你之前是要走向右边的，所以你仍然应该要继续往右走，所以最后你参数update的方向仍然会继续向右；你甚至可以期待Momentum比较强，惯性的力量可以支撑着你走出这个谷底，去到loss更低的地方。</p><h5 id="2-2-4-Adam"><a href="#2-2-4-Adam" class="headerlink" title="2.2.4. Adam"></a>2.2.4. Adam</h5><p><strong>RMSProp加上Momentum，就是Adam</strong>。根据下面的paper来快速描述一下Adam的algorithm：</p><ul><li><p>先初始化$m_0=0$，$m_0$就是Momentum中，前一个时间点的movement</p><p>再初始化$v_0=0$，$v_0$就是RMSProp里计算gradient的root mean square的$\sigma$</p><p>最后初始化$t=0$，t用来表示时间点</p></li><li><p>先算出gradient $g_t$</p><script type="math/tex; mode=display">g_t=\nabla _{\theta}f_t(\theta_{t-1})</script></li><li><p>再根据过去要走的方向$m_{t-1}$和gradient $g_t$，算出现在要走的方向 $m_t$——Momentum</p><script type="math/tex; mode=display">m_t=\beta_1 m_{t-1}+(1-\beta_1) g_t</script></li><li><p>然后根据前一个时间点的$v_{t-1}$和gradient $g_t$的平方，算一下放在分母的$v_t$——RMSProp</p><script type="math/tex; mode=display">v_t=\beta_2 v_{t-1}+(1-\beta_2) g_t^2</script></li><li><p>接下来做了一个原来RMSProp和Momentum里没有的东西，就是<strong>bias correction</strong>，它使$m_t$和$v_t$都除上一个值，这个值本来比较小，后来会越来越接近于1 (原理详见paper)</p><script type="math/tex; mode=display">\hat{m}_t=\frac{m_t}{1-\beta_1^t} \\ \hat{v}_t=\frac{v_t}{1-\beta_2^t}</script></li><li><p>最后做update，把Momentum建议你的方向$\hat{m_t}$乘上learning rate $\alpha$，再除掉RMSProp normalize后建议的learning rate分母，然后得到update的方向</p><script type="math/tex; mode=display">\theta_t=\theta_{t-1}-\frac{\alpha \cdot \hat{m}_t}{\sqrt{\hat{v}_t}+\epsilon}</script></li></ul><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711202257.png" style="zoom:67%;"></p><p>到这里我们就了解了改善Deep learning在training data上的表现的基本方法。下面来介绍如何改善Deep learning在testing data上的表现。</p><h3 id="3-Good-Results-on-Testing-Data？"><a href="#3-Good-Results-on-Testing-Data？" class="headerlink" title="3. Good Results on Testing Data？"></a>3. Good Results on Testing Data？</h3><p>在Testing data上得到更好的performance的基本方法，大致可以分为三种：<strong>Early Stopping</strong>、<strong>Regularization</strong>和<strong>Dropout</strong>。值得注意的是，Early Stopping和Regularization是很typical的做法，它们不是特别为deep learning所设计的；而Dropout是一个蛮有deep learning特色的做法。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711204838.png" style="zoom:50%;"></p><h4 id="3-1-Early-Stopping"><a href="#3-1-Early-Stopping" class="headerlink" title="3.1. Early Stopping"></a>3.1. Early Stopping</h4><p>假设你今天的learning rate调的比较好，那随着训练的进行，total loss通常会越来越小，但是Training set和Testing set的情况并不是完全一样的，很有可能当你在Training set上的loss逐渐减小的时候，在Testing set上的loss反而上升了。理想上假如我们知道testing data上的loss变化情况，就会在testing set的loss最小的时候停下来，即提前停止训练—Early Stopping，而不是在training set的loss最小的时候停下来；但testing set实际上是未知的东西，所以我们需要用validation set来替代它去做这件事情。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711204842.png" style="zoom:50%;"></p><p>注：很多时候，我们所讲的“testing set”并不是指代那个未知的数据集，而是一些已知的被你拿来做测试之用的数据集，比如kaggle上的public set，或者是你自己切出来的validation set。</p><h4 id="3-2-Regularization"><a href="#3-2-Regularization" class="headerlink" title="3.2. Regularization"></a>3.2. Regularization</h4><p>regularization就是在原来的loss function上额外增加几个term，比如我们要minimize的loss function原先应该是square error或cross entropy，那在做Regularization的时候，就在后面加一个Regularization的term。</p><h5 id="3-2-1-L2-regularization"><a href="#3-2-1-L2-regularization" class="headerlink" title="3.2.1. L2 regularization"></a>3.2.1. L2 regularization</h5><p>regularization term可以是参数的L2 norm(L2范数)，L2 norm是把model参数集$\theta$里的每一个参数都取平方然后求和，这称作L2 regularization（L2 正则化），即</p><script type="math/tex; mode=display">L2 \ regularization:||\theta||_2=(w_1)^2+(w_2)^2+...</script><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711204845.png" style="zoom:50%;"></p><p>通常我们在做regularization的时候，新加的term里是<strong>不考虑bias这一项</strong>的，因为加regularization的目的是为了让我们的function更平滑，而bias通常是跟function的平滑程度没有关系的。</p><p>L2 regularization具体流程如下：</p><ul><li>加上regularization term之后得到了一个新的loss function：$L’(\theta)=L(\theta)+\lambda \frac{1}{2}||\theta||_2$</li><li>将这个loss function对参数$w_i$求微分：$\frac{\partial L’}{\partial w_i}=\frac{\partial L}{\partial w_i}+\lambda w_i$</li><li>然后update参数$w_i$：$w_i^{t+1}=w_i^t-\eta \frac{\partial L’}{\partial w_i}=w_i^t-\eta(\frac{\partial L}{\partial w_i}+\lambda w_i^t)=(1-\eta \lambda)w_i^t-\eta \frac{\partial L}{\partial w_i}$</li></ul><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711204849.png" style="zoom:50%;"></p><p>如果把这个推导出来的式子和原式作比较，你会发现参数$w_i$在每次update之前，都会乘上一个$(1-\eta \lambda)$，而$\eta$和$\lambda$通常会被设为一个很小的值，因此$(1-\eta \lambda)$通常是一个接近于1的值，比如0.99,；也就是说，regularization做的事情是，每次update参数$w_i$之前，就先对原来的$w_i$乘个小于1的数，这意味着，随着update次数增加，参数$w_i$会越来越接近于0。</p><p>Q：你可能会问，要是所有的参数都越来越靠近0，那最后岂不是$w_i$通通变成0，得到的network还有什么用？</p><p>A：其实不会出现最后所有参数都变为0的情况，因为通过微分得到的$\eta \frac{\partial L}{\partial w_i}$这一项是会和前面$(1-\eta \lambda)w_i^t$这一项最后取得平衡的。</p><p>使用L2 regularization可以让weight每次都变得更小一点，这就叫做<strong>Weight Decay</strong>(权重衰减)，意思就是如果有一些weight它每次都会越来越小，最后就接近0然后不见了。</p><h5 id="3-2-2-L1-regularization"><a href="#3-2-2-L1-regularization" class="headerlink" title="3.2.2. L1 regularization"></a>3.2.2. L1 regularization</h5><p>除了L2 regularization中使用平方项作为new term之外，还可以使用L1 regularization，把平方项换成每一个参数的绝对值，即</p><script type="math/tex; mode=display">||\theta||_1=|w_1|+|w_2|+...</script><p>Q：绝对值不能微分啊，该怎么处理呢？</p><p>A：实际上绝对值就是一个V字形的函数，在V的左边微分值是-1，在V的右边微分值是1，只有在0的地方是不能微分的，那在0处就可以设定一个微分值，比如0。</p><p>如果w是正的，那微分出来就是+1，如果w是负的，那微分出来就是-1，所以这边用了一个$w$的<strong>sign function</strong>，它的意思是，如果w是正数的话，这个function output就是+1，w是负数的话，这个function output就是-1。</p><p>L1 regularization的流程如下：</p><ul><li>加上regularization term之后得到了一个新的loss function：$L’(\theta)=L(\theta)+\lambda \frac{1}{2}||\theta||_1$</li><li>将这个loss function对参数$w_i$求微分：$\frac{\partial L’}{\partial w_i}=\frac{\partial L}{\partial w_i}+\lambda \ sgn(w_i)$</li><li>然后update参数$w_i$：$w_i^{t+1}=w_i^t-\eta \frac{\partial L’}{\partial w_i}=w_i^t-\eta(\frac{\partial L}{\partial w_i}+\lambda \ sgn(w_i^t))=w_i^t-\eta \frac{\partial L}{\partial w_i}-\eta \lambda \ sgn(w_i^t)$</li></ul><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711204853.png" style="zoom:50%;"></p><p>这个式子告诉我们，每次update参数的时候，都要减去一个$\eta \lambda \ sgn(w_i^t)$，如果w是正的，sgn是+1，就会变成减一个positive的值让你的参数变小；如果w是负的，sgn是-1，就会变成加一个值让你的参数变大；总之就是让它们的绝对值减小至接近于0。</p><h5 id="3-2-3-L1-V-s-L2"><a href="#3-2-3-L1-V-s-L2" class="headerlink" title="3.2.3. L1 V.s. L2"></a>3.2.3. L1 V.s. L2</h5><p>来对比一下L1和L2的update过程：</p><script type="math/tex; mode=display">L1: w_i^{t+1}=w_i^t-\eta \frac{\partial L}{\partial w_i}-\eta \lambda \ sgn(w_i^t)\\L2: w_i^{t+1}=(1-\eta \lambda)w_i^t-\eta \frac{\partial L}{\partial w_i}</script><p>L1和L2，虽然它们同样是让参数的绝对值变小，但它们做的事情其实略有不同：</p><ul><li>L1使参数绝对值变小的方式是每次update<strong>减掉一个固定的值</strong></li><li>L2使参数绝对值变小的方式是每次update<strong>乘上一个小于1的固定值</strong></li></ul><p>因此，当参数w的绝对值比较大的时候，L2会让w下降得更快，而L1每次update只让w减去一个固定的值，train完以后可能还会有很多比较大的参数；当参数w的绝对值比较小的时候，L2的下降速度就会变得很慢，train出来的参数平均都是比较小的，而L1每次下降一个固定的value，train出来的参数是比较sparse的，这些参数有很多是接近0的值，也会有很大的值。在之前所讲的CNN的task里，用L1做出来的效果是比较合适的，是比较sparse的。</p><p><strong>some tips</strong></p><p>ps：在deep learning里面，regularization虽然有帮助，但它的重要性往往没有在SVM这类方法的作用来得高，因为我们在做neural network的时候，通常都是从一个很小的、接近于0的值开始初始参数的，而做update的时候，通常都是让参数离0越来越远，但是regularization要达到的目的，就是希望我们的参数不要离0太远。</p><p>如果你做的是Early Stopping，它会减少update的次数，其实也会避免你的参数离0太远，这跟regularization做的事情是很接近的。所以在neural network里面，regularization的作用并没有在SVM来的重要，SVM其实是explicitly把regularization这件事情写在了它的objective function(目标函数)里面，SVM是要去解一个convex optimization problem，因此它解的时候不一定会有iteration的过程，它不会有Early Stopping这件事，而是一步就可以走到那个最好的结果了，所以你没有办法用Early Stopping防止它离目标太远，必须要把regularization explicitly加到loss function里面去。</p><h4 id="3-3-Dropout"><a href="#3-3-Dropout" class="headerlink" title="3.3. Dropout"></a>3.3. Dropout</h4><p>我们先来介绍dropout是怎么做的，然后再来解释为什么这样做。</p><h5 id="3-3-1-How-to-do-Dropout"><a href="#3-3-1-How-to-do-Dropout" class="headerlink" title="3.3.1 How to do Dropout"></a>3.3.1 How to do Dropout</h5><p><strong>Training</strong></p><p>在training的时候，每次update参数之前，我们对每一个neuron(也包括input layer的“neuron”)做sampling(抽样) ，每个neuron都有p%的几率会被丢掉，如果某个neuron被丢掉的话，跟它相连的weight也都要被丢掉，实际上就是每次update参数之前都通过抽样只保留network中的一部分neuron来做训练。做完sampling以后，network structure就会变得比较细长了，然后再去train这个细长的network。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711210658.png" style="zoom:50%;"></p><p>注：每次update参数之前都要做一遍sampling，所以每次update参数的时候，拿来training的network structure都是不一样的；你可能会觉得这个方法跟前面提到的Maxout会有一点像，但实际上，Maxout是每一笔data对应的network structure不同，而Dropout是每一次update参数时（每一个minibatch）的network structure都是不同的。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711210704.png" style="zoom:50%;"></p><p>当你在training的时候使用dropout，得到的performance其实是会变差的，因为某些neuron在training的时候莫名其妙就会消失不见，但这并不是问题，因为：</p><p><strong>Dropout真正要做的事情，就是要让你在training set上的结果变差，但是在testing set上的结果是变好的</strong>。</p><p>所以如果你遇到的问题是在training set上得到的performance不够好，你再加dropout，就只会越做越差；我们应该要懂得，不同的problem需要用不同的方法去解决，而不是胡乱使用，dropout就是针对testing set的方法，当然不能够拿来解决training set上的问题。</p><p><strong>Testing</strong></p><p>在使用dropout方法做testing的时候要注意两件事情：</p><ul><li><strong>testing的时候不做dropout，所有的neuron都要被用到</strong>；</li><li><strong>假设在training的时候，dropout rate是p%，从training data中被learn出来的所有weight都要乘上(1-p%)才能被当做testing的weight使用</strong>。</li></ul><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711210721.png" style="zoom:50%;"></p><h5 id="3-3-2-Why-Dropout？"><a href="#3-3-2-Why-Dropout？" class="headerlink" title="3.3.2. Why Dropout？"></a>3.3.2. Why Dropout？</h5><p><strong>为什么dropout会有用？</strong></p><p>直觉的想法是：在training的时候，会丢掉一些neuron，就好像是你要练轻功的时候，会在脚上绑一些重物；然后，你在实际战斗的时候，就是实际testing的时候，是没有dropout的，就相当于把重物拿下来，所以你就会变得很强（老火影忍者了）。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711210733.png" style="zoom:50%;"></p><p>另一个直觉的想法是：neural network里面的每一个neuron就是一个学生，那大家被连接在一起就好像要组队做final project，总是有人会拖后腿，就是他会dropout，所以假设你觉得自己的队友会dropout，这个时候你就会想要好好做，然后去carry这个队友，这就是training的过程。那实际在testing的时候，其实大家都有好好做，没有人需要被carry，由于每个人都比一般情况下更努力，所以得到的结果会是更好的，这也就是testing的时候不做dropout的原因。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711210913.png" style="zoom:50%;"></p><p><strong>为什么training和testing使用的weight是不一样的呢？</strong></p><p>直觉的解释是这样的：假设现在的dropout rate是50%，那在training的时候，你总是期望每次update之前会丢掉一半的neuron，就像下图左侧所示，在这种情况下你learn好了一组weight参数，然后拿去testing。但是在testing的时候是没有dropout的，所以如果testing使用的是和training同一组weight，那左侧得到的output z和右侧得到的output z‘，它们的值其实是会相差两倍的，即$z’≈2z$，这样会造成testing的结果与training的结果并不match，最终的performance反而会变差。这时就需要把右侧testing中所有的weight乘上0.5，然后做normalization，这样z就会等于z’，使得testing的结果与training的结果是比较match的。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711210919.png" style="zoom:50%;"></p><p><strong>Dropout is a kind of ensemble</strong></p><p>在文献上有很多不同的观点来解释为什么dropout会work，其中一种比较令人信服的解释是：<strong>dropout是一种终极的ensemble（集成）的方法</strong>。ensemble的方法在比赛的时候经常用得到，它的思想是，我们有一个很大的training set，那你每次都只从这个training set里面sample一部分的data出来，像下图一样，抽取了set1,set2,set3,set4。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711210926.png" style="zoom:50%;"></p><p>我们之前在讲bias和variance的trade off的时候说过，打靶有两种情况：</p><ul><li>一种是因为bias大而导致打不准(参数过少)</li><li>另一种是因为variance大而导致打不准(参数过多)</li></ul><p>假设我们今天有一个很复杂的model，它往往是bias比较准，但variance很大的情况，如果你有很多个笨重复杂的model，虽然它们的variance都很大，但取平均后，结果往往就会很准。所以ensemble做的事情，就是利用这个特性，我们从原来的training data里面sample出很多subset，然后train很多个model，每一个model的structure甚至都可以不一样；在testing的时候，丢了一笔testing data进来，使它通过所有的model，分别得到结果，然后把这些结果平均起来当做最后的output。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711210931.png" style="zoom:50%;"></p><p>如果你的model很复杂，这一招往往是很有用的。random forest(随机森林)也是实践这种思想的一个方法，也就是如果用一个decision tree，它的效果会很弱，也很容易overfitting，而如果采用random forest，它就没有那么容易overfitting。</p><p><strong>为什么dropout是一个终极的ensemble方法呢？</strong></p><p>在training network的时候，每次拿一个minibatch出来就做一次update，而根据dropout的特性，每次update之前都要对所有的neuron进行sample，因此每一个minibatch所训练的network structure都是不同的。</p><p>假设我们有M个neuron，每个neuron都有可能drop或不drop，所以总共可能的network数量有$2^M$个；所以当你在做dropout的时候，相当于是在用很多个minibatch分别去训练很多个network(一个minibatch一般设置为100笔data)，当做了有限次的update之后，就相当于train了很多种不同的network，最多可以训练到$2^M$个network。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711210935.png" style="zoom:50%;"></p><p>每个network都只用一个minibatch的data来train，可能会让人感到不安，一个batch才100笔data，怎么train一个network呢？其实没有关系，因为这些<strong>不同的network之间的参数是shared</strong>，也就是说，虽然一个network只能用一个minibatch来train，但同一个weight可以在不同的network里被不同的minibatch train，所以同一个weight实际上是被所有没有丢掉它的network一起share的，它是拿所有这些network的minibatch合起来一起train的结果。</p><p>如果按照这个思路来实际操作会遇到这样的问题：我们train出来的network实在太多了，没有办法每一个network都丢一个input进去，再把它们的output平均起来，这样运算量太大了。</p><p>那dropout最神奇的地方就在于，它<strong>没有把这些network分开考虑，而是用一个完整的network</strong>，这个network的weight是用之前那一把network train出来的对应weight乘上(1-p%)，然后再把手上这笔testing data丢进这个完整的network，得到的output跟network分开考虑的ensemble的output，是惊人的相近。也就是说下图左侧ensemble的做法和右侧dropout的做法，得到的结果是approximate(近似)的。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711210939.png" style="zoom:50%;"></p><p><strong>举例说明dropout和ensemble的关系</strong></p><p>这里用一个例子来解释：我们train一个下图右上角所示的简单的network，它只有一个neuron，activation function是linear的，并且不考虑bias，这个network经过dropout训练以后得到的参数分别为$w_1,w_2$，那给它input $x_1,x_2$，得到的output就是$z=w_1 x_1+w_2 x_2$</p><p>如果我们今天要做ensemble的话，theoretically就是像下图这么做，每一个neuron都有可能被drop或不drop，这里只有两个input的neuron，所以我们一共可以得到2^2=4种network。我们把手上这笔testing data $x_1,x_2$丢到这四个network中，分别得到4个output：$w_1x_1+w_2x_2,w_2x_2,w_1x_1,0$，然后根据ensemble的思路，把这四个network的output相加然后取平均，得到的结果是$\frac{1}{2}(w_1x_1+w_2x_2)$。</p><p>那根据dropout的想法，我们把从training中得到的参数$w_1,w_2$乘上(1-50%)，作为testing network里的参数，也就是$w’_1,w’_2=(1-50\%)(w_1,w_2)=0.5w_1,0.5w_2$。那可以发现，在这个最简单的case里面，用不同的network structure做ensemble这件事情，跟我们用一整个network，并且把weight乘上一个值而不做ensemble所得到的output，其实是一样的。</p><p><img src="/2020/07/11/ML%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89Tips-for-Deep-Learning/QQ图片20200711210944.png" style="zoom:50%;"></p><p>值得注意的是，<strong>只有是linear的network，才会得到上述的等价关系</strong>，如果network是非linear的，ensemble和dropout是不equivalent的；但是，dropout最后一个很神奇的地方是，虽然在non-linear的情况下，它是跟ensemble不相等的，但最后的结果还是会work，会很接近。</p><p><strong>如果network很接近linear的话，dropout所得到的performance会比较好，而ReLU和Maxout的network相对来说是比较接近于linear的，所以我们通常会把含有ReLU或Maxout的network与Dropout配合起来使用</strong>。</p>]]></content>
    
    <summary type="html">
    
      本文从改善模型在Training Data上的表现和在Testing Data上表现，这两个方面介绍了Deep Learning的几个Tips，前者包括New activation function和Adaptive Learning Rate，后者包括Early Stopping，Regularization和Dropout。
    
    </summary>
    
    
      <category term="Deep Learning" scheme="http://nekomoon404.github.io/categories/Deep-Learning/"/>
    
    
      <category term="ReLU" scheme="http://nekomoon404.github.io/tags/ReLU/"/>
    
      <category term="Maxout" scheme="http://nekomoon404.github.io/tags/Maxout/"/>
    
      <category term="Adam" scheme="http://nekomoon404.github.io/tags/Adam/"/>
    
      <category term="Regularization" scheme="http://nekomoon404.github.io/tags/Regularization/"/>
    
      <category term="Dropout" scheme="http://nekomoon404.github.io/tags/Dropout/"/>
    
  </entry>
  
  <entry>
    <title>DL笔记（6）Convolutional Neural Network（CNN）</title>
    <link href="http://nekomoon404.github.io/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/"/>
    <id>http://nekomoon404.github.io/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/</id>
    <published>2020-07-10T13:38:47.000Z</published>
    <updated>2020-07-10T14:38:47.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-Why-CNN-for-Image"><a href="#1-Why-CNN-for-Image" class="headerlink" title="1.Why CNN for Image?"></a>1.Why CNN for Image?</h3><h4 id="1-1-CNN-vs-DNN"><a href="#1-1-CNN-vs-DNN" class="headerlink" title="1.1. CNN vs DNN"></a>1.1. CNN vs DNN</h4><p><strong>Convolutional Neural Network，CNN（卷积神经网络）</strong>常常被用在影像辨识领域。当然也可以用一般的neural network来做影像处理，不一定要用CNN，比如做图像的分类，就可以去train一个neural network，它的input是一张图片，用pixel来表示这张图片，即一个很长的vector，而output则是由图像类别组成的vector，假设你有1000个类别，那output就有1000个dimension。</p><p>但是我们会遇到这样的问题：实际上，在train neural network的时候，我们会有一种期待：在这个network structure里面的每一个neuron，都应该代表了一个最基本的classifier；事实上，在文献中，根据训练的结果，也有很多人得到这样的结论，举例来说，下图中：</p><ul><li>第一层layer的neuron，它就是最简单的classifier，它做的事情就是detect有没有绿色出现、有没有黄色出现、有没有斜的条纹出现等等；</li><li>第二层layer，它detect更复杂的东西，根据第一个layer的output，它如果看到直线横线，就是窗框的一部分；如果看到棕色的直条纹就是木纹；看到斜条纹加灰色的，这个有可能是轮胎的一部分等等；</li><li>第三层hidden layer再根据第二层hidden layer的output，会做更复杂的事情，比如当某一个neuron看到蜂巢，它就会被activate；当某一个neuron看到车子，它就会被activate；当某一个neuron看到人的上半身，它就会被activate等等。</li></ul><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200710215101.png" style="zoom: 50%;"></p><p>但如果直接用一般的<strong>fully connected feedforward network来做图像处理</strong>的时候，<strong>往往会需要太多的参数</strong>。举例来说，假设我们的网络需要辨识的是100*100  pixel的彩色图片，它的分辨率是100*100，那这其实是很小张的image了。然后需要把他转换成一个vector，总共有100*100*3个pixel(如果是彩色的图的话，每个pixel其实需要3个value，即RGB值来描述它的)，那input vector就是30000维；如果input vector是三万维，又假设hidden layer有1000个neuron，那仅仅是第一层hidden layer的参数就已经有30000*1000个了，这样参数就太多了，train network的成本太高。</p><p>那<strong>CNN做的事情其实是，来简化这个neural network的架构</strong>，我们可以根据自己的知识和对图像处理的理解，一开始就把某些实际上用不到的参数给过滤掉。虽然CNN看起来它的运作比较复杂，但事实上，它的模型比DNN还要更简单，我们就是用prior knowledge，去把原来fully connected的layer里面的一些参数拿掉，就变成CNN。</p><h4 id="1-2-Three-Property-for-CNN-theory-base"><a href="#1-2-Three-Property-for-CNN-theory-base" class="headerlink" title="1.2. Three Property for CNN theory base"></a>1.2. Three Property for CNN theory base</h4><p>为什么我们有可能把一些参数拿掉？为什么我们有可能只用比较少的参数就可以来做图像处理这件事情？下面列出三个对影像处理的观察：(<strong>这也是CNN架构提出的基础所在</strong>)</p><ul><li><strong>Some patterns are much smaller than the whole image</strong></li></ul><p>在影像处理中，如果network的第一层hidden layer中的neuron要做的事情是侦测有没有一种东西、一种pattern(图案样式)出现，那大部分的pattern其实是比整张image要小的（比如鸟会出现而图片的中央，而其他地方是背景），所以对一个neuron来说，想要侦测有没有某一个pattern出现，它其实并不需要看整张image，只需要看这张image的一小部分。</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200710220343.png" style="zoom:50%;"></p><p>比如现在有一张鸟的图片，那第一层hidden layer的某一个neuron的工作是，检测有没有鸟嘴的存在（可能还有一些neuron侦测有没有鸟嘴的存在、有一些neuron侦测有没有爪子的存在、有一些neuron侦测有没有翅膀的存在、有没有尾巴的存在，之后合起来，就可以辨识图片中有没有一只鸟），那它其实并不需要看整张图，只要给neuron看这个小的红色杠杠里面的区域，它就可以知道这是不是一个鸟嘴。所以，<strong>每一个neuron其实只要连接到一个小块的区域就好，它不需要连接到整张完整的图，因此也对应着更少的参数</strong>。</p><ul><li><strong>The same patterns appear in different regions</strong></li></ul><p>同样的pattern，可能会出现在image的不同部分，但是它们有同样的形状、代表的是同样的含义，因此它们也可以用同样的neuron、同样的参数，被同一个detector检测出来。</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200710220348.png" style="zoom: 50%;"></p><p>比如上面两张图中分别有一个处于左上角的鸟嘴和一个处于中央的鸟嘴，但我们并不需要训练两个不同的detector去专门侦测左上角有没有鸟嘴和中央有没有鸟嘴这两件事情，这样做太冗余了，我们要cost down(降低成本)，我们并不需要有两个neuron、两组不同的参数来做duplicate(重复一样)的事情，所以<strong>我们可以要求这些功能几乎一致的neuron共用一组参数，它们share同一组参数就可以帮助减少总参数的量</strong>。</p><ul><li><strong>Subsampling the pixels will not change the object</strong></li></ul><p>我们可以对一张image做subsampling(二次抽样)，假如你把它奇数行、偶数列的pixel拿掉，image就可以变成原来的四分之一大小，而且并不会影响人对这张image的理解。所以，<strong>可以利用subsampling把image变小，从而减少需要的参数量</strong>。</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200710220351.png" style="zoom:50%;"></p><h3 id="2-The-whole-CNN-structure"><a href="#2-The-whole-CNN-structure" class="headerlink" title="2. The whole CNN structure"></a>2. The whole CNN structure</h3><p>CNN的结构可以这样理解：首先，input data以后，它会先通过Convolution的layer，接下来做Max Pooling，然后再去做Convolution，再做Maxi Pooling…，这个process可以反复进行多次(重复次数需要事先决定)，这就是network的架构。当做完先前决定的convolution和max pooling的次数后，接着做Flatten（将矩阵展开成vector），最后把Flatten output放到一般的Fully connected network里面去，最终得到输出的结果。</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200710221023.png" style="zoom:50%;"></p><p>我们基于之前提到的三个对影像处理的观察，设计了CNN这样的架构，第一个是要侦测一个pattern，不需要看整张image，只要看image的一个小部分；第二个是同样的pattern会出现在一张图片的不同区域；第三个是我们可以对整张image做subsampling。那<strong>前面这两个property，是用convolution的layer来处理的；而第三个property，是用max pooling来处理的</strong>。</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200710221026.png" style="zoom:50%;"></p><h4 id="2-1-Convolution"><a href="#2-1-Convolution" class="headerlink" title="2.1. Convolution"></a>2.1. Convolution</h4><p>假设现在我们的network的input是一张6*6的image，图像是黑白的，因此每个pixel只需要用一个value来表示，而在convolution layer里面，有很多<strong>Filter</strong>，每一个Filter，其实就相当于是Fully connected layer里的一个neuron。</p><ul><li><strong>Property 1</strong></li></ul><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200710221954.png" style="zoom:50%;"></p><p>每一个Filter其实就是一个matrix，这个matrix里面每一个element的值，就跟那些neuron的weight和bias一样，是network的parameter，它们具体的值都是通过Training data学出来的，而不是人去设计的。上图中每一个Filter是3*3的size，意味着它就是在侦测一个3*3的pattern，<strong>当它侦测的时候，并不会去看整张image，它只看一个3*3范围内的pixel，就可以判断某一个pattern有没有出现</strong>，这就实现了property 1。</p><ul><li><strong>Property 2</strong></li></ul><p>这个Filter是从image的左上角开始，做一个slide window，每次向右<strong>挪动一定的距离</strong>，<strong>这个距离就叫做stride</strong>，由你自己设定，每次filter停下的时候就跟image中对应的3*3的matrix做一个内积(相当于展开成vector再作内积，其实就是相同位置的值相乘并累计求和)。</p><p>这里假设stride=1，那么我们的Filter每次移动一格，当它碰到image最右边的时候，就从下一行的最左边开始重复进行上述操作，经过一整个convolution的process，最终得到下图所示的红色的4*4 matrix。</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200710221959.png" style="zoom:50%;"></p><p>观察上图中的Filter1，它斜对角的地方是1,1,1，所以它的工作就是detect有没有连续的从左上角到右下角的1,1,1出现在这个image里面，检测到的结果已在上图中用蓝线标识出来，此时Filter得到的卷积结果的左上和左下得到了最大的值，这就代表说，该Filter所要侦测的pattern出现在image的左上角和左下角。<strong>同一个pattern出现在image左上角的位置和左下角的位置，并不需要用到不同的Filter，我们用Filter1就可以侦测出来</strong>，这就实现了property 2。</p><p><strong>Feature Map</strong></p><p>在一个convolution的layer里面，它会有很多的filter，不一样的filter会有不一样的参数，但是这些filter做卷积的过程都是一模一样的，把filter2和image做完convolution以后，就会得到另外一个的4*4 matrix，那这个蓝色的4*4 matrix跟之前红色的4*4matrix合起来，就叫做<strong>Feature Map(特征映射)</strong>，有多少个filter，对应就有多少个映射后的image。</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200710222003.png" style="zoom: 50%;"></p><p><strong>CNN对不同scale的相同pattern的处理</strong>上存在一定的困难，由于现在每一个filter size都是一样的，这意味着，如果你今天有同一个pattern，它有不同的size，有大的鸟嘴，也有小的鸟嘴，CNN并不能够自动处理这个问题；DeepMind曾经发过一篇paper，上面提到了当你input一张image的时候，它在CNN前面，再接另外一个network，这个network做的事情是，它会output一些scalar，告诉你说，它要把这个image的里面的哪些位置做旋转、缩放，然后，再丢到CNN里面，这样你其实会得到比较好的performance。</p><p><strong>Colorful image</strong></p><p>刚才举的例子是黑白的image，input的是一个2维的matrix。彩色的image的每一个pixel就是由RGB组成的，相当于3个matrix叠在一起，可以理解是多了一维“深度”。这时Filter也会跟着input作相应的变化，假如上面的例子中输入的是彩色图片，input就是3*6*6的，Filter相应就是3*3*3。在做convolution的时候，就是把<strong>这个Filter的27个值跟image里对应区块的27个值做内积，即三个channel是一起处理的，经过convolution之后仍然得到一个$4*4$的matrix</strong>（注意不是$4<em>4</em>3$），这样在做完这一层的convolution之后，有多少个Filter，得到的Feature Map就有多少“层”，和处理黑白image是一样的。</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200710222007.png" style="zoom:50%;"></p><h4 id="2-2-Convolution-V-s-Fully-connected"><a href="#2-2-Convolution-V-s-Fully-connected" class="headerlink" title="2.2. Convolution V.s. Fully connected"></a>2.2. Convolution V.s. Fully connected</h4><p><strong>filter是特殊的”neuron“</strong></p><p>接下来要讲的是，convolution跟fully connected有什么关系。你可能觉得会觉得它是一个很特别的operation，感觉跟neural network没半毛钱关系┐(ﾟ～ﾟ)┌ ，但其实它就是一个neural network。</p><p>convolution其实就相当于是fully connected的layer把一些weight删掉，下图中绿色方框标识出的feature map的output，其实就是hidden layer的neuron的output。</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200710225714.png" style="zoom:50%;"></p><p>那为什么是这样的呢(。-`ω´-)？如下图，我们在做convolution的时候，把Filter放在image的左上角，然后再去做inner product，得到一个值3；这件事情等同于，我们现在把这个image的6*6的matrix拉直变成右边这个用于input的vector（竖着的一长条），然后有一个红色的neuron，这些input经过这个neuron之后，得到的output是3。</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200710225718.png" style="zoom:50%;"></p><p><strong>每个“neuron”只检测image的部分区域</strong></p><p>那这个neuron的output怎么来的呢？这个neuron实际上就是由Filter转化而来的，我们把filter放在image的左上角，此时filter考虑的就是和它重合的9个pixel，假设你把这一个6*6的image的36个pixel拉成直的vector作为input，那这9个pixel分别就对应着右侧编号1，2，3的pixel，编号7，8，9的pixel跟编号13，14，15的pixel。</p><p>如果我们说这个filter和image matrix做inner product以后得到的output 3，就是input vector经过某个neuron得到的output 3的话，这就代表说存在这样一个neuron，这个neuron带weight的连线，就只连接到编号为1，2，3，7，8，9，13，14，15的这9个pixel而已，而这个neuron和这9个pixel连线上所标注的的weight就是filter matrix里面的这9个数值。</p><p>作为对比，<strong>Fully connected的neuron是必须连接到所有36个input上</strong>的，但是，我们<strong>现在只用连接9个input</strong>，因为我们知道要detect一个pattern，不需要看整张image，看9个input pixel就够了，所以当我们这么做的时候，就用了比较少的参数</p><p><strong>“neuron”之间共享参数</strong></p><p>当我们把filter做stride = 1的移动后，通过filter和image matrix的内积得到另外一个output值-1，我们假设这个-1是另外一个neuron的output，那这个neuron会连接到哪些input呢？下图中这个框起来的地方正好就对应到pixel 2，3，4，pixel 8，9，10跟pixel 14，15，16</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200710225722.png" style="zoom:50%;"></p><p>你会发现output为3和-1的这两个neuron，它们的作用是分别去检测在image的两个不同位置上是否存在某个相同pattern，它们的weight是一样的。但在Fully connected layer里它们通常做的是两件不同的事情，每一个neuron应该有自己独立的weight。</p><p>来看我们的convolution，首先是把每一个neuron前面连接的weight减少了，然后我们强迫某些neuron(比如上图中output为3和-1的两个neuron)，它们一定要共享一组weight，虽然这两个neuron连接到的pixel对象各不相同，但它们用的weight都必须是一样的(9=3*3对应着filter的元素个数，这些weight也就是filter内部的元素值，上图中圆圈的颜色与连线的颜色一一对应，PS：李老师讲课真的很用心)，等于filter里面的元素值，这件事情就叫做<strong>weight share</strong>。这样的两个方法就会让<strong>convolution里的参数数量相比于fully connected layer的大大减少</strong>。可以说CNN的本质，就是减少参数的过程。</p><p>看到这里你可能会问(´ω｀)，这样的network该怎么搭建，又该怎么去train呢？其实现在这些都是用toolkit（Tensorflow, Pytorch等等）来完成的，所以你大概不会自己去写；如果要自己写的话，它其实就是跟原来的Backpropagation用一模一样的做法，只是有一些weight就永远是0，你就不用去train它，它就永远是0。然后，<strong>怎么让某些neuron的weight值永远都是一样呢</strong>？就可以先用一般的Backpropagation的方法，对每个weight都去算出gradient，再把本来要tight在一起、要share weight的那些weight的gradient取平均，然后让这些weight用这个相同的平均值取update就好了。</p><h4 id="2-3-Max-Pooling"><a href="#2-3-Max-Pooling" class="headerlink" title="2.3. Max Pooling"></a>2.3. Max Pooling</h4><p><strong>Operation of max pooling</strong></p><p>相较于convolution，max pooling是比较简单的，它相当于实现了property3，即subsampling，由Filter 1得到一个4*4的matrix，由Filter 2得到另外一个4*4的matrix。接下来，我们把output四个分为一组，每一组里面通过选取平均值或最大值的方式，把原来4个value合成一个 value，这种subsampling的方式就可以让你的“image”缩小。</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200711103949.png" style="zoom:50%;"></p><p>但是如果取Maximum放到network里面，不就没法微分了吗？其实是可以的，后面的章节会讲到Maxout network，会告诉你怎么用微分的方式来处理它。</p><p><strong>Convolution + Max Pooling</strong></p><p>做完一次convolution加一次max pooling，我们就把原来6*6的image，变成了一个 <strong>Filter个数<em>2\</em>2</strong> 的image；如下图中是两个Filter，那经过一次convolution+max pooling得到的image就是$2<em>2</em>2$维的。这是一个新的比较小的image，它表示的是不同区域上提取到的特征，不同的Filter检测的是该image同一区域上的不同特征属性。</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200711103624.png" style="zoom:50%;"></p><p>Convolution + Max Pooling可以repeat很多次，你可以把得到的这个比较小的image，再次进行convolution和max pooling的操作，得到一个更小的image，依次类推。</p><p>你可能会问：假设我第一个convolution有25个filter，通过这些filter得到25个feature map，然后repeat的时候第二个convolution也有25个filter，那这样做完，我是不是会得到25*25个feature map呢？</p><p>其实不是这样的，convolution的input是会考虑“深度”的，比如在第一次convolution+max pooling后得到的是$25<em>6</em>6$的matrix，那么第二层convolution的FIlter就可以是$25<em>3</em>3$了，这样第二次得到的feature map也是25个。所以<strong>每次convolution+max pooling得到的matrix的“层数”或者说“深度”，只和这一层的convolution中的Filter数有关，即等于这一层的convolution中的Filter数</strong>。</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200711103640.png" style="zoom:50%;"></p><h4 id="2-4-Flatten"><a href="#2-4-Flatten" class="headerlink" title="2.4. Flatten"></a>2.4. Flatten</h4><p>做完convolution和max pooling之后，就是FLatten和Fully connected Feedforward network的部分。Flatten的意思是，把左边的feature map“拉直”成一个vector。然后把这个vector丢进一个Fully connected Feedforward network，最后得到输出的结果。</p><p>也就是说，我们之前通过CNN提取出了image的feature，它相较于原先一整个image的vetor，少了很大一部分内容，因此需要的参数也大幅度地减少了，但最终也还是要丢到一个Fully connected的network中去做最后的分类工作。</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200711105557.png" style="zoom:50%;"></p><h4 id="2-5-Example-CNN-in-Keras"><a href="#2-5-Example-CNN-in-Keras" class="headerlink" title="2.5. Example: CNN in Keras"></a>2.5. Example: CNN in Keras</h4><p>过程可以概括为：</p><ul><li>假设我们input是一个1*28*28的image；</li><li>通过25个Filter的convolution layer，每个Filter的size是3<em>3，如果不考虑image边缘处的处理的话，得到的每个channel会是26\</em>26的，因此通过第一个convolution得到25*26*26的“cubic image”；</li><li>接着做Max pooling，把2*2的pixel分为一组，然后从里面选一个最大的组成新的image，得到25*13*13的image；</li><li>再做一次convolution，假设这次选择50个filter，每个filter size是25<em>3\</em>3，output得到50*11*11的image；</li><li>再做一次Max Pooling，也是把2*2的pixel分为一组，然后从里面选最大值，output得到50*5*5的image；</li><li>最后用Flatten将这个image“拉直”成一个1250维的vector，把这个vector作为一个Fully Connected Feedforward network的输入，这样我们的CNN的structure就搭建完成了。</li></ul><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200711110051.png" style="zoom: 50%;"></p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200711110112.png" style="zoom:50%;"></p><h3 id="3-What-does-CNN-learn"><a href="#3-What-does-CNN-learn" class="headerlink" title="3. What does CNN learn?"></a>3. What does CNN learn?</h3><p>很多人会说Deep Learning就是一个黑盒子，你learn出来以后，根本就不知道为什么是这样子，于是你会感觉它很intelligent⊙(・◇・)？，但其实我们可以从CNN设计的思路出发来分析它在learn的过程中学到了什么。</p><h4 id="3-1-what-does-filter-do"><a href="#3-1-what-does-filter-do" class="headerlink" title="3.1. what does filter do"></a>3.1. what does filter do</h4><p>还是用上面的例子，第一层convolution的Filter比较容易理解，每一个Filter是一个3*3的matrix，它对应到image中3*3范围内的9个pixel，所以这个Filter的值就反映着它在detect什么东西。</p><p>但第二层convolution中的Filter的作用就比较难理解了，每个Filter的size是$25<em>3</em>3$，这些Filter的input并不是pixel，而是做完一次convolution+max pooling的结果，因此Filter考虑的范围并不是3*3=9个pixel，而是一个长宽为3*3，高为25的“cubic”，filter实际在image上看到的范围是远大于9个pixel的，就算把它的weight拿出来看，也不知道它在做什么。</p><p>那我们可以通过下面的方法来分析一个Filter它做的事情是什么：</p><p>第二层convolution里面的50个Filter，每一个Filter的output是一个11*11的matrix，假设现在把第k个filter的output拿出来，如下图所示，这个matrix里的每一个element，记为$a^k_{ij}$，上标$k$表示这是第$k$个filter，下标$ij$表示它在这个matrix里的第$i$行，第$j$列。</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200711112219.png" style="zoom:50%;"></p><p>定义$a^k$为<strong>Degree of the activation of the k-th filter</strong>，这个值表示现在的第k个filter，它有多被activate，直观来讲就是描述现在input的东西跟第k个filter有多接近，它对filter的“激活程度”有多少。$a^k$等于，第k个filter与input进行卷积所输出的output里所有element的summation，以上图为例，就是这11*11的output matrix里所有元素之和：</p><script type="math/tex; mode=display">a^k=\sum\limits^{11}_{i=1}\sum\limits^{11}_{j=1} a^k_{ij}</script><p>接下来我们想要知道第k个filter的作用是什么，那就<strong>找一张image</strong>，<strong>这张image可以让第k个filter被activate的程度最大</strong>；即找一个image x*，它可以让我们定义的activation的degree $a^k$最大：</p><script type="math/tex; mode=display">x^*=\arg \max\limits_x a^k</script><p>之前我们求minimize用的是gradient descent，那现在我们求Maximum用gradient ascent(梯度上升法)。</p><p>这个方法还是颇为神妙的(๑´ㅂ`๑) ，现在是把input x作为要找的参数，对它去用gradient descent或ascent进行update，在这个task里面model的参数是固定的，要用gradient ascent去update这个x，让它可以使degree of activation最大。</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200711112240.png" style="zoom:50%;"></p><p>上图就是得到的结果，50个filter理论上可以分别找50张image使对应的activation最大，这里仅挑选了其中的12张image作为展示，这些image有一个共同的特征，它们里面都是一些<strong>反复出现的某种texture(纹路)</strong>，<strong>比如说第三张image上布满了小小的斜条纹，这意味着第三个filter的工作就可以理解为是在detect图上有没有斜条纹</strong>，要知道现在每个filter检测的都只是图上一个小小的范围而已，所以图中一旦出现一个小小的斜条纹，这个filter就会被activate，相应的output也会比较大，所以如果整张image上布满这种斜条纹的话，这个filter的activation程度是最大的，相应的output值也会达到最大。</p><p>因此我们可以用这种方法去研究CNN中的每个filter的作用是去detect怎样的pattern，或者说texture。</p><h4 id="3-2-what-does-neuron-do"><a href="#3-2-what-does-neuron-do" class="headerlink" title="3.2. what does neuron do"></a>3.2. what does neuron do</h4><p>做完convolution和max pooling之后，会将结果用Flatten展开，然后丢到Fully connected neural network里面去，之前已经搞清楚了filter是做什么的，那我们也想要知道在这个neural network里的每一个neuron是做什么的，那就可以对刚才的做法如法炮制。</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200711114024.png" style="zoom:50%;"></p><p>我们定义第$j$个neuron的output就是$a_j$，接下来就用gradient ascent的方法去找一张image $x<em>$，这个$x</em>$作为输入可以使$a_j$的值最大，即：</p><script type="math/tex; mode=display">x^*=\arg \max\limits_x a^j</script><p>找到的结果如上图所示，同理这里仅取出其中的9张image作为展示，你会发现这9张图跟之前filter所观察到的情形是很不一样的，刚才我们观察到的是类似纹路的东西，那是因为每个filter考虑的只是图上一部分的vision，所以它detect的是一种texture；但是在做完Flatten以后，每一个neuron不再是只看整张图的一小部分，它现在的工作是看整张图。</p><h4 id="3-3-what-about-output"><a href="#3-3-what-about-output" class="headerlink" title="3.3. what about output"></a>3.3. what about output</h4><p>接下来考虑CNN的output，由于是手写数字识别的demo，因此这里的output就是10维。同样地，我们把某一维拿出来，然后同样去找一张image x，使这个维度的output值最大，即</p><script type="math/tex; mode=display">x^*=\arg \max_x y^i</script><p>可以想象说既然现在每一个output的每一个dimension就对应到一个数字，那如果我们去找一张image x，它可以让对应到数字1的那个output layer的neuron的output值最大，那这张image显然应该看起来会像是数字1，你甚至可以期待搞不好用这个方法就可以让machine自动画出数字⊙(・◇・)？</p><p>但实际上得到的结果却是如下图所示：</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200711114028.png" style="zoom:50%;"></p><p>上面的每一张图分别对应着数字0-8，发现可以让数字1对应neuron的output值最大的image看起来一点也不像1；为了验证程序有没有bug，把上述得到的image作为testing data丢到CNN里面，结果classify的结果确实对应着的数字0-8。看来这个CNN所学到的东西跟人类一般的想象认知还是有差别的。</p><p>那有没有办法让上面这个图看起来更像数字呢？想法是这样的：一张图是不是一个数字，它会有一些基本的假设，比如这些image，显然人类手写出来的东西就不是长这个样子的。所以<strong>要对x做一些regularization，做一些constraint</strong>(限制约束)，我们应该告诉machine说，虽然有一些x可以让y很大，但是它们不是数字。</p><p>最简单的加constraint的想法是：image中白色代表的是有墨水、有笔画的地方，而对于一个digit来说，整张image上涂白的区域是有限的，像上面这些整张图都是白白的，它一定不会是数字。假设image里的每一个pixel都用$x_{ij}$表示，我们把所有pixel值取绝对值并求和$\sum\limits_{i,j}|x_{ij}|$，这一项其实就是之前提到过的L1的regularization，再用$y^i$减去这一项，得到：</p><script type="math/tex; mode=display">x^*=\arg \max\limits_x (y^i-\sum\limits_{i,j} |x_{ij}|)</script><p>这样我们找出的让上式最大的$x*$，它可以让$y^i$很大的同时，也是让$|x_ij|$的summation越小越好，那我们希望找出来的image，大部分的地方是没有涂颜色的，只有少数数字笔画在的地方才有颜色出现。加上这个constraint以后，得到的结果会像下图右侧所示一样，已经隐约有些可以看出来是数字的形状了</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200711114041.png" style="zoom:50%;"></p><p>如果再加上一些额外的constraint，比如希望相邻的pixel是同样的颜色等等，应该可以得到更好的结果。</p><h4 id="3-4-Deep-Dream"><a href="#3-4-Deep-Dream" class="headerlink" title="3.4. Deep Dream"></a>3.4. Deep Dream</h4><p>那上面讲到的有点“逆向”的思路，我们就可以实现这一一件事：如果你给network一张image，它会在这个image里面加上它看到的东西，做法就是：找一张image输入到CNN训练，然后把某一个convolution layer里面的filter或是fully connected layer里的某一个hidden layer的output拿出来；接下来把本来是positive的dimension值调大，negative的dimension值调小，即让绝对值更大，将它作为我们要找的image的target。</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200711115948.png" style="zoom:50%;"></p><p>然后用gradient descent的方法找一张image x，让它通过这个hidden layer后的output就是你调整后的target，这么做的目的是<strong>让CNN夸大化它看到的东西</strong>——make CNN exaggerates what is sees。也就是说，如果某个filter有被activate，那你让它被activate的更剧烈，CNN可能本来看到了某一样东西的“端倪”，那现在你就让它更“具象化”，或者说“夸大化”。如果把上面这张image拿去做Deep Dream的话，看到的结果就会像下面这个样子（着实是有点吓人｀Д´|）：</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200711115952.png" style="zoom:50%;"></p><h4 id="3-5-Deep-Style"><a href="#3-5-Deep-Style" class="headerlink" title="3.5. Deep Style"></a>3.5. Deep Style</h4><p>Deep Dream还有一个进阶的版本，叫做<strong>Deep Style</strong>，或者叫<strong>Neural Style</strong>，<strong>图片风格迁移</strong>。我们input一张image，Deep Style做的事情就是让machine去修改这张图，让它有另外一张图的风格，如下所示：</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200711115955.png" style="zoom:50%;"></p><center><img src="https://gitee.com/Sakura-gh/ML-notes/raw/master/img/deep-style.png" width="60%;"></center><p>实际上机器做出来的效果惊人的好，具体的做法参考reference：<a href="https://arxiv.org/abs/1508.06576" target="_blank" rel="noopener">A Neural Algorithm of Artistic Style</a></p><p>Deep Style的大致思路是，把原本的image输入到CNN，得到CNN filter的output，代表这张image里面有什么样的content。然后你把呐喊这张图也丢到CNN里面得到filter的output，这时我们在意的是，filter和filter的output之间的correlation，这个correlation代表了这张image的style。</p><p>接下来就用一个CNN去找一张image，<strong>这张image的content像左边的图片</strong>，比如使这张image的filter output的value接近左边的图片的value；同时让<strong>这张image的style像右边的图片</strong>，比如使这张image output的filter之间的correlation像右边这张图片。最终用gradient descent找到一张image，同时可以maximize左边的content和右边的style，它的样子就像上图左下角所示：</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200711121143.png" style="zoom:50%;"></p><h3 id="4-More-Application"><a href="#4-More-Application" class="headerlink" title="4. More Application"></a>4. More Application</h3><h4 id="4-1-Playing-Go"><a href="#4-1-Playing-Go" class="headerlink" title="4.1. Playing Go"></a>4.1. Playing Go</h4><p>除了图像处理，CNN可以被运用到不同的领域，比如广为人知的alphaGo。想要让machine来下围棋，其实一般的neural network也可以帮我们做到这件事情，但采用CNN的话会得到更好的performance。</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200711131904.png" style="zoom:50%;"></p><p>之前举的例子都是把CNN用在图像上面，input是一个matrix，而棋盘就可以表示成一个19*19的matrix，那对CNN来说，就是直接把它当成一个image来看待，然后再output下一步要落子的位置，training process可以通过搜集很多棋谱来train CNN，看到这样的棋局应该有什么样的output，即下一步应该在哪里落子。其实这时supervised的部分，AlphaGo还有reinforcement learning的部分，后面的章节会讲到。</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200711131909.png" style="zoom:50%;"></p><p>回想之前讲过的设计在图像识别中，设计CNN的结构时考虑的三个property：</p><ul><li><strong>Some patterns are much smaller than the whole image</strong></li><li><strong>The same patterns appear in different regions</strong></li><li><strong>Subsampling the pixels will not change the object</strong></li></ul><p>CNN能够应用在Alpha-Go上，是因为围棋有一些特性和图像处理是很相似的。对于property 1，有一些pattern是比整张image要小得多，在围棋中也有同样的现象。在AlphaGo里面，它第一层convolution是用5*5的filter，显然做设计的人了解围棋上最基本的pattern可能都是在5*5的范围内就可以被侦测出来。对于property 2，同样的pattern可能会出现在不同的region，这在围棋中也是存在的，所以可以用同一个detector，来处理这些在不同位置的同样的pattern。</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200711131912.png" style="zoom:50%;"></p><p>但是对于property3，对棋谱做subsampling之后，其所表达的内容明显就和之前的不同的，通过阅读Alpha-go的论文，我们可以知道<strong>AlphaGo的network structure中并没有Max pooling层</strong>，即没有做subampling。可见根据围棋的特性，并不需要在围棋的CNN里面使用用Max pooling这样的构架。</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200711132944.png" style="zoom:50%;"></p><h4 id="4-2-Speech"><a href="#4-2-Speech" class="headerlink" title="4.2. Speech"></a>4.2. Speech</h4><p>CNN也可以用在语音处理上，我们可以<strong>把一段声音表示成spectrogram</strong>，spectrogram的横轴是时间，纵轴则是这一段时间里声音的频率，如下图中是一段“你好”的音频，偏红色代表这段时间里该频率的energy是比较大的，也就对应着“你”和“好”这两个字，spectrogram用颜色来描述某一个时刻不同频率的能量。我们可以把这个spectrogram当作一张image，然后用CNN来判断input的这张image对应着什么样的声音信号，通常用来判断结果的单位可以用phoneme（类似音标）。</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200711133947.png" style="zoom:50%;"></p><p>用CNN处理语言的一个比较特别的点是：<strong>在convolution中通常只考虑在frequency(频率)方向上移动Filter</strong>，而不在时间的序列上移动。</p><p>这是因为在语音里面，CNN的output后面都还会再接别的东西，比如接LSTM之类，它们都已经有考虑时间有关的信息。那在频率上的filter有帮助的原因是，在声音讯号上，比如虽然男生和女生说同样的话看起来这个spectrogram是非常不一样的，但实际上他们的不同只是表现在一个频率的shift而已(整体在频率上的位移)，男生说的“你好”跟女生说的“你好”，它们的pattern其实是一样的，它们的差别可能只是所在的频率范围不同而已，所以filter在frequency的direction上移动是有效的。</p><h4 id="4-3-Text"><a href="#4-3-Text" class="headerlink" title="4.3. Text"></a>4.3. Text</h4><p>CNN也可以用在文字处理上，假设input是一个word sequence，你要做的事情是让machine侦测这个word sequence代表的意思是positive的还是negative的。</p><p>首先把这个word sequence里面的每一个word都用一个vector来表示，vector代表的这个word本身的semantic (语义)，那如果两个word本身含义越接近的话，它们的vector在高维的空间上就越接近，这叫做<strong>word embedding</strong>。</p><p><img src="/2020/07/10/ML%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Convolutional-Neural-Network%EF%BC%88CNN%EF%BC%89/QQ图片20200711133951.png" style="zoom:50%;"></p><p>把一个sentence里面所有word的vector排在一起，它就变成了一张image（一个matrxi），然后把CNN套用到这个image上，但是这时Filter的“高”和image的高是一样的，然后把Filter沿着句子里词汇的顺序来移动，每个filter移动完成之后都会得到一个由内积结果组成的vector，不同的filter就会得到不同的vector，接下来做Max pooling，然后把Max pooling的结果丢到fully connected layer里面，得到最后的output。</p><p>与语音处理不同的是，<strong>在文字处理上，filter只在时间的序列(按照word的顺序)上移动，而不在embedding的dimension上移动</strong>；因为在word embedding里面，不同dimension是independent的，它们是相互独立的，不会出现有两个相同的pattern的情况，所以在这个方向上面移动filter，是没有意义的。</p><p>——————</p><p>这一章举这三个例子是为了说明，虽然CNN很powerful，但在设计network structure去解决新的task的时候，都要根据所要解决的问题的特性，设计出合理合适的strcuture，包括Filter的尺寸，移动的方向，stride的大小；有无Max pooling等等很多因素，而不是生搬硬套已有的模式。所谓<strong>应用之道，存乎一心</strong>。</p>]]></content>
    
    <summary type="html">
    
      本文主要介绍了Convolutional Neural Network，CNN（卷积神经网络）的基本概念和结构，以及Convolution层和Max pooling层的实现方式和作用；相比于DNN，它是如何实现减少参数的。CNN并不是一个黑盒子，我们是可以分析它的learn的过程中学到了什么。最后用CNN应用在Alpha Go，Speech，Text中的三个例子来说明我们应该充分考虑task的特性去设计合理的network strcuture。
    
    </summary>
    
    
      <category term="Deep Learning" scheme="http://nekomoon404.github.io/categories/Deep-Learning/"/>
    
    
      <category term="CNN" scheme="http://nekomoon404.github.io/tags/CNN/"/>
    
      <category term="Convolution" scheme="http://nekomoon404.github.io/tags/Convolution/"/>
    
      <category term="Max pooling" scheme="http://nekomoon404.github.io/tags/Max-pooling/"/>
    
      <category term="Filter" scheme="http://nekomoon404.github.io/tags/Filter/"/>
    
  </entry>
  
  <entry>
    <title>DL笔记（5）Backpropagation</title>
    <link href="http://nekomoon404.github.io/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%885%EF%BC%89Backpropagation/"/>
    <id>http://nekomoon404.github.io/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%885%EF%BC%89Backpropagation/</id>
    <published>2020-07-09T10:58:41.000Z</published>
    <updated>2020-07-09T11:58:41.000Z</updated>
    
    <content type="html"><![CDATA[<p>训练Neural Network依然可以使用此前学过的Gradient Descent的方法来更新参数，基本步骤与linear Regression或Logistic Regression中是相同的，但Neural network中的parameters $\theta=w_1,w_2,…,b_1,b_2,…$里面可能会有将近million个参数。所以现在最大的困难是，如何有效地把这个近百万维的vector给计算出来，这就是Backpropagation要做的事情，<strong>Backpropagation并不是一个和gradient descent不同的training的方法，它只是一个比较有效率的算法</strong>，使得求gradient更有效率。</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%885%EF%BC%89Backpropagation/QQ图片20200709191138.png" style="zoom:40%;"></p><p><strong>Chain Rule</strong></p><p>Backpropagation的数学原理其实很简单，只需记住<strong>Chain Rule 链式法则</strong>。</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%885%EF%BC%89Backpropagation/QQ图片20200709191418.png" style="zoom:40%;"></p><h3 id="Backpropagation"><a href="#Backpropagation" class="headerlink" title="Backpropagation"></a>Backpropagation</h3><p>对整个neural network，定义一个loss function：$L(\theta)=\sum\limits_{n=1}^N l^n(\theta)$，它等于所有training data的loss之和。我们把training data里任意一个样本点$x^n$代到neural network里面，它会output一个$y^n$，我们把这个output跟样本点本身的label标注的target $\hat{y}^n$作cross entropy，这个<strong>交叉熵定义了output $y^n$和target $\hat{y}^n$之间的距离$l^n(\theta)$</strong>，如果cross entropy比较大的话，说明output和target之间距离很远，这个network的parameter的loss是比较大的，反之则说明这组parameter是比较好的。然后summation over所有training data的cross entropy $l^n(\theta)$，得到total loss $L(\theta)$，这就是我们的loss function，用这个$L(\theta)$对某一个参数w做偏微分，表达式如下：</p><script type="math/tex; mode=display">\frac{\partial L(\theta)}{\partial w}=\sum\limits_{n=1}^N\frac{\partial l^n(\theta)}{\partial w}</script><p>从表达式中可知，只需要考虑如何计算对某一笔data的$\frac{\partial l^n(\theta)}{\partial w}$，再将所有training data的cross entropy对参数w的偏微分累计求和，就可以把total loss对某一个参数w的偏微分给计算出来。</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%885%EF%BC%89Backpropagation/QQ图片20200709191916.png" style="zoom:50%;"></p><p>我们先考虑某一个neuron（图中被红色三角形圈住的neuron），假设只有两个input $x_1,x_2$，通过这个neuron，我们先得到$z=b+w_1 x_1+w_2 x_2$，然后经过activation function从这个neuron中output出来，作为后续neuron的input，再经过了很多层的运算之后，会得到最终的output $y_1,y_2$</p><p>接着考虑计算$\frac{\partial l}{\partial w}$，按照chain rule，可以把它拆分成两项，$\frac{\partial l}{\partial w}=\frac{\partial z}{\partial w} \frac{\partial l}{\partial z}$，这两项分别去把它计算出来：</p><ul><li>计算前一项$\frac{\partial z}{\partial w}$的process，称之为<strong>Forward pass</strong>；</li><li>计算后一项$\frac{\partial l}{\partial z}$的process，称之为<strong>Backward pass</strong>。</li></ul><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%885%EF%BC%89Backpropagation/QQ图片20200709193921.png" style="zoom: 40%;"></p><h4 id="Forward-Pass"><a href="#Forward-Pass" class="headerlink" title="Forward Pass"></a>Forward Pass</h4><p>$\frac{\partial z}{\partial w}$这一项计算很简单，$\frac{\partial z}{\partial w_1}=x_1 ,\ \frac{\partial z}{\partial w_2}=x_2$。它的规律是这样的：求$\frac{\partial z}{\partial w}$，就是看$w$前面连接的input是什么，那微分后的$\frac{\partial z}{\partial w}$值就是什么，因此只要计算出neural network里面每一个neuron的output就可以知道任意的$z$对$w$的偏微分：</p><ul><li>比如input layer作为neuron的输入时，$w_1$前面连接的是$x_1$，所以微分值就是$x_1$；$w_2$前面连接的是$x_2$，所以微分值就是$x_2$</li><li>比如hidden layer作为neuron的输入时，那该neuron的input就是前一层neuron的output，于是$\frac{\partial z}{\partial w}$的值就是前一层的z经过activation function之后输出的值(下图中的数据是假定activation function为sigmoid function得到的)</li></ul><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%885%EF%BC%89Backpropagation/QQ图片20200709194132.png" style="zoom: 67%;"></p><h4 id="Backward-Pass"><a href="#Backward-Pass" class="headerlink" title="Backward Pass"></a>Backward Pass</h4><p>$\frac{\partial l}{\partial z}$这一项比较复杂的，这里我们依旧假设activation function是sigmoid function。$z$通过activation function后得到$a$，这个neuron的output是$a=\sigma(z)$，接下来这个a会乘上某一个weight $w_3$，再加上其它的value得到$z’$，它是下一个neuron activation function的input，然后a又会乘上另一个weight $w_4$，再加上其它value得到$z’’$，后面还会经过很多运算，这里我们先考虑下一步会发生什么事情。</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%885%EF%BC%89Backpropagation/QQ图片20200709194628.png" style="zoom: 67%;"></p><p>由Chain Rule，$\frac{\partial l}{\partial z}$可以写成</p><script type="math/tex; mode=display">\frac{\partial l}{\partial z}=\frac{\partial a}{\partial z} \frac{\partial l}{\partial a}</script><p>这里的$\frac{\partial a}{\partial z}$实际上就是activation function的微分(在这里就是sigmoid function的微分)，接下来的问题是$\frac{\partial l}{\partial a}$应该长什么样子呢？a会影响$z’$和$z’’$，而$z’$和$z’’$会影响$l$，所以通过chain rule可以得到</p><script type="math/tex; mode=display">\frac{\partial l}{\partial a}=\frac{\partial z'}{\partial a} \frac{\partial l}{\partial z'}+\frac{\partial z''}{\partial a} \frac{\partial l}{\partial z''}</script><p>这里的$\frac{\partial z’}{\partial a}=w_3$，$\frac{\partial z’’}{\partial a}=w_4$，那$\frac{\partial l}{\partial z’}$和$\frac{\partial l}{\partial z’’}$又该怎么算呢？这里先假设我们已经通过某种方法把$\frac{\partial l}{\partial z’}$和$\frac{\partial l}{\partial z’’}$这两项给算出来了，然后回过头去就可以把$\frac{\partial l}{\partial z}$给轻易地算出来</p><script type="math/tex; mode=display">\frac{\partial l}{\partial z}=\frac{\partial a}{\partial z} \frac{\partial l}{\partial a}=\sigma'(z)[w_3 \frac{\partial l}{\partial z'}+w_4 \frac{\partial l}{\partial z''}]</script><p>那么由Forward pass和Backward就可以得到$\frac{\partial l}{\partial w_1}$：</p><script type="math/tex; mode=display">\frac{\partial l}{\partial w_1}=\frac{\partial z}{\partial w_1} \frac{\partial l}{\partial z}=x_1 \cdot \sigma'(z)[w_3 \frac{\partial l}{\partial z'}+w_4 \frac{\partial l}{\partial z''}]</script><h4 id="换个角度"><a href="#换个角度" class="headerlink" title="换个角度"></a>换个角度</h4><p>我们可以从另外一个观点来看待这个式子。想象现在有另外一个neuron，它不在我们原来的network里面，在下图中它被画成三角形，这个neuron的input就是$\frac{\partial l}{\partial z’}$和$\frac{\partial l}{\partial z’’}$，那input $\frac{\partial l}{\partial z’}$乘上$w_3$，input $\frac{\partial l}{\partial z’’}$乘上$w_4$，它们两个相加再乘上activation function的微分 $\sigma’(z)$，就可以得到output $\frac{\partial l}{\partial z}$</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%885%EF%BC%89Backpropagation/QQ图片20200709194631.png" style="zoom:67%;"></p><p>这张图描述了一个新的“neuron”，它的含义跟图下方的表达式是一模一样的，作这张图的目的是为了方便理解。值得注意的是，这里的<strong>$\sigma’(z)$是一个constant常数</strong>，它并不是一个function，<strong>因为$z$其实在计算forward pass的时候就已经被计算好了</strong>（$z=w_1x_1+w_2x_2+b$），在这里$z$是一个固定的值。</p><p>所以这个neuron其实跟我们之前看到的sigmoid function是不一样的，它并不是把input通过一个non-linear进行转换，而是直接把input乘上一个constant $\sigma’(z)$，就得到了output，因此这个neuron被画成三角形，代表它跟我们之前看到的圆形的neuron的运作方式是不一样的，它是直接乘上一个constant(这里的三角形有点像电路里的运算放大器op-amp，它也是乘上一个constant)</p><p>现在需要解决的问题是，怎么计算$\frac{\partial l}{\partial z’}$和$\frac{\partial l}{\partial z’’}$这两项，这里需要考虑两种case：</p><p><strong>case 1：Output Layer</strong></p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%885%EF%BC%89Backpropagation/QQ图片20200709194802.png" style="zoom:67%;"></p><p>假设蓝色的这个neuron已经是hidden layer的最后一层了，也就是说连接在$z’$和$z’’$后的这两个红色的neuron已经是output layer，它的output就已经是整个network的output了，这个时候计算就比较简单：</p><script type="math/tex; mode=display">\frac{\partial l}{\partial z'}=\frac{\partial y_1}{\partial z'} \frac{\partial l}{\partial y_1}</script><p>其中$\frac{\partial y_1}{\partial z’}$就是output layer的activation function (softmax) 对$z’$的偏微分</p><p>而$\frac{\partial l}{\partial y_1}$就是loss对$y_1$的偏微分，它取决于你的loss function是怎么定义的，也就是你的output和target之间是怎么evaluate的，可以是cross entropy或者是mean square error，用不同的定义，$\frac{\partial l}{\partial y_1}$的值就不一样。这样就可以把$l$对$w_1$和$w_2$的偏微分$\frac{\partial l}{\partial w_1}$、$\frac{\partial l}{\partial w_2}$算出来了。</p><p><strong>Case 2：Not Output Layer</strong></p><p>假设现在红色的neuron并不是整个network的output，那$z’$经过红色neuron的activation function得到$a’$，然后output $a’$和$w_5$、$w_6$相乘并加上一堆其他东西分别得到$z_a$和$z_b$，如下图所示</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%885%EF%BC%89Backpropagation/QQ图片20200709194806.png" style="zoom:67%;"></p><p>根据之前的推导证明类比，如果知道$\frac{\partial l}{\partial z_a}$和$\frac{\partial l}{\partial z_b}$，我们就可以计算$\frac{\partial l}{\partial z’}$，如下图所示，借助运算放大器的辅助理解，将$\frac{\partial l}{\partial z_a}$乘上$w_5$和$\frac{\partial l}{\partial z_b}$乘上$w_6$的值加起来再通过op-amp，乘上放大系数$\sigma’(z’)$，就可以得到output $\frac{\partial l}{\partial z’}$</p><script type="math/tex; mode=display">\frac{\partial l}{\partial z'}=\sigma'(z')[w_5 \frac{\partial l}{\partial z_a} + w_6 \frac{\partial l}{\partial z_b}]</script><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%885%EF%BC%89Backpropagation/QQ图片20200709194809.png" style="zoom:67%;"></p><p>知道$z’$和$z’’$就可以知道$z$，知道$z_a$和$z_b$就可以知道$z’$，…… ，现在这个过程就可以反复进行下去，直到找到output layer，我们可以算出确切的值，然后再一层一层反推回去。</p><p>这个方法听起来挺让人崩溃的，每次要算一个微分的值，都要一路往后走，一直走到network的output，如果写成表达式的话，一层一层往后展开，感觉会是一个很可怕的式子，但是实际上并不是这样做的。</p><p>你只要换一个方向，<strong>从output layer的$\frac{\partial l}{\partial z}$开始算</strong>，你就会发现它的运算量跟原来的network的Feedforward path其实是一样的。假设现在有6个neuron，每一个neuron的activation function的input分别是$z_1$、$z_2$、$z_3$、$z_4$、$z_5$、$z_6$，我们要计算$l$对这些$z$的偏微分，按照原来的思路，我们想要知道$z_1$的偏微分，就要去算$z_3$和$z_4$的偏微分，想要知道$z_3$和$z_4$的偏微分，就又要去计算两遍$z_5$和$z_6$的偏微分，这样做没有效率。</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%885%EF%BC%89Backpropagation/QQ图片20200709194813.png" style="zoom:67%;"></p><p>但是，如果反过来先去计算$z_5$和$z_6$的偏微分的话，这个process就会变得有效率。我们先去计算$\frac{\partial l}{\partial z_5}$和$\frac{\partial l}{\partial z_6}$，然后就可以算出$\frac{\partial l}{\partial z_3}$和$\frac{\partial l}{\partial z_4}$，最后就可以算出$\frac{\partial l}{\partial z_1}$和$\frac{\partial l}{\partial z_2}$，而这一整个过程，就可以转化为op-amp运算放大器的那张图</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%885%EF%BC%89Backpropagation/QQ图片20200709204309.png" style="zoom:67%;"></p><p>这里每一个op-amp的放大系数就是$\sigma’(z_1)$、$\sigma’(z_2)$、$\sigma’(z_3)$、$\sigma’(z_4)$，所以整一个流程就是，先快速地计算出$\frac{\partial l}{\partial z_5}$和$\frac{\partial l}{\partial z_6}$，然后再把这两个偏微分的值乘上路径上的weight汇集到neuron上面，再通过op-amp的放大，就可以得到$\frac{\partial l}{\partial z_3}$和$\frac{\partial l}{\partial z_4}$这两个偏微分的值，再让它们乘上一些weight，并且通过一个op-amp，就得到$\frac{\partial l}{\partial z_1}$和$\frac{\partial l}{\partial z_2}$这两个偏微分的值，这样就计算完了，这个步骤，就叫做<strong>Backward pass</strong>。</p><p>以上面这个图中的neural network为例，network共有12个$w$，写一下反向传播求梯度的过程，假如现在要求$\frac{\partial l}{\partial w_1}$和$\frac{\partial l}{\partial w_2}$，由Chain Rule知：</p><script type="math/tex; mode=display">\frac{\partial l}{\partial w_1}=\frac{\partial l}{\partial z_1} \cdot\frac{\partial z_1}{\partial w_1}\\\frac{\partial l}{\partial w_2}=\frac{\partial l}{\partial z_1} \cdot\frac{\partial z_1}{\partial w_2}</script><p><strong>Forward Pass：</strong></p><script type="math/tex; mode=display">\frac{\partial z_1}{\partial w_1}=x_1\\\frac{\partial z_1}{\partial w_2}=x_2</script><p><strong>Backward Pass：</strong></p><ul><li>Step 1：</li></ul><script type="math/tex; mode=display">\frac{\partial l}{\partial z_5}=\frac{\partial l}{\partial y_1}\cdot\frac{\partial y_1}{\partial z_5} \\\frac{\partial l}{\partial z_6}=\frac{\partial l}{\partial y_2}\cdot\frac{\partial y_2}{\partial z_5}</script><ul><li>Step 2:</li></ul><script type="math/tex; mode=display">\frac{\partial l}{\partial z_3}=\sigma'(z_3)[w_9 \frac{\partial l}{\partial z_5} + w_{11} \frac{\partial l}{\partial z_6}] \\\frac{\partial l}{\partial z_4}=\sigma'(z_4)[w_{10} \frac{\partial l}{\partial z_5} + w_{12} \frac{\partial l}{\partial z_6}]</script><ul><li>Step 3:</li></ul><script type="math/tex; mode=display">\frac{\partial l}{\partial z_1}=\sigma'(z_1)[w_5 \frac{\partial l}{\partial z_3} + w_7 \frac{\partial l}{\partial z_4}] \\\frac{\partial l}{\partial z_2}=\sigma'(z_2)[w_6 \frac{\partial l}{\partial z_3} + w_8 \frac{\partial l}{\partial z_4}]</script><p>最后就可以得到损失函数$l$对参数$w_1$，$w_2$的梯度：</p><script type="math/tex; mode=display">\frac{\partial l}{\partial w_1}=\frac{\partial l}{\partial z_1} \cdot\frac{\partial z_1}{\partial w_1}=x_1 \cdot \sigma'(z_1)[w_5 \frac{\partial l}{\partial z_3} + w_7 \frac{\partial l}{\partial z_4}] \\\frac{\partial l}{\partial w_2}=\frac{\partial l}{\partial z_1} \cdot\frac{\partial z_1}{\partial w_2}=x_2 \cdot \sigma'(z_1)[w_6 \frac{\partial l}{\partial z_3} + w_8 \frac{\partial l}{\partial z_4}]</script><p>在做Backward pass的时候，实际上的做法就是建另外一个neural network，本来正向neural network里面的activation function都是sigmoid function，而现在计算Backward pass的时候，就是<strong>建一个反向的neural network，它的activation function就是一个运算放大器op-amp</strong>，每一个反向neuron的input是loss $l$对后面一层layer的$z$的偏微分$\frac{\partial l}{\partial z}$，output则是loss $l$对这个neuron的$z$的偏微分$\frac{\partial l}{\partial z}$，做Backward pass就是通过这样一个反向neural network的运算，把loss $l$对每一个neuron的$z$的偏微分$\frac{\partial l}{\partial z}$都给算出来。</p><p>（注：如果是正向做Backward pass的话，实际上每次计算一个$\frac{\partial l}{\partial z}$，就需要把该neuron后面所有的$\frac{\partial l}{\partial z}$都给计算一遍，会造成很多不必要的重复运算，如果写成code的形式，就相当于调用了很多次重复的函数；而如果是反向做Backward pass，实际上就是把这些调用函数的过程都变成调用“值”的过程，因此可以直接计算出结果，而不需要占用过多的堆栈空间。）</p><h4 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h4><p>最后来总结一下Backpropagation是怎么做的</p><p><strong>Forward pass</strong>，每个neuron的activation function的$w$前连接的input，就是$\frac{\partial z}{\partial w}$；</p><p><strong>Backward pass</strong>，建一个与原来方向相反的neural network，它的三角形neuron的output就是$\frac{\partial l}{\partial z}$</p><p>把通过forward pass得到的$\frac{\partial z}{\partial w}$和通过backward pass得到的$\frac{\partial l}{\partial z}$乘起来就可以得到$l$对$w$的梯度$\frac{\partial l}{\partial w}$</p><script type="math/tex; mode=display">\frac{\partial l}{\partial w} = \frac{\partial z}{\partial w}|_{forward\ pass} \cdot \frac{\partial l}{\partial z}|_{backward \ pass}</script><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%885%EF%BC%89Backpropagation/QQ图片20200709201544.png" style="zoom:67%;"></p>]]></content>
    
    <summary type="html">
    
      本文主要介绍了Backpropagation 反向传播的原理，Backpropagation是一种有效的求梯度的方法，并不是一种区别于Gradient Descent的新算法。
    
    </summary>
    
    
      <category term="Deep Learning" scheme="http://nekomoon404.github.io/categories/Deep-Learning/"/>
    
    
      <category term="Backpropagation" scheme="http://nekomoon404.github.io/tags/Backpropagation/"/>
    
  </entry>
  
  <entry>
    <title>DL笔记（4）Brief Introduction of Deep Learning</title>
    <link href="http://nekomoon404.github.io/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89Brief-Introduction-of-Deep-Learning/"/>
    <id>http://nekomoon404.github.io/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89Brief-Introduction-of-Deep-Learning/</id>
    <published>2020-07-09T07:24:47.000Z</published>
    <updated>2020-07-09T08:24:47.000Z</updated>
    
    <content type="html"><![CDATA[<p>首先简单了解一下Deep Learning 深度学习的发展历程：</p><ul><li>1958：Perceptron(linear model)，感知机的提出<ul><li>和Logistic Regression类似，只是少了sigmoid的部分</li></ul></li><li>1969：Perceptron has limitation，from MIT</li><li>1980s：Multi-layer Perceptron，多层感知机<ul><li>和今天的DNN很像</li></ul></li><li>1986：Backpropagation，反向传播<ul><li>Hinton propose的Backpropagation</li><li>存在problem：通常超过3个layer的neural network，就train不出好的结果</li></ul></li><li>1989: 1 hidden layer is “good enough”，why deep？<ul><li>有人提出一个理论：只要neural network有一个hidden layer，它就可以model出任何的function，所以根本没有必要叠加很多个hidden layer，所以Multi-layer Perceptron的方法又坏掉了，这段时间Multi-layer Perceptron这个东西是受到抵制的</li></ul></li><li>2006：RBM initialization(breakthrough)：Restricted Boltzmann Machine，受限玻尔兹曼机<ul><li>Deep learning -&gt; another Multi-layer Perceptron ？在当时看来，它们的不同之处在于在做gradient descent的时候选取初始值的方法如果是用RBM，那就是Deep learning；如果没有用RBM，就是传统的Multi-layer Perceptron</li><li>那实际上呢，RBM用的不是neural network base的方法，而是graphical model，后来大家试验得多了发现RBM并没有什么太大的帮助，因此现在基本上没有人使用RBM做initialization了</li><li>RBM最大的贡献是，它让大家重新对Deep learning这个model有了兴趣(石头汤的故事)</li></ul></li><li>2009：GPU加速的发现</li><li>2011：start to be popular in speech recognition，语音识别领域</li><li>2012：win ILSVRC image competition，Deep learning开始在图像领域流行开来</li></ul><h3 id="1-Neural-Network"><a href="#1-Neural-Network" class="headerlink" title="1.Neural Network"></a>1.Neural Network</h3><p>实际上，Deep learning跟machine learning一样，也是“大象放进冰箱”的三个步骤。在Deep learning的step1里定义的function，就是neural network。</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89Brief-Introduction-of-Deep-Learning/QQ图片20200709153823.png" style="zoom: 40%;"></p><p>把多个Logistic Regression前后connect在一起，然后把一个Logistic Regression称之为neuron，整个称之为<strong>neural network</strong>。我们可以用不同的方法连接这些neuron，就可以得到不同的structure，neural network里的每一个Logistic Regression都有自己的weight和bias，这些weight和bias集合起来，就是这个network的parameter，我们用$\theta$来描述。</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89Brief-Introduction-of-Deep-Learning/QQ图片20200709154209.png" style="zoom: 50%;"></p><p><strong>Fully Connect Feedforward Network</strong></p><p>这些神经元Neuron之间的连接方式需要我们自己去设计的，最常见的连接方式叫做<strong>Fully Connect Feedforward Network(全连接前馈网络)</strong>。如果一个neural network的参数weight和bias已知的话，它就是一个function，它的input是一个vector，output是另一个vector，这个vector里面放的是样本点的feature，vector的dimension就是feature的个数</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89Brief-Introduction-of-Deep-Learning/QQ图片20200709154513.png" style="zoom:50%;"></p><p>如果现在我们还不知道网络中每个神经元中的参数，只是定出了这个network的structure，只是决定好这些neuron该怎么连接在一起，这样的一个network structure其实是定义了一个function set(model)，给这个network设不同的参数，它就变成了不同的function，把这些可能的function集合起来，就得到了一个function set。用neural network决定function set的时候，这个function set是比较大的，它包含了很多原来你做Logistic Regression、做linear Regression所没有办法包含的function。</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89Brief-Introduction-of-Deep-Learning/QQ图片20200709154734.png" style="zoom:50%;"></p><p>上图中，每一排表示一个layer，每个layer里面的每一个球都代表一个neuron</p><ul><li>layer和layer之间neuron是两两互相连接的，layer 1的neuron output会连接给layer 2的每一个neuron作为input</li><li>对整个neural network来说，它需要一个input，这个input就是一个feature vector，而对layer 1的每一个neuron来说，它的input就是input layer的每一个dimension</li><li>最后那个layer L，由于它后面没有接其它东西了，所以它的output就是整个network的output</li><li>这里每一个layer都是有名字的<ul><li><strong>input layer</strong>，输入层(严格来说input layer其实不是一个layer，它跟其他layer不一样，不是由neuron所组成的)</li><li><strong>output layer</strong>，输出层</li><li>中间层，叫做<strong>hidden layer</strong>，隐藏层</li></ul></li><li>每一个neuron里面的sigmoid function，在Deep Learning中被称为<strong>activation function</strong>(激励函数)，事实上它不见得一定是sigmoid function，还可以是其他function(sigmoid function是从Logistic Regression迁移过来的，现在已经较少在Deep learning里使用了)</li><li>有很多层layers的neural network，被称为<strong>DNN(Deep Neural Network)</strong></li></ul><p>上图中的神经网络中layer和layer之间，所有的neuron都是两两连接，所以它叫Fully connected network；因为现在传递的方向是从layer 1-&gt;2-&gt;3，由前向后传，所以它叫做Feedforward network。</p><p>那所谓的Deep其实就是指有很多层hidden layer，具体的层数并没有规定。但好像现在只要是neural network base的方法，都被称为Deep Learning（苦笑）。</p><p><strong>Matrix Operation</strong></p><p>network的运作过程，我们通常会用Matrix Operation来表示，以下图为例，假设第一层hidden layers的两个neuron，它们的weight分别是$w_1=1,w_2=-2,w_1’=-1,w_2’=1$，那就可以把它们排成一个matrix：$\begin{bmatrix}1 \ \ \ -2\\ -1 \ \ \ 1 \end{bmatrix}$，而我们的input又是一个2*1的vector：$\begin{bmatrix}1\-1 \end{bmatrix}$，将$w$和$x$相乘，再加上bias的vector：$\begin{bmatrix}1\\0 \end{bmatrix}$，就可以得到这一层的vector $z$，再经过activation function得到这一层的output：(activation function可以是很多类型的function，这里还是用Logistic Regression迁移过来的sigmoid function作为运算)</p><script type="math/tex; mode=display">\sigma(\begin{bmatrix}1 \ \ \ -2\\ -1 \ \ \ 1 \end{bmatrix} \begin{bmatrix}1\\-1 \end{bmatrix}+\begin{bmatrix}1\\0 \end{bmatrix})=\sigma(\begin{bmatrix}4\\-2 \end{bmatrix})=\begin{bmatrix}0.98\\0.12 \end{bmatrix}</script><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89Brief-Introduction-of-Deep-Learning/QQ图片20200709155414.png" style="zoom:50%;"></p><p>这里我们把所有的变量都以matrix的形式表示出来，注意$W^i$的matrix，每一行对应的是一个neuron的weight，行数就是neuron的个数，而input $x$，bias $b$和output $y$都是一个列向量，行数就是feature的个数(也是neuron的个数，neuron的本质就是把feature transform到另一个space)。</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89Brief-Introduction-of-Deep-Learning/QQ图片20200709160357.png" style="zoom:90%;"></p><p>写成矩阵运算的好处是不仅在于形式简洁，还在于可以用GPU加速，GPU对matrix的运算是比CPU要来的快的，所以写neural network的时候，习惯把它写成matrix operation，然后call GPU来加速它。</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89Brief-Introduction-of-Deep-Learning/QQ图片20200709160404.png" style="zoom:90%;"></p><p><strong>Output Layer</strong></p><p>我们可以把hidden layers这部分，看做是一个<strong>feature extractor(特征提取器)</strong>，这个feature extractor就r代替了我们之前手动做feature engineering，feature transformation这些事情，经过这个feature extractor得到的$x_1,x_2,…,x_k$就可以被当作一组新的feature。</p><p>output layer做的事情，其实就是把它当做一个<strong>Multi-class classifier</strong>，它是拿经过feature extractor转换后的那一组比较好的feature(能够被很好地separate)进行分类的，如果我们想把把output layer看做是一个Multi-class classifier，那么可以在最后一个layer加上<strong>softmax</strong>。</p><h3 id="2-Example-Application-Handwriting-Digit-Recognition"><a href="#2-Example-Application-Handwriting-Digit-Recognition" class="headerlink" title="2.Example Application: Handwriting Digit Recognition"></a>2.Example Application: Handwriting Digit Recognition</h3><p>这里举一个手写数字识别的例子，input是一张image，对机器来说一张image实际上就是一个vector，假设这是一张16*16的image，那它有256个pixel，对machine来说，它是一个256维的vector，image中的每一个pixel都对应到vector中的一个dimension，我们把黑色的pixel的值设为1，白色的pixel的值设为0。</p><p>而neural network的output，如果在output layer使用了softmax，那它的output就是一个突出极大值的Probability distribution，假设output是10维(10个数字，0~9)，这个output的每一维都对应到它可能是某一个数字的几率，实际上这个neural network的作用就是计算这张image成为10个数字的几率各自有多少，几率最大(softmax突出极大值的意义所在)的那个数字，就是机器的预测值。</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89Brief-Introduction-of-Deep-Learning/QQ图片20200709161118.png" style="zoom: 60%;"></p><p><strong>Step 1：Neural Network</strong></p><p>在这个手写字体识别的demo里，我们需要的就是一个function，这个function的input是一个256的vector，output是一个10维的vector，这个function就是neural network(这里我们用简单的Feedforward network)。</p><p>input固定为256维，output固定为10维的feedforward neural network，实际上这个network structure就已经确定了一个function set(model)的形状，在这个function set里的每一个function都可以拿来做手写数字识别，接下来我们要做的事情是用gradient descent去计算出一组参数，挑一个最适合拿来做手写数字识别的function。（input、output的dimension，加上<strong>network structure</strong>，就可以确定一个model的形状，前两个是容易知道的，而确定这个network的structure则是整个Deep Learning中最为关键的步骤）</p><p>所以这里很重要的一件事情是，我们要对network structure进行design，之前在做Logistic Regression或者是linear Regression的时候，我们对model的structure是没有什么好设计的，但是对neural network来说，我们现在已知的constraint只有input是256维，output是10维，而中间要有几个hidden layer，每个layer要有几个neuron，都是需要我们自己去设计的，它们近乎是决定了function set长什么样子。如果network structure设计的很差，这个function set里面根本就没有好的function，那就会像大海捞针一样，结果针并不在海里(=´ω｀=)</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89Brief-Introduction-of-Deep-Learning/QQ图片20200709174501.png" style="zoom: 50%;"></p><p>input 256维，output 10维，以及自己design的network structure =》function set(model)</p><p><strong>Step 2：Goodness of function</strong></p><p>定义一个function的好坏，由于我们做的是一个Multi-class classification，所以image为数字1的label “1”告诉我们，现在的target是一个10维的vector，只有在第一维对应数字1的地方，它的值是1，其他都是0</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89Brief-Introduction-of-Deep-Learning/QQ图片20200709161556.png" style="zoom: 60%;"></p><p>input这张image的256个pixel，通过这个neural network之后，会得到一个output，称之为y；而从这张image的label中转化而来的target，称之为$\hat{y}$，有了output $y$和target $\hat{y}$之后，要做的事情是计算它们之间的<strong>cross entropy(交叉熵)</strong>，这个做法跟我们之前做Multi-class classification的时候是一模一样的</p><script type="math/tex; mode=display">Cross \ Entropy :l(y,\hat{y})=-\sum\limits_{i=1}^{10}\hat{y}_i lny_i</script><p><strong>Step 3：Pick the best function</strong></p><p>接下来就去调整参数，让这个cross entropy越小越好，当然整个training data里面不会只有一笔data，你需要把所有data的cross entropy都sum起来，得到一个total loss $L=\sum\limits_{n=1}^Nl^n$，得到loss function之后要做的就是找一组network的parameters：$\theta^*$，它可以minimize这个total loss，这组parameter对应的function就是我们最终训练好的model。</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89Brief-Introduction-of-Deep-Learning/QQ图片20200709161756.png" style="zoom: 67%;"></p><p>那如何去找这个使total loss minimize的$\theta^<em>$呢？我们依然可以使用之前学过的——<em>*Gradient Descent</em></em></p><p>实际上在deep learning里面用gradient descent，跟在linear regression里面使用完全没有什么差别，只是function和parameter变得更复杂了而已，其他事情都是一模一样的。现在的$\theta$里面是一大堆的weight、bias参数，先random找一个初始值，接下来去计算每一个参数对total loss的偏微分，把这些偏微分全部集合起来，就叫做gradient，有了这些偏微分以后，就可以更新所有的参数，都减掉learning rate乘上偏微分的值，这个process反复进行下去，最终找到一组好的参数，就做完deep learning的training了。</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89Brief-Introduction-of-Deep-Learning/QQ图片20200709162020.png" style="zoom:67%;"></p><p><strong>Design network structure V.s. Feature Engineering</strong></p><p>其实network structure的design是一件蛮难的事情，我们到底要怎么决定layer的数目和每一个layer的neuron的数目呢？其实这个只能够凭着经验和直觉、多方面的尝试，有时候甚至会需要一些domain knowledge(专业领域的知识)，从非deep learning的方法到deep learning的方法，并不是说machine learning比较简单，而是我们把一个问题转化成了另一个问题。</p><p>本来不是deep learning的model，要得到一个好的结果，往往需要做feature engineering(特征工程)，也就是做feature transform，然后找一组好的feature；一开始学习deep learning的时候，好像会觉得deep learning的layers之间也是在做feature transform，但实际上在做deep learning的时候，往往不需要一个好的feature ，比如说在做影像辨识的时候，你可以把所有的pixel直接丢进去，但是在过去做图像识别，你是需要对图像抽取出一些人定的feature出来的，这件事情就是feature transform，但是有了deep learning之后，你完全可以直接丢pixel进去硬做</p><p>但是，今天deep learning制造了一个新的问题，它所制造的问题就是，你需要去design network的structure，所以<strong>你的问题从本来的如何抽取feature转化成怎么design network structure</strong>，所以deep learning是不是真的好用，取决于你觉得哪一个问题比较容易。</p><p>如果是影像辨识或者是语音辨识的话，design network structure可能比feature engineering要来的容易，因为，虽然我们人都会看、会听，但是这件事情，它太过潜意识了，它离我们意识的层次太远，我们无法意识到，我们到底是怎么做语音辨识这件事情，所以对人来说，你要抽一组好的feature，让机器可以很方便地用linear的方法做语音辨识，其实是很难的，因为人根本就不知道好的feature到底长什么样子；所以还不如design一个network structure，或者是尝试各种network structure，让machine自己去找出好的feature，这件事情反而变得比较容易，对影像来说也是一样的。</p><h3 id="3-Why-Deep？"><a href="#3-Why-Deep？" class="headerlink" title="3.Why Deep？"></a>3.Why Deep？</h3><p>前面在介绍Deep Learning发展历程的时候有提到“只要neural network有一个hidden layer，它就可以model出任何的function”，那么是不是意味着我们并不不需要费尽心思地设计”Deep”的Network，只要用有一层layer的Network就可以解决问题了？显然不是这样的（要不然Deep Learning怎么发展到今天啊喂ヽ(#`Д´)ﾉ┌┛〃），那么<strong>Deep</strong>好在哪呢？</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89Brief-Introduction-of-Deep-Learning/QQ图片20200709164517.png" style="zoom: 50%;"></p><h4 id="Fat-Short-v-s-Thin-Tall"><a href="#Fat-Short-v-s-Thin-Tall" class="headerlink" title="Fat + Short v.s. Thin + Tall"></a>Fat + Short v.s. Thin + Tall</h4><p>论上只要这一层里neuron的数目足够多，有足够的参数，就可以表示出任何函数。那用大量的data加上参数足够多的model就可以实现这个效果，那为什么一定要用DNN呢？我们完全可以用一层的shallow neural network来做同样的事情，其实“Deep”和”Shallow”这两种结构的Network的performance是会不一样的，这里我们就拿下面这两种结构的network做一下比较。</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89Brief-Introduction-of-Deep-Learning/QQ图片20200709165542.png" style="zoom:50%;"></p><p>如果要给Deep和Shallow的model一个公平的评比，就要调整它们的形状，让它们的参数是一样多的，在这个情况下Shallow的model就会是一个“矮胖”的model，Deep的model就会是一个“瘦高”的model。有学者在这个公平的评比之下，得到的结果如下图所示。左侧表示的是deep network的情况，右侧表示的是shallow network的情况，为了保证两种情况下参数的数量是比较接近的，因此设置了右侧1*3772和1*4634这两种size大小，它们分别对应比较左侧5*2k和7*2k这两种情况下的network(注意参数数目和neuron的数目并不是等价的)。</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89Brief-Introduction-of-Deep-Learning/QQ图片20200709165545.png" style="zoom: 50%;"></p><p>发现，在参数数量接近的情况下，只有1层的network，它的error rate是远大于好几层的network的；1层的shallow network的performance甚至都比不过很多参数比它少但层数比它多的deep network。根据上面的对比可知，deep learning显然是在结构上存在着某种优势，不然无法解释它会比参数数量相同的shallow learning表现得更好这个现象。</p><h4 id="Modularization"><a href="#Modularization" class="headerlink" title="Modularization"></a>Modularization</h4><p>DNN结构一个很大的优势是，Modularization(模块化)，它用的是结构化的架构。就像写程序一样，shallow network实际上就是把所有的程序都写在了同一个main函数中，所以它去检测不同的class使用的方法是相互独立的；而deep network则是把整个任务分为了一个个小任务，每个小任务又可以不断细分下去，以形成modularization。</p><p>在DNN的架构中，实际上每一层layer里的neuron都像是在解决同一个级别的任务，它们的output作为下一层layer处理更高级别任务的数据来源，低层layer里的neuron做的是对不同小特征的检测，高层layer里的neuron则根据需要挑选低层neuron所抽取出来的不同小特征，去检测一个范围更大的特征；neuron就像是一个个classifier ，后面的classifier共享前面classifier的参数。</p><p>这样做的好处是，低层的neuron输出的信息可以被高层不同的neuron重复使用，而并不需要像shallow network一样，每次在用到的时候都要重新去检测一遍，因此大大降低了程序的复杂度。</p><p>这里举一个分类的例子，我们要把input的人物分为四类：长头发女生、长头发男生、短头发女生、短头发男生。如果按照shallow network的想法，我们分别独立地train四个classifier(其实就相当于训练四个独立的model)，然后就可以解决这个分类的问题；但是这里有一个问题，长头发男生的data是比较少的，没有太多的training data，所以，你train出来的classifier就比较weak，去detect长头发男生的performance就比较差。</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89Brief-Introduction-of-Deep-Learning/QQ图片20200709170613.png" style="zoom: 50%;"></p><p>其实我们的input并不是没有关联的，长头发的男生和长头发的女生都有一个共同的特征，就是长头发，因此如果我们分别<strong>独立地训练四个model作为分类器</strong>，实际上就是忽视了这个共同特征，也就是没有高效地用到data提供的全部信息，这恰恰是shallow network的弊端。</p><p>而利用modularization的思想，使用deep network的架构，我们可以<strong>训练一个model作为分类器就可以完成所有的任务</strong>，我们可以把整个任务分为两个子任务：</p><ul><li>Classifier1：检测是男生或女生</li><li>Classifier2：检测是长头发或短头发</li></ul><p>虽然长头发的男生data很少，但长头发的人的data就很多，这样就真正做到了充分、高效地利用数据，最终的Classifier再根据Classifier1和Classifier2提供的信息给出四类人的分类结果。</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89Brief-Introduction-of-Deep-Learning/QQ图片20200709170616.png" style="zoom:50%;"></p><p>经过层层layer的任务分解，其实每一个Classifier要做的事情都是比较简单的，又因为这种分层的、模组化的方式充分利用了data，并提高了信息利用的效率，所以只要用比较少的training data就可以把结果train好。</p><p><strong>deep -&gt; modularization</strong></p><p>做modularization的好处是<strong>把原来比较复杂的问题变得简单</strong>，比如原来的任务是检测一个长头发的女生，但现在你的任务是检测长头发和检测性别，而当检测对象变简单的时候，就算training data没有那么多，我们也可以把这个task做好，并且<strong>所有的classifier都用同一组参数检测子特征</strong>，提高了参数使用效率，这就是modularization的作用。<strong>由于deep learning的deep就是在做modularization这件事，所以它需要的training data反而是比较少的</strong>，这可能会跟你的认知相反，AI=big data+deep learning，但deep learning其实是为了解决less data的问题才提出的。</p><p>以图像识别为例，每一个neuron其实就是一个basic的classifier：</p><ul><li>第一层neuron，它是一个最basic的classifier，检测的是颜色、线条这样的小特征</li><li>第二层neuron是比较复杂的classifier，它用第一层basic的classifier的output当作input，也就是把第一层的classifier当作module，利用第一层得到的小特征分类出不同样式的花纹</li><li>而第三层的neuron又把第二层的neuron当作它module，利用第二层得到的特征分类出蜂窝、轮胎、人</li><li>以此类推</li></ul><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89Brief-Introduction-of-Deep-Learning/QQ图片20200709171359.png" style="zoom:50%;"></p><p>这边要强调的是，在做deep learning的时候，怎么做模块化这件事情是machine自动学到的，也就是说，第一层要检测什么特征、第二层要检测什么特征…这些都不是人为指定的，人只定好有几层layer、每层layer有几个neuron，剩下的事情都是machine自己学到的。</p><p>传统的机器学习算法，是人为地根据domain knowledge指定特征来进行提取，这种指定的提取方式，甚至是提取到的特征，也许并不是实际最优的，所以它的识别成功率并没有那么高；但是在Deep Learning中，提取什么特征、怎么提取这件事让机器自己去学，它所提取的就会是那个最优解，因此识别成功率普遍会比人为指定要来的高。</p><p>后面老师举了一个DNN在语音识别领域的例子，传统的HMM-GMM方法是默认把所有的phone或者state都看做是无关联的，对它们分别训练independent model，没有充分利用data提供的信息。而DNN的做法是把所有的state通通用同一个model来做分类，比较lower的layer会先观察人是用什么样的方式在发这个声音，人的舌头位置应该在哪里，是高是低，是前是后；接下来的layer再根据这个结果，去决定现在的发音是属于哪一个state或哪一个phone。这些lower的layer是一个人类发音方式的detector，而所有phone的检测都share这同一组detector的结果，因此最终的这些classifier是share了同一组用来detect发音方式的参数，这就做到了模块化，同一个参数被更多的地方share，因此显得更有效率。</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89Brief-Introduction-of-Deep-Learning/QQ图片20200709172056.png" style="zoom:50%;"></p><h4 id="Deep-is-better"><a href="#Deep-is-better" class="headerlink" title="Deep is better"></a>Deep is better</h4><p>Universality Theorem告诉我们任何的continuous的function都可以用一层足够宽的neural network来实现，在90年代，这是很多人放弃做deep learning的一个原因。但是这个理论只告诉了我们可能性，却没有说明这件事的效率问题；根据上面的几个例子我们已经知道，只用一个hidden layer来描述function其实是没有效率的；当你用multi-layer，用hierarchy structure来描述function的时候，才会是比较有效率的。</p><p>老师分别用逻辑电路和剪窗花的小例子来说明”Deep”相比于”Shallow”的优势，这里就不详细展开了。下面是老师做的一个小例子，左边的图是training data，右边则是1层hidden layer与3层hidden layer的不同network的情况对比，这里已经控制它们的参数数量趋于相同，试验结果是，当training data为10w笔的时候，两个network学到的样子是比较接近原图的，而如果只给2w笔training data，1层hidden layer的情况就完全崩掉了，而3层hidden layer的情况会比较好一些。</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89Brief-Introduction-of-Deep-Learning/QQ图片20200709172556.png" style="zoom:50%;"></p><h4 id="End-to-end-Learning"><a href="#End-to-end-Learning" class="headerlink" title="End-to-end Learning"></a>End-to-end Learning</h4><p>所谓的<strong>End-to-end learning 端到端的学习</strong>，指的是只给model input和output，而不告诉它中间每一个function要怎么分工，让它自己去学会知道在生产线的每一站，自己应该要做什么事情；在DNN里，就是叠一个很深的neural network，每一层layer就是生产线上的一个站，我们不需要告诉机器生产线上的每一站是干什么的，而是是让机器自己去完成整条生产线的学习。</p><p>相对于深度学习，<strong>传统机器学习</strong>的流程往往由多个独立的模块组成，比如在一个典型的自然语言处理（Natural Language Processing）问题中，包括分词、词性标注、句法分析、语义分析等多个独立步骤，每个步骤是一个独立的任务，其结果的好坏会影响到下一步骤，从而影响整个训练的结果，这是非端到端的。</p><p>而<strong>深度学习</strong>模型在训练过程中，从输入端（输入数据）到输出端会得到一个预测结果，与真实结果相比较会得到一个误差，这个误差会在模型中的每一层传递（反向传播），每一层的表示都会根据这个误差来做调整，直到模型收敛或达到预期的效果才结束，这是端到端的。</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89Brief-Introduction-of-Deep-Learning/QQ图片20200709173248.png" style="zoom:50%;"></p><p>CNN就是比较典型的end2end模型。在图像分类里输入image各通道像素，输出图像类别。 相比于非end2end，conv层的卷积核可以充当feature extractor部分而不需要额外的工作去做特征工程的内容。尽管每一层需要自己设计，但如何得到feature并不需要额外的操作。</p><p>End-to-end Learning在语音识别上也有很好的应用，在传统的Speech Recognition里，只有最后GMM这个蓝色的block，才是由training data学出来的，前面绿色的“生产线”部分都是由过去的“五圣先贤”(°ω°｣∠)_ 手动制订出来的，这些function其实是很有效的，可以说是增一分则太肥，减一分则太瘦这样子，以至于在这个阶段卡了将近20年。后来有了deep learning，就可以用neural network把DCT、log这些部分取代掉，甚至从spectrogram开始都拿deep neural network取代掉，也可以得到更好的结果，如果你分析DNN的weight，它其实可以自动学到要做filter bank这件事情(filter bank是模拟人类的听觉器官所制定出来的filter)。</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89Brief-Introduction-of-Deep-Learning/QQ图片20200709173251.png" style="zoom:50%;"></p><h4 id="Complex-Task"><a href="#Complex-Task" class="headerlink" title="Complex Task"></a>Complex Task</h4><p>有时候我们会遇到非常复杂的task：</p><ul><li>Very similar input,  but different output</li><li>Very different input, but similar output</li></ul><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89Brief-Introduction-of-Deep-Learning/QQ图片20200709173821.png" style="zoom: 50%;"></p><p>如果你的network只有一层的话，就只能做简单的transform，没有办法把一样的东西变得很不一样，把不一样的东西变得很像；如果要实现这些，就需要做很多层次的转换，就像前面那个剪窗花的例子，在二维、三维空间上看起来很难辨别，但是到了高维空间就完全有可能把它们给辨别出来。</p><p>这里以MNIST手写数字识别为例，展示一下DNN中，在高维空间上对这些Complex Task的处理能力。如果把28*28个pixel组成的vector投影到二维平面上就像左上角所示，你会发现4跟9的pixel几乎是叠在一起的，因为4跟9很像，都是一个圈圈再加一条线，所以如果你光看input的pixel的话，4跟9几乎是叠在一起的，你几乎没有办法把它分开。但是，等到第二个、第三个layer的output，就会发现4、7、9逐渐就被分开了，这也是Deep Learning的”Deep”的一个优势所在。</p><p><img src="/2020/07/09/ML%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89Brief-Introduction-of-Deep-Learning/QQ图片20200709174025.png" style="zoom:50%;"></p>]]></content>
    
    <summary type="html">
    
      本文简单介绍了Deep Neural Network的概念，以及其在数字识别案例中的应用，并解释了&quot;Deep&quot;的Network Structure为什么具有优势。
    
    </summary>
    
    
      <category term="Deep Learning" scheme="http://nekomoon404.github.io/categories/Deep-Learning/"/>
    
    
      <category term="Deep Neural Network" scheme="http://nekomoon404.github.io/tags/Deep-Neural-Network/"/>
    
  </entry>
  
  <entry>
    <title>ML笔记（3）Logistic_Regression</title>
    <link href="http://nekomoon404.github.io/2020/07/08/ML%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89Logistic-Regression/"/>
    <id>http://nekomoon404.github.io/2020/07/08/ML%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89Logistic-Regression/</id>
    <published>2020-07-08T10:48:14.000Z</published>
    <updated>2020-07-08T12:49:03.747Z</updated>
    
    <content type="html"><![CDATA[<p><strong>回顾 Review</strong></p><p>在上一节课 Classification中，讨论了如何通过样本点的均值$u$和协方差$\Sigma$来计算$P(C_1),P(C_2),P(x|C_1),P(x|C_2)$，进而利用$P(C_1|x)=\frac{P(C_1)P(x|C_1)}{P(C_1)P(x|C_1)+P(C_2)P(x|C_2)}$计算得到新的样本点$x$属于class 1的概率，由于是二元分类，属于class 2的概率$P(C_2|x)=1-P(C_1|x)$。</p><p>然后推导了$P(C_1|x)=\sigma(z)=\frac{1}{1+e^{-z}}$，并且在Gaussian distribution下考虑class 1和class 2共用$\Sigma$，可以得到一个线性的z(其实很多其他的Probability model经过化简以后也都可以得到同样的结果)</p><script type="math/tex; mode=display">P_{w,b}(C_1|x)=\sigma(z)=\frac{1}{1+e^{-z}} \\z=w\cdot x+b=\sum\limits_i w_ix_i+b \\</script><p>从上式中我们可以看出，现在这个model(function set)是受$w$和$b$控制的，因此我们不必要再去像前面一样计算那些与概率相关的东西，而是直接计算$w$和$b$，用这个全新的由$w$和$b$决定的model——<strong>Logistic Regression逻辑回归</strong>。</p><h3 id="1-Three-Steps-of-Logistic-Regression"><a href="#1-Three-Steps-of-Logistic-Regression" class="headerlink" title="1.Three Steps of Logistic Regression"></a>1.Three Steps of Logistic Regression</h3><p>现在来用机器学习的“三步走”分析一下逻辑回归。</p><p><strong>Step 1: Function Set</strong></p><p>由所有不同的$w$和$b$组成的函数的集合就是Logistic Regression的Function set。</p><p>$w_i$：weight，$b$：bias，$\sigma(z)$：sigmoid function，$x_i$：input</p><p><img src="/2020/07/08/ML%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89Logistic-Regression/QQ图片20200708190620.png" style="zoom:67%;"></p><p><img src="/2020/07/08/ML%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89Logistic-Regression/QQ图片20200708190653.png" style="zoom: 50%;"></p><p><strong>Step 2：Goodness of a function</strong></p><p>现在我们有N笔Training data，每一笔data都要标注它是属于哪一个class。假设这些Training data是从我们定义的posterior Probability中产生的(后置概率，某种意义上就是概率密度函数)，而w和b就决定了这个posterior Probability，那么就可以去计算某一组w和b去产生这N笔Training data的概率，利用极大似然估计的思想，求出使得似然函数取最大值时的那组参数$w^<em>$和$b^</em>$。</p><p>似然函数只需要将每一个点产生的概率相乘即可，注意，这里假定是二元分类，class 2的概率为1减去class 1的概率。</p><p><img src="/2020/07/08/ML%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89Logistic-Regression/QQ图片20200708191019.png" style="zoom:67%;"></p><p>由于$L(w,b)$是乘积项的形式，为了方便计算，我们将上式做个变换，求$L$的最大值相当于求$-\ln L$的最小值：</p><script type="math/tex; mode=display">\begin{split}&w^*,b^*=\arg \max\limits_{w,b} L(w,b)=\arg\min\limits_{w,b}(-\ln L(w,b)) \\&\begin{equation}\begin{split}-\ln L(w,b)=&-\ln f_{w,b}(x^1)\\&-\ln f_{w,b}(x^2)\\&-\ln(1-f_{w,b}(x^3))\\&\ -...\end{split}\end{equation}\end{split}</script><p>由于class 1和class 2的概率表达式不统一，上面的式子无法写成统一的形式，为了统一格式，这里将Logistic Regression里的所有<strong>Training data都打上0和1的标签</strong>，即output  $\hat{y}=1$代表class 1，output  $\hat{y}=0$代表class 2，于是上式进一步改写成：</p><script type="math/tex; mode=display">\begin{split}-\ln L(w,b)=&-[\hat{y}^1 \ln f_{w,b}(x^1)+(1-\hat{y}^1)ln(1-f_{w,b}(x^1))]\\&-[\hat{y}^2 \ln f_{w,b}(x^2)+(1-\hat{y}^2)ln(1-f_{w,b}(x^2))]\\&-[\hat{y}^3 \ln f_{w,b}(x^3)+(1-\hat{y}^3)ln(1-f_{w,b}(x^3))]\\&\ -...\end{split}</script><p>现在已经有了统一的格式，我们就可以把要minimize的对象写成一个summation的形式：</p><script type="math/tex; mode=display">-\ln L(w,b)=\sum\limits_n -[\hat{y}^n \ln f_{w,b}(x^n)+(1-\hat{y}^n) \ln(1-f_{w,b}(x^n))]</script><p>这里$x^n$表示第n个样本点，$\hat{y}^n$表示第n个样本点的class标签(1表示class 1,0表示class 2)，最终这个summation的形式，里面其实是<strong>两个Bernouli distribution(两点分布)的cross entropy(交叉熵)</strong>。</p><p><img src="/2020/07/08/ML%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89Logistic-Regression/QQ图片20200708191316.png" style="zoom:67%;"></p><p>假设有如上图所示的两个distribution $p$和$q$，它们的交叉熵就是$H(p,q)=-\sum\limits_{x} p(x) \ln (q(x))$，这也就是之前的推导中在$-\ln L(w,b)$前加一个负号的原因。</p><p><strong>cross entropy 交叉熵</strong>的含义是表达这两个distribution有多接近，如果$p$和$q$这两个distribution一模一样的话，那它们算出来的cross entropy就是0，而这里$f(x^n)$表示function的output，$\hat{y}^n$表示预期 的target，因此<strong>交叉熵实际上表达的是希望这个function的output和它的target越接近越好</strong></p><p>总之，我们要找的参数实际上就是：</p><script type="math/tex; mode=display">w^*,b^*=\arg \max\limits_{w,b} L(w,b)=\arg\min\limits_{w,b}(-\ln L(w,b)=\sum\limits_n -[\hat{y}^n \ln f_{w,b}(x^n)+(1-\hat{y}^n) \ln(1-f_{w,b}(x^n))]</script><p><strong>step 3：Find the best function</strong></p><p>实际上就是去找到使loss function即交叉熵之和最小的那组参数$w^<em>,b^</em>$，这里依然可以使用gradient descent的方法。</p><p>sigmoid function $\sigma(z)=\frac{1}{1+e^{-z}}$的微分可以直接作为公式记下来：$\frac{\partial \sigma(z)}{\partial z}=\sigma(z)(1-\sigma(z))$。</p><p>先计算$-\ln L(w,b)=\sum\limits_n -[\hat{y}^n \ln f_{w,b}(x^n)+(1-\hat{y}^n) \ln(1-f_{w,b}(x^n))]$对$w_i$的偏微分，这里$\hat{y}^n$和$1-\hat{y}^n$是常数先不用管它，只需要分别求出$\ln f_{w,b}(x^n)$和$\ln (1-f_{w,b}(x^n))$对$w_i$的偏微分即可，整体推导过程如下：</p><p><img src="/2020/07/08/ML%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89Logistic-Regression/QQ图片20200708191840.png" style="zoom:67%;"></p><p>进一步化简得：</p><p><img src="/2020/07/08/ML%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89Logistic-Regression/QQ图片20200708191844.png" style="zoom:67%;"></p><p>我们发现最终的结果竟然异常的简洁，gradient descent每次update只需要做：</p><script type="math/tex; mode=display">w_i=w_i-\eta \sum\limits_{n}-(\hat{y}^n-f_{w,b}(x^n))x_i^n</script><p>那这个式子到底代表着什么意思呢？现在你的update取决于三件事：</p><ul><li>learning rate，是你自己设定的；</li><li>$x_i$，来自于data；</li><li>$\hat{y}^n-f_{w,b}(x^n)$，代表function的output跟理想target的差距有多大，如果离目标越远，update的步伐就要越大。</li></ul><p>通过上面的分析，我们可以将Logistic Regression和Linear Regression的三个步骤作一个<strong>对比</strong>：</p><p><img src="/2020/07/08/ML%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89Logistic-Regression/QQ图片20200708192230.png" style="zoom:60%;"></p><h3 id="2-Logistic-Regression-Square-error？"><a href="#2-Logistic-Regression-Square-error？" class="headerlink" title="2.Logistic Regression + Square error？"></a>2.Logistic Regression + Square error？</h3><p>这里可能会有一个疑惑，为什么Logistic Regression的loss function不能像linear Regression一样用square error来表示呢？我们试着用square error来定义Loss function重新写一下Logistic Regression的三个步骤：</p><p><img src="/2020/07/08/ML%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89Logistic-Regression/QQ图片20200708192527.png" style="zoom:67%;"></p><p><img src="/2020/07/08/ML%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89Logistic-Regression/QQ图片20200708192546.png" style="zoom: 67%;"></p><p>这样就会遇到一个问题：如果第n个点的目标target是class 1，则$\hat{y}^n=1$，此时如果function的output $f_{w,b}(x^n)=1$的话，说明现在离target很接近了，$f_{w,b}(x)-\hat{y}$这一项是0，于是得到的微分$\frac{\partial L}{\partial w_i}$会变成0，这件事情是很合理的；但是当function的output $f_{w,b}(x^n)=0$的时候，说明离target还很遥远，但是由于在step3中求出来的update表达式中有一个$f_{w,b}(x^n)$，因此这个时候也会导致得到的微分$\frac{\partial L}{\partial w_i}$变成0，这样无论function的输出是1还是0，微分项都会是0，导致在做gradient descent时参数无法获得更新。如果举class 2的例子，得到的结果与class 1是一样的。</p><p>如果我们把参数的变化对total loss作图的话，loss function选择cross entropy或square error，参数的变化跟loss的变化情况可视化出来如下所示：(黑色的是cross entropy，红色的是square error)</p><p><img src="/2020/07/08/ML%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89Logistic-Regression/QQ图片20200708192935.png" style="zoom:67%;"></p><p>假设中心点就是距离目标很近的地方，如果是cross entropy的话，距离目标越远，微分值就越大，参数update的时候变化量就越大，迈出去的步伐也就越大。但当选择square error的时候，过程就会很卡，因为距离目标远的时候，微分也是非常小的，移动的速度是非常慢的。我们之前提到过，实际操作的时候，当gradient接近于0的时候，其实就很有可能会停下来，因此使用square error很有可能在一开始的时候就卡住不动了，而且这里也不能随意地增大learning rate，因为在做gradient descent的时候，你的gradient接近于0，有可能离target很近也有可能很远，因此不知道learning rate应该设大还是设小。</p><p>综上，尽管square error可以使用，但是会出现update十分缓慢的现象，而使用cross entropy可以让你的Training更顺利。</p><h3 id="3-Discriminative-v-s-Generative"><a href="#3-Discriminative-v-s-Generative" class="headerlink" title="3. Discriminative v.s. Generative"></a>3. Discriminative v.s. Generative</h3><p><strong>same model but different currency</strong></p><p>Logistic Regression的方法，称之为Discriminative的方法；而上节课中用Gaussian来描述posterior Probability来建立Generative model的方法，称之为Generative的方法。</p><p><img src="/2020/07/08/ML%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89Logistic-Regression/QQ图片20200708193605.png" style="zoom:67%;"></p><p>实际上它们用的model(function set)是一模一样的，都是$P(C_1|x)=\sigma(w\cdot x+b)$，如果是用Logistic Regression的话，可以用gradient descent的方法直接去把b和w找出来；如果是用Generative model的话，我们要先去算$u_1,u_2,\Sigma^{-1}$，然后算出b和w。</p><p>但是用这两种方法得到的b和w是不同的，尽管我们的function set是同一个，但是由于做了不同的假设，最终从同样的Training data里找出来的参数会是不一样的。</p><p>在Logistic Regression里面，我们<strong>没有做任何实质性的假设</strong>，没有对Probability distribution有任何的描述，我们就是单纯地去找b和w(推导过程中的假设只是便于理解和计算，对实际结果没有影响)。而在Generative model里面，我们对Probability distribution是<strong>有实质性的假设</strong>的，之前我们假设的是Gaussian(高斯分布)，甚至假设在相互独立的前提下是否可以是naive bayes(朴素贝叶斯)，根据这些假设我们才找到最终的b和w</p><p>下图是宝可梦属性分类例子中Generative model和discriminative model的预测结果比较：</p><p><img src="/2020/07/08/ML%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89Logistic-Regression/QQ图片20200708193814.png" style="zoom:67%;"></p><p>实际上Discriminative的方法常常会比Generative的方法表现得更好，这里举一个简单的例子来解释一下：</p><p><img src="/2020/07/08/ML%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89Logistic-Regression/QQ图片20200708194028.png" style="zoom: 67%;"></p><p>Testing data的两个feature都是1，凭直觉来说会认为它肯定是class 1。但是如果用naive bayes的方法(朴素贝叶斯假设所有的feature相互独立，方便计算)，却会得到相反的结果：</p><p><img src="/2020/07/08/ML%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89Logistic-Regression/QQ图片20200708194032.png" style="zoom: 67%;"></p><p><img src="/2020/07/08/ML%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89Logistic-Regression/QQ图片20200708194035.png" style="zoom:67%;"></p><p>Discriminative model在data充足的情况下，它训练出来的model的准确率一般是比Generative model要来的高的。但是Generative的方法也有它自己的优势：它对data的依赖并没有像discriminative model那么严重，在data数量少或者data本身就存在noise的情况下受到的影响会更小，而它还可以做到Prior部分与class-dependent部分分开处理，如果可以借助其他方式提高Prior model的准确率，对整一个model是有所帮助的(比如前面提到的语音辨识)。</p><p><img src="/2020/07/08/ML%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89Logistic-Regression/QQ图片20200708194443.png" style="zoom:67%;"></p><h3 id="4-Multi-class-Classification"><a href="#4-Multi-class-Classification" class="headerlink" title="4.Multi-class Classification"></a>4.Multi-class Classification</h3><p>之前讲的都是二元分类的情况，这里讨论一下多元分类问题，其原理的推导过程与二元分类基本一致</p><p>假设有三个class：$C_1,C_2,C_3$，每一个class都有自己的weight和bias，这里$w_1,w_2,w_3$分布代表三个vector，$b_1,b_2,b_3$分别代表三个const，input x也是一个vector</p><blockquote><p>softmax的意思是对最大值做强化，因为在做第一步的时候，对$z$取exponential会使大的值和小的值之间的差距被拉得更开，也就是强化大的值。</p></blockquote><p>我们把$z_1,z_2,z_3$丢进一个<strong>softmax</strong>的function，softmax做的事情是这样三步：</p><ul><li>取exponential，得到$e^{z_1},e^{z_2},e^{z_3}$</li><li>把三个exponential累计求和，得到total sum=$\sum\limits_{j=1}^3 e^{z_j}$</li><li>将total sum分别除去这三项(归一化)，得到$y_1=\frac{e^{z_1}}{\sum\limits_{j=1}^3 e^{z_j}}$、$y_2=\frac{e^{z_2}}{\sum\limits_{j=1}^3 e^{z_j}}$、$y_3=\frac{e^{z_3}}{\sum\limits_{j=1}^3 e^{z_j}}$</li></ul><p><img src="/2020/07/08/ML%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89Logistic-Regression/QQ图片20200708194749.png" style="zoom:67%;"></p><p>原来的output $z$可以是任何值，但是做完softmax之后，output $y_i$的值一定是介于0~1之间，并且其和一定是1，$\sum\limits_i y_i=1$。softmax的output，就是拿来当z的posterior probability。</p><p>假设我们用的是Gaussian distribution(共用covariance)，经过一般推导以后可以得到softmax的function，而从information theory也可以推导出softmax function，Maximum entropy本质内容和Logistic Regression是一样的，它是从另一个观点来切入为什么我们的classifier长这样子。</p><h5 id="multi-class-classification的过程："><a href="#multi-class-classification的过程：" class="headerlink" title="multi-class classification的过程："></a><strong>multi-class classification的过程：</strong></h5><p>如下图所示，input $x$经过三个式子分别生成$z_1,z_2,z_3$，经过softmax转化成output $y_1,y_2,y_3$，它们分别是这三个class的posterior probability，由于summation=1，因此做完softmax之后就可以把y的分布当做是一个probability contribution，我们在训练的时候还需要有一个target，因为是三个class，output是三维的，对应的target也是三维的，为了满足交叉熵的条件，target $\hat{y}$也必须是probability distribution，这里我们不能使用1,2,3作为class的区分，为了保证所有class之间的关系是一样的，这里使用类似于one-hot编码的方式，即:</p><script type="math/tex; mode=display">\hat{y}=\begin{bmatrix}1\\0\\0\end{bmatrix}_{x \ ∈ \ class 1}\hat{y}=\begin{bmatrix}0\\1\\0\end{bmatrix}_{x \ ∈ \ class 2}\hat{y}=\begin{bmatrix}0\\0\\1\end{bmatrix}_{x \ ∈ \ class 3}</script><p><img src="/2020/07/08/ML%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89Logistic-Regression/QQ图片20200708194751.png" style="zoom:67%;"></p><p>这个时候就可以计算一下output $y$和 target $\hat{y}$之间的交叉熵，即$-\sum\limits_{i=1}^3 \hat{y}_i \ln y_i$，同二元分类一样，多元分类问题也是通过极大似然估计法得到最终的交叉熵表达式的，这里不再赘述。</p><p><strong>Limitation of Logistic Regression</strong></p><p>Logistic Regression其实有很强的限制，给出下图的例子中的Training data，想要用Logistic Regression对它进行分类，其实是做不到的。</p><p><img src="/2020/07/08/ML%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89Logistic-Regression/QQ图片20200708194755.png" style="zoom:67%;"></p><p>因为Logistic Regression在两个class之间的boundary就是一条直线，但是在这个平面上无论怎么画直线都不可能把图中的两个class分隔开来。关于这种不可分问题，还有几个点最多可以分几类的问题的深入分析可以看林轩田老师的《机器学习基石》课程的Lecture 5和Lecture 6。</p><p><strong>Feature Transformation</strong></p><p>如果坚持要用Logistic Regression的话，可以使用<strong>Feature Transformation</strong>的方法，原来的feature分布不好划分，那我们可以将之转化以后，找一个比较好的feature space，让Logistic Regression能够处理。</p><p>比如我们可以这样做：假设这里定义$x_1’$是原来的点到$\begin{bmatrix}0\\0 \end{bmatrix}$之间的距离，$x_2’$是原来的点到$\begin{bmatrix}1\\ 1 \end{bmatrix}$之间的距离，重新映射之后如下图右侧(红色两个点重合)，此时Logistic Regression就可以把它们划分开来。</p><p><img src="/2020/07/08/ML%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89Logistic-Regression/QQ图片20200708194804.png" style="zoom:67%;"></p><p>但麻烦的是，我们通常并不知道怎么做到有效的feature Transformation，如果在这上面花费太多的时间就得不偿失了，于是我们会希望这个Transformation是机器自己产生的，怎么让机器自己产生呢？</p><p>我们可以让很多<strong>Logistic Regression cascade</strong>(连接)起来，让一个input $x$的两个feature $x_1,x_2$经过两个Logistic Regression的transform，得到新的feature $x_1’,x_2’$，在这个新的feature space上，class 1和class 2是可以用一条直线分开的，那么最后只要再接另外一个Logistic Regression的model(对它来说，$x_1’,x_2’$才是每一个样本点的”feature”，而不是原先的$x_1,x_2$)，它根据新的feature，就可以把class 1和class 2分开。</p><p><img src="/2020/07/08/ML%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89Logistic-Regression/QQ图片20200708194801.png" style="zoom:67%;"></p><p>因此着整个流程是，先用n个Logistic Regression做feature Transformation(n为每个样本点的feature数量)，生成n个新的feature，然后再用一个Logistic Regression作classifier</p><p>Logistic Regression的boundary一定是一条直线，它可以有任何的画法，但肯定是按照某个方向从高到低的等高线分布，具体的分布是由Logistic Regression的参数决定的，每一条直线都是由$z=b+\sum\limits_i^nw_ix_i$组成的(二维feature的直线画在二维平面上，多维feature的直线则是画在多维空间上)</p><p>下图是二维feature的例子，分别表示四个点经过transform之后的$x_1’$和$x_2’$，在新的feature space中可以通过最后的Logistic Regression划分开来。</p><p><img src="/2020/07/08/ML%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89Logistic-Regression/QQ图片20200708200056.png" style="zoom:67%;"></p><p>注意，这里的Logistic Regression只是一条直线，它指的是“属于这个类”或“不属于这个类”这两种情况，因此最后的这个Logistic Regression是跟要检测的目标类相关的，当只是二元分类的时候，最后只需要一个Logistic Regression即可，当面对多元分类问题，需要用到多个Logistic Regression来画出多条直线划分所有的类，每一个Logistic Regression对应它要检测的那个类。</p><p><strong>Powerful Cascading Logistic Regression</strong></p><p>通过上面的例子，我们发现，多个Logistic Regression连接起来会产生很powerful的效果(:3_ヽ)_，如果我们把每一个Logistic Regression叫做一个neuron(神经元)，把这些Logistic Regression串起来所形成的network，就叫做Neural Network 类神经网路，那我们已经开始接触到Deep Learning了∠(ᐛ」∠)＿。</p><p><img src="/2020/07/08/ML%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89Logistic-Regression/QQ图片20200708194808.png" style="zoom:67%;"></p>]]></content>
    
    <summary type="html">
    
      本文介绍了如何用Logisic Regression逻辑回归解决二分类和多分类问题，解释了逻辑回归中为什么不用square error作为loss，以及逻辑回归的局限性，并比较了Discriminative model和Generaive model的区别。
    
    </summary>
    
    
      <category term="Machine Learning" scheme="http://nekomoon404.github.io/categories/Machine-Learning/"/>
    
    
      <category term="Machine Learning" scheme="http://nekomoon404.github.io/tags/Machine-Learning/"/>
    
      <category term="Logistic Regression" scheme="http://nekomoon404.github.io/tags/Logistic-Regression/"/>
    
      <category term="Discriminaive model" scheme="http://nekomoon404.github.io/tags/Discriminaive-model/"/>
    
  </entry>
  
  <entry>
    <title>ML笔记（2）Classification</title>
    <link href="http://nekomoon404.github.io/2020/07/01/ML%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89Classification/"/>
    <id>http://nekomoon404.github.io/2020/07/01/ML%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89Classification/</id>
    <published>2020-07-01T03:06:27.000Z</published>
    <updated>2020-07-01T13:44:49.271Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-Classification"><a href="#1-Classification" class="headerlink" title="1.Classification"></a>1.Classification</h3><p>这节课的例子是对宝可梦进行分类（老宝可梦训练大师了），宝可梦有18种属性，现在要解决的分类问题就是做一个宝可梦种类的分类器，我们要找一个function，这个function的input是某一只宝可梦，它的output就是这只宝可梦属于这18类别中的哪一个type。</p><p><img src="/2020/07/01/ML%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89Classification/QQ图片20200701150638.png" style="zoom: 33%;"></p><p>对每一只宝可梦（比如皮卡丘），可以用7个feature的数值组成的vector来描述它。</p><p><img src="/2020/07/01/ML%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89Classification/QQ图片20200701150644.png" style="zoom:33%;"></p><p>把编号400以下的宝可梦当做training data，编号400以上的当做testing data。这里我们先只考虑二分类，只考虑水系Water和一般系Normal宝可梦。</p><h4 id="1-1-Classification-as-Regression？"><a href="#1-1-Classification-as-Regression？" class="headerlink" title="1.1.Classification as Regression？"></a>1.1.Classification as Regression？</h4><p>以binary classification为例，我们在Training时让输入为class 1的输出为1，输入为class 2的输出为-1；那么在testing的时候，regression的output是一个数值，它接近1则说明它是class 1，它接近-1则说明它是class 2。但Regression中对“好，坏”的定义并不适用于Classification。</p><p><img src="/2020/07/01/ML%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89Classification/QQ图片20200701151214.png" style="zoom:33%;"></p><h4 id="1-2-Ideal-Alternatives"><a href="#1-2-Ideal-Alternatives" class="headerlink" title="1.2.Ideal Alternatives"></a>1.2.Ideal Alternatives</h4><p>理想的方法是这样的：我们要找的function f(x)里面会有另外一个function g(x)，当我们的input x输入后，如果g(x)&gt;0，那f(x)的输出就是class 1，如果g(x)&lt;0，那f(x)的输出就是class 2，这个方法保证了function的output都是离散的表示class的数值。</p><p><img src="/2020/07/01/ML%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89Classification/QQ图片20200701151702.png" style="zoom:33%;"></p><p>把loss function定义成$L(f)=\sum\limits_n\delta(f(x^n)≠\hat{y}^n)$，即这个model在所有的training data上predict预测错误的次数，也就是说分类错误的次数越少，这个function表现得就越好</p><p>但是这个loss function没有办法微分，是无法用gradient descent的方法去解的，当然有Perceptron、SVM这些方法可以用（感知机和支持向量机的内容，在林轩田老师的机器学习基石和技法课程中都有详细的讲解），但这里先用另外一个solution来解决这个问题，即从概率的角度来考虑二分类问题。</p><h3 id="2-Solution-Generative-model"><a href="#2-Solution-Generative-model" class="headerlink" title="2.Solution: Generative model"></a>2.Solution: Generative model</h3><p><img src="/2020/07/01/ML%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89Classification/QQ图片20200701152159.png" style="zoom:33%;"></p><p><img src="/2020/07/01/ML%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89Classification/QQ图片20200701152137.png" style="zoom:33%;"></p><p>这两张图的内容很好理解，就是贝叶斯公式啦。这种想法叫做<strong>Generative model</strong>(生成模型)，因为有这个model，就可以拿它来generate $x$(如果你可以计算出每一个$x$出现的概率，就可以用这个distribution分布来生成$x$、sample $x$出来)。</p><p>接下来考虑怎么计算其中的四项：$P(C_1)，P(C_2)，P(x|C_1)，P(x|C_2)$。</p><h4 id="2-1-Prior"><a href="#2-1-Prior" class="headerlink" title="2.1.Prior"></a>2.1.Prior</h4><p>$P(C_1)$和$P(C_2)$这两个概率，被称为Prior，计算这两个值还是很简单的。</p><p>假设我们还是考虑二元分类问题，编号小于400的data用来Training，编号大于400的data用来testing，如果想要严谨一点，可以在Training data里面分一部分validation出来模拟testing的情况</p><p>在Training data里面，有79只水系宝可梦，61只一般系宝可梦，那么$P(C_1)=79/(79+61)=0.56$，$P(C_2)=61/(79+61)=0.44$</p><h4 id="2-2-Probability-from-Class"><a href="#2-2-Probability-from-Class" class="headerlink" title="2.2.Probability from Class"></a>2.2.Probability from Class</h4><p>计算$P(x|C_1)$和$P(x|C_2)$的值，假设$x$是一只新来的海龟，它显然是水系的，但是在79只水系的宝可梦training data里面根本就没有海龟，那要如何计算$P(x|C_1)$呢。</p><p><img src="/2020/07/01/ML%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89Classification/QQ图片20200701111739.png" style="zoom: 33%;"></p><p>每一只宝可梦可以用由特征值组成的向量来表示，每个sample有7个feature，为了方便可视化，这里只考虑Defense和SP Defence两种feature。我们需要用已有的数据去估测海龟出现的可能性，你可以想象说这已有的79只水系宝可梦的data其实只是冰山一角，假定水系神奇宝贝的Defense和SP Defense是从一个Gaussian的distribution里面sample出来的，下图只是采样了79个点之后得到的分布，但是从高斯分布里采样出海龟这个点的几率并不是0。现在的问题是怎么从这79个已有的点计算出Gaussian distribution函数。</p><h4 id="2-3-Gaussian-distribution函数"><a href="#2-3-Gaussian-distribution函数" class="headerlink" title="2.3.Gaussian distribution函数"></a>2.3.Gaussian distribution函数</h4><script type="math/tex; mode=display">f_{u,\Sigma}(x)=\frac{1}{(2\pi)^{\frac{D}{2}}}\frac{1}{|\Sigma|^{\frac{1}{2}}} \exp \{ -\frac{1}{2}(x-u)^T\Sigma^{-1}(x-u) \}</script><p>Input: vector $x$, output: probability of sampling x ；其中$\mu$表示方差均值mean，$\Sigma$表示协方差矩阵covariance matrix。</p><p>从下图中可以看出，同样的$\Sigma$，不同的$u$，概率分布最高点的地方是不一样的：</p><p><img src="/2020/07/01/ML%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89Classification/QQ图片20200701113417.png" style="zoom: 25%;"></p><p>如果是同样的$u$，不同的$\Sigma$，概率分布最高点的地方是一样的，但是分布的密集程度是不一样的：</p><p><img src="/2020/07/01/ML%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89Classification/QQ图片20200701113421.png" style="zoom:25%;"></p><p>Gaussian distribution函数是由$\mu$和$\Sigma$决定的，估计$\mu$和$\Sigma$可以使用极大似然估计(Maximum Likelihood)的方法，其思路是找出最特殊的那对$u$和$\Sigma$，从它们决定的高斯函数中再次采样出79个点，使”得到的分布情况与当前已知79点的分布情况相同“这件事情发生的可能性最大。</p><p>实际上任意一组$u$和$\Sigma$对应的高斯函数($u$表示该Gaussian的中心点，$\Sigma$表示该Gaussian的分散程度)都有可能sample出跟当前分布一致的样本点，就像上图中的两个红色圆圈所代表的高斯函数，但肯定存在着发生概率最大的哪一个Gaussian，而这个函数就是我们要找的。</p><p><img src="/2020/07/01/ML%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89Classification/QQ图片20200701113858.png" style="zoom:33%;"></p><p>似然函数：</p><script type="math/tex; mode=display">L(u,\Sigma)=f_{u,\Sigma}(x^1)\cdot f_{u,\Sigma}(x^2)...f_{u,\Sigma}(x^{79})</script><p>实际上就是该事件发生的概率就等于每个点都发生的概率之积，要求的$\mu$和$\Sigma$就是使似然函数取极大值的$\mu$和$\Sigma$：</p><script type="math/tex; mode=display">u^*,\Sigma^*=\arg \max\limits_{u,\Sigma} L(u,\Sigma)</script><p>对$\mu$和$\Sigma$分别偏导，使微分等于0，得到的高斯函数的$u$和$\Sigma$的最优解如下：</p><script type="math/tex; mode=display">u^*=\frac{1}{79}\sum\limits_{n=1}^{79}x^n \\ \Sigma^*=\frac{1}{79}\sum\limits_{n=1}^{79}(x^n-u^*)(x^n-u^*)^T</script><p>这样我们由Training Data就可以分别求出Class 1和Class 2的$\mu$和$\Sigma$，从而计算出海龟这个sample的$P(x|C_1),P(x|C_2)$。</p><p><img src="/2020/07/01/ML%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89Classification/QQ图片20200701114737.png" style="zoom: 33%;"></p><h4 id="2-4-Do-Classification"><a href="#2-4-Do-Classification" class="headerlink" title="2.4.Do Classification"></a>2.4.Do Classification</h4><p>接着将$P(C_1),P(x|C_1),P(C_2),P(x|C_2)$代入公式计算出$P(C_1|x)$，若大于0.5，则说明sample $x$属于Class 1啦。</p><p><img src="/2020/07/01/ML%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89Classification/QQ图片20200701115026.png" style="zoom:33%;"></p><p>将得到的结果在图中表示出来，横轴是Defense，纵轴是SP Defense，蓝色的点是水系的宝可梦的分布，红色的点是一般系的宝可梦的分布，对图中的每一个点都计算出它是class 1的概率$P(C_1|x)$，这个概率用颜色来表示，如果某点在红色区域，表示它是水系宝可梦的概率更大；如果该点在其他颜色的区域，表示它是水系宝可梦的概率比较小</p><p>因为我们做的是分类问题，因此令几率&gt;0.5的点为类别1，几率&lt;0.5的点为类别2，也就是右上角的图中的红色和蓝色两块区域，再把testing data上得到的结果可视化出来，即右下角的图，发现分的不是太好，正确率才是47%。</p><p><img src="/2020/07/01/ML%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89Classification/QQ图片20200701120221.png" style="zoom:33%;"></p><p>我们之前用的只是Defense和SP Defense这两个feature，在二维空间上得到的效果不太好，但实际上一开始就提到了宝可梦总共是有7个features的，也许在二维空间上它们是重叠在一起的，但是在六维空间上看它们也许会区分得很好。​考虑7个feature时，$\mu$是一个7-dim的vector，$\Sigma$则是一个7*7的matrix，发现得到的准确率也才54%，这个分类器表现并不好，接下来考虑如何改进这个分类器。</p><h4 id="2-5-Modify-Model"><a href="#2-5-Modify-Model" class="headerlink" title="2.5.Modify Model"></a>2.5.Modify Model</h4><p>上面用到的Gaussian distribution函数，我们给每一个Class的Gaussian都计算了自己的mean和convariance，这种做法其实并不实用，常用的做法是，<strong>不同的class可以share同一个cocovariance matrix</strong>。variance是跟input的feature size的平方成正比的，所以当feature的数量很大的时候，$\Sigma$大小的增长是可以非常快的，在这种情况下，给不同的Gaussian以不同的covariance matrix，会造成model的参数太多，而参数多会导致该model的variance过大，出现overfitting的现象，因此对不同的class使用同一个covariance matrix，可以有效减少参数，减小overfitting。</p><p><img src="/2020/07/01/ML%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89Classification/QQ图片20200701140609.png" style="zoom:33%;"></p><p>这样用$\mu_1$、$\mu_2$和$\Sigma$来决定一个总的似然函数，求出其取极大值时的$\mu_1$、$\mu_2$和$\Sigma$，发现得到的$u_1$和$u_2$和原来一样，还是各自的均值，而$\Sigma$则是原先两个$\Sigma_1$和$\Sigma_2$的加权。</p><p>将结果表示在图中，你会发现，class 1和class 2在没有共用covariance matrix之前，它们的分界线是一条曲线；如果共用covariance matrix的话，它们之间的分界线就会变成一条直线，这样的model，我们也称之为linear model(尽管Gaussian不是linear的，但是它分两个class的boundary是linear)。</p><p><img src="/2020/07/01/ML%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89Classification/QQ图片20200701141141.png" style="zoom:33%;"></p><p>如果考虑宝可梦的所有的7个feature，且共用covariance的话，正确率会从原来的54%提升到73%。</p><h4 id="2-6-Three-Steps-of-classification"><a href="#2-6-Three-Steps-of-classification" class="headerlink" title="2.6.Three Steps of classification"></a>2.6.Three Steps of classification</h4><p>回顾一下做classification的三个步骤，实际上也就是做machine learning的三个步骤：</p><ul><li><p>Find a function set(model)</p><p>这些required probability $P(C)$和probability distribution $P(x|C)$就是model的参数，选择不同的Probability distribution(比如不同的分布函数，或者是不同参数的Gaussian distribution)，就会得到不同的function，把这些不同参数的Gaussian distribution集合起来，就是一个model，如果不适用高斯函数而选择其他分布函数，就是一个新的model了</p><p>当这个posterior Probability $P(C|x)&gt;0.5$的话，就output class 1，反之就output class 2</p></li><li><p>Goodness of function</p><p>对于Gaussian distribution这个model来说，要评价的是决定这个高斯函数形状的均值$u$和协方差$\Sigma$这两个参数的好坏，而极大似然函数$L(u,\Sigma)$的输出值，就评价了这组参数的好坏</p></li><li><p>Find the best function</p><p>找到的那个最好的function，就是使$L(u,\Sigma)$值最大的那组参数，实际上就是所有样本点的均值和协方差：</p><script type="math/tex; mode=display">u^*=\frac{1}{n}\sum\limits_{i=0}^n x^i \ \ \ \ \Sigma^*=\frac{1}{n}\sum\limits_{i=0}^n (x^i-u^*)(x^i-u^*)^T</script><p>式中的$x$表示一个feature的vector，上标$i$表示第$i$个sample</p></li></ul><p><img src="/2020/07/01/ML%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89Classification/QQ图片20200701142029.png" style="zoom: 33%;"></p><h4 id="2-7-Probability-distribution"><a href="#2-7-Probability-distribution" class="headerlink" title="2.7.Probability distribution"></a>2.7.Probability distribution</h4><p>上面的讨论中我们使用的是Gaussian distribution函数，当然你也可以使用其他分布函数，这通常要根据数据集的具体情况来确定，比如一个特征是binary feature，那选择使用伯努利分布Bernoulli distribution比较好。如果选择的是简单的分布函数(参数比较少)，那么bias就偏大，variance就小；如果选择复杂的分布函数，那么bias就偏小，variance就偏大。</p><h5 id="Naive-Bayes-Classifier-朴素贝叶斯分类法"><a href="#Naive-Bayes-Classifier-朴素贝叶斯分类法" class="headerlink" title="Naive Bayes Classifier(朴素贝叶斯分类法)"></a>Naive Bayes Classifier(朴素贝叶斯分类法)</h5><p>考虑这样一件事情，假设$x=[x_1 \ x_2 \ x_3 \ … \ x_k \ … \ ]$中每一个dimension $x_k$的分布都是相互独立的，它们之间的covariance都是0，那我们就可以把x产生的几率拆解成$x_1,x_2,…,x_k$产生的几率之积。</p><p><img src="/2020/07/01/ML%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89Classification/QQ图片20200701142630.png" style="zoom:33%;"></p><p>这里每一个dimension的分布函数都是一维的Gaussian distribution，就相当于原高维的Gaussian，它的covariance matrix变成是diagonal(对角的)，在不是对角线的地方，值都是0，这样就可以更加减少需要的参数量，就可以得到一个更简单的model。</p><p>这种方法叫做Naive Bayes Classifier(朴素贝叶斯分类法)，如果真的明确了<u>所有的feature之间是相互独立的</u>，是不相关的，使用朴素贝叶斯分类法的performance是会很好的；如果这个假设是不成立的，那么Naive bayes classfier的bias就会很大，它就不是一个好的classifier(朴素贝叶斯分类法本质就是减少参数)。</p><p>在宝可梦这个例子中（李老师也是个老二次元了|ू･ω･` )），使用朴素贝叶斯的效果并不好，因为不同feature之间还是有相关的，各种feature之间的covariance还是必要的，比如战斗力和防御力它们之间是正相关的，covariance不能等于0。</p><h4 id="2-8-Analysis-Posterior-Probability"><a href="#2-8-Analysis-Posterior-Probability" class="headerlink" title="2.8.Analysis Posterior Probability"></a>2.8.Analysis Posterior Probability</h4><p>接下来我们来分析一下这个后置概率的表达式，会发现一些有趣的现象</p><p>表达式上下同除以分子，再引入变量$z$，得到$\sigma(z)=\frac{1}{1+e^{-z}}$，这个function叫做sigmoid function</p><p><img src="/2020/07/01/ML%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89Classification/QQ图片20200701144150.png" style="zoom: 25%;"></p><p>sigmoid函数真是再熟悉不过了，接下来推导一下$z$的具体表达式，Warning of Math（老师原话：下面这部分推导听不懂的同学可以先睡一会⊙(・◇・)？，之后直接听结论）</p><p><img src="/2020/07/01/ML%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89Classification/QQ图片20200701144720.png" style="zoom:33%;"></p><p><img src="/2020/07/01/ML%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89Classification/QQ图片20200701144725.png" style="zoom:33%;"></p><p><img src="/2020/07/01/ML%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89Classification/QQ图片20200701144732.png" style="zoom:33%;"></p><p>推导是有些复杂，但当$\Sigma_1$和$\Sigma_2$相同时，经过化简$z$就变成了一个linear的function，$x$前的一项可以当做vector $w$，后面的几项相加是一个scalar，当做常数$b$。</p><p><img src="/2020/07/01/ML%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89Classification/QQ图片20200701145229.png" style="zoom:33%;"></p><p>$P(C_1|x)=\sigma (w\cdot x+b)$这个式子就解释了，当class 1和class 2共用$\Sigma$的时候，它们之间的boundary会是线性的。</p><p>这样在Generative model里，我们要做的就是用某些方法去找出$N_1,N_2,u_1,u_2,\Sigma$，找出这些以后就算出$w$和$b$，把它们代进$P(C_1|x)=\sigma(w\cdot x+b)$这个式子，计算概率。</p><p>但是为什么要这么麻烦呢(ｷ｀ﾟДﾟ´)？我们的最终目标都是要找一个vector $w$和const $b$，何必先去计算概率，算出一些$u,\Sigma$，然后再回过头来又去算$w$和$b$。那么能不能直接把$w$和$b$计算出来呢，下一节课Logistic Regression将会解决这个问题。</p>]]></content>
    
    <summary type="html">
    
      本文以宝可梦分类为例，从概率的角度来解释一个二元分类问题
    
    </summary>
    
    
      <category term="Machine Learning" scheme="http://nekomoon404.github.io/categories/Machine-Learning/"/>
    
    
      <category term="Machine Learning" scheme="http://nekomoon404.github.io/tags/Machine-Learning/"/>
    
      <category term="Classification" scheme="http://nekomoon404.github.io/tags/Classification/"/>
    
  </entry>
  
  <entry>
    <title>ML笔记（1）Gradient_Descent</title>
    <link href="http://nekomoon404.github.io/2020/06/30/ML%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89Gradient-Descent/"/>
    <id>http://nekomoon404.github.io/2020/06/30/ML%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89Gradient-Descent/</id>
    <published>2020-06-30T03:05:18.000Z</published>
    <updated>2020-06-30T04:05:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>这周开始学李宏毅老师的Machine Learning 2020的课程了，从第一节课的课程概述来看，这门课除了会介绍传统的Machine Learning算法外，还会介绍很多Deep Learning的内容，时长也是非常感人(ㄒoㄒ)，希望自己能坚持学下去吧。</p><p><img src="/2020/06/30/ML%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89Gradient-Descent/QQ图片20200701212455.png" style="zoom: 60%;"></p><p><img src="/2020/06/30/ML%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89Gradient-Descent/QQ图片20200701212506.png" style="zoom:50%;"></p><p>前面几节课（p3-p7）分别讲了回归 Regression，误差来源 Where does the error come from，梯度下降 Gradient Descent，老师用的预测宝可梦pokemon的CP值的例子还是蛮有趣的hhh。这部分的理论内容自己是比较熟悉，也有之前做的纸质笔记，在这里就不详细展开了，这里主要写一下使用Gradient Descent的Tips，以及其背后的Theory。</p><h1 id="1-Gradient-Descent-Tips"><a href="#1-Gradient-Descent-Tips" class="headerlink" title="1. Gradient Descent Tips"></a>1. Gradient Descent Tips</h1><h2 id="1-1-Tip-1-Tuning-your-learning-rates"><a href="#1-1-Tip-1-Tuning-your-learning-rates" class="headerlink" title="1.1.Tip 1: Tuning your learning rates"></a>1.1.Tip 1: Tuning your learning rates</h2><p>gradient descent过程中，影响结果的一个很关键的因素就是learning rate的大小</p><p><img src="/2020/06/30/ML%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89Gradient-Descent/QQ图片20200701212510.png" style="zoom: 67%;"></p><p>当参数有很多个的时候(&gt;3)，其实我们很难做到将loss随每个参数的变化可视化出来(因为最多只能可视化出三维的图像，也就只能可视化三维参数)，但是我们可以把update的次数作为唯一的一个参数，将loss随着update的增加而变化的趋势给可视化出来(上图右半部分)</p><p>所以做gradient descent时可以把不同的learning rate下，loss随update次数的变化曲线给可视化出来，它可以提醒你该如何调整当前的learning rate的大小，直到出现稳定下降的曲线</p><h3 id="Adaptive-Learning-rates"><a href="#Adaptive-Learning-rates" class="headerlink" title="Adaptive Learning rates"></a>Adaptive Learning rates</h3><p>显然这样手动地去调整learning rates很麻烦，因此我们需要有一些自动调整learning rates的方法。最基本、最简单的大原则是：learning rate通常是随着参数的update越来越小的。可以这样理解：在起始点的时候，通常是离最低点是比较远的，这时候步伐就要跨大一点；而经过几次update以后，会比较靠近目标，这时候就应该减小learning rate，让它能够收敛在最低点的地方。如可以设置到了第t次update，$\eta^t=\eta/ \sqrt{t+1}$。</p><p><img src="/2020/06/30/ML%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89Gradient-Descent/QQ图片20200701212514.png" style="zoom: 67%;"></p><p>这种方法使所有参数以同样的方式同样的learning rate进行update，而最好的状况是每个参数都给他不同的learning rate去update</p><h3 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h3><p><strong>Adagrad</strong>就是将不同参数的learning rate分开考虑的一种算法(adagrad算法update到后面速度会越来越慢，当然这只是adaptive算法中最简单的一种)。</p><p><img src="/2020/06/30/ML%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89Gradient-Descent/QQ图片20200701212519.png" style="zoom:67%;"></p><p>这里的$w$是function中的某个参数，$t$表示第$t$次update，$g^t$表示Loss对$w$的偏微分，而$\sigma^t$是之前所有Loss对$w$偏微分的<strong>均方根 root mean square</strong>这个值对每一个参数来说都是不一样的。</p><script type="math/tex; mode=display">\begin{equation}\begin{split}&Adagrad\\&w^1=w^0-\frac{\eta^0}{\sigma^0}\cdot g^0 \ \ \ \sigma^0=\sqrt{(g^0)^2} \\&w^2=w^1-\frac{\eta^1}{\sigma^1}\cdot g^1 \ \ \ \sigma^1=\sqrt{\frac{1}{2}[(g^0)^2+(g^1)^2]} \\&w^3=w^2-\frac{\eta2}{\sigma^2}\cdot g^2 \ \ \ \sigma^2=\sqrt{\frac{1}{3}[(g^0)^2+(g^1)^2+(g^2)^2]} \\&... \\&w^{t+1}=w^t-\frac{\eta^t}{\sigma^t}\cdot g^t \ \ \ \sigma^t=\sqrt{\frac{1}{1+t}\sum\limits_{i=0}^{t}(g^i)^2}\end{split}\end{equation}</script><p>由于$\eta^t$和$\sigma^t$中都有一个$\sqrt{\frac{1}{1+t}}$的因子，两者相消，即可得到Adagrad的最终表达式：</p><script type="math/tex; mode=display">w^{t+1}=w^t-\frac{\eta}{\sqrt{\sum\limits_{i=0}^t(g^i)^2}}\cdot g^t</script><h3 id="对Adagrad中的contradiction的解释"><a href="#对Adagrad中的contradiction的解释" class="headerlink" title="对Adagrad中的contradiction的解释"></a>对Adagrad中的contradiction的解释</h3><p>Adagrad的表达式$w^{t+1}=w^t-\frac{\eta}{\sqrt{\sum\limits_{i=0}^t(g^i)^2}}\cdot g^t$里面有一件很矛盾的事情：我们在做gradient descent的时候，希望的是当梯度值即微分值$g^t$越大的时候(此时斜率越大，还没有接近最低点)更新的步伐要更大一些，但是Adagrad的表达式中，分母表示梯度越大步伐越大，分子却表示梯度越大步伐越小，两者似乎相互矛盾。</p><p><img src="/2020/06/30/ML%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89Gradient-Descent/QQ图片20200701212523.png" style="zoom:67%;"></p><p>在一些paper里是这样解释的：Adagrad要考虑的是，这个gradient有多surprise，即反差有多大，假设t=4的时候$g^4$与前面的gradient反差特别大，那么$g^t$与$\sqrt{\frac{1}{t+1}\sum\limits_{i=0}^t(g^i)^2}$之间的大小反差就会比较大，它们的商就会把这一反差效果体现出来。</p><p><img src="/2020/06/30/ML%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89Gradient-Descent/QQ图片20200701212527.png" style="zoom:67%;"></p><p>而且需要注意的是：gradient越大，离最低点越远，这个有点直观的想法在有多个参数的情况下是不一定成立的。如下图所示，$w_1$和$w_2$分别是loss function的两个参数，loss的值投影到该平面中以颜色深度表示大小，分别在$w_2$和$w_1$处垂直切一刀(这样就只有另一个参数的gradient会变化)，对应的情况为右边的两条曲线，可以看出，比起a点，c点距离最低点更近，但是它的gradient却越大。</p><p><img src="/2020/06/30/ML%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89Gradient-Descent/QQ图片20200701212530.png" style="zoom:67%;"></p><p>考虑一个简单的情况，对于一个二次函数$y=ax^2+bx+c$来说，最小值点的$x=-\frac{b}{2a}$，而对于任意一点$x_0$，它迈出最好的步伐长度是$|x_0+\frac{b}{2a}|=|\frac{2ax_0+b}{2a}|$(这样就一步迈到最小值点了)，联系该函数的一阶和二阶导数$y’=2ax+b$、$y’’=2a$，可以发现the best step 就是 $|\frac{y’}{y’’}|$，即|一阶导数|/|二阶导数|，可见best step不仅跟一阶导数(gradient)有关，还跟二阶导数有关，用这个best step可以来反映Loss Function上一点到最低点的距离。</p><p>再来回顾Adagrad的表达式：</p><script type="math/tex; mode=display">w^{t+1}=w^t-\frac{\eta}{\sqrt{\sum\limits_{i=0}^t(g^i)^2}}\cdot g^t</script><p>其中，$g^t$是一次微分，而分母中的$\sqrt{\sum\limits_{i=0}^t(g^i)^2}$则反映了二次微分的大小。Adagrad中用root mean square of the previous derivatives of parameter w来近似二次微分的大小，避免引入额外的计算量。</p><p><img src="/2020/06/30/ML%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89Gradient-Descent/QQ图片20200701213759.png" style="zoom:33%;"></p><h2 id="1-2-Tip-2-Stochastic-Gradient-Descent"><a href="#1-2-Tip-2-Stochastic-Gradient-Descent" class="headerlink" title="1.2.Tip 2: Stochastic Gradient Descent"></a>1.2.Tip 2: Stochastic Gradient Descent</h2><p><strong>随机梯度下降 Stochastic Gradient Descent</strong>的方法可以让训练更快速，传统的gradient descent的思路是遍历所有的样本点之后再构建loss function，然后去update参数；而stochastic gradient descent的做法是，看到一个样本点就update一次，因此它的loss function不是所有样本点的error平方和，而是这个随机样本点的error平方。</p><p><img src="/2020/06/30/ML%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89Gradient-Descent/QQ图片20200701212538.png" style="zoom: 67%;"></p><p>Stochastic Gradient Descent与传统Gradient Descent的效果对比如下：</p><p><img src="/2020/06/30/ML%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89Gradient-Descent/QQ图片20200701212543.png" style="zoom:67%;"></p><h2 id="1-3-Tip-3-Feature-Scaling"><a href="#1-3-Tip-3-Feature-Scaling" class="headerlink" title="1.3.Tip 3: Feature Scaling"></a>1.3.Tip 3: Feature Scaling</h2><p><strong>特征缩放Feature Scaling</strong>，当多个特征的尺度很不一样时，最好将这些不同feature的范围缩放成一样的。</p><p><img src="/2020/06/30/ML%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89Gradient-Descent/QQ图片20200701212548.png" style="zoom:67%;"></p><p>举个例子来解释为什么需要做feature scaling，$y=b+w_1x_1+w_2x_2$，假设$x_1$的值都是很小的，比如1,2…；$x_2$的值都是很大的，比如100,200…。此时去画出loss的error surface，如果对$w_1$和$w_2$都做一个同样的变动$\Delta w$，那么$w_1$的变化对$y$的影响是比较小的，而$w_2$的变化对$y$的影响是比较大的。</p><p><img src="/2020/06/30/ML%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89Gradient-Descent/QQ图片20200701212552.png" style="zoom:67%;"></p><p>左边的error surface表示，w1对y的影响比较小，所以w1对loss是有比较小的偏微分的，因此在w1的方向上图像是比较平滑的；w2对y的影响比较大，所以w2对loss的影响比较大，因此在w2的方向上图像是比较sharp的。如果x1和x2的的scale是接近的，那么w1和w2对loss就会有差不多的影响力，loss的图像接近于圆形，那这样做对gradient descent有什么好处呢？</p><p><strong>对Gradient Descent的帮助</strong></p><p>之前我们做的demo已经表明了，对于这种长椭圆形的error surface，如果不使用Adagrad之类的方法，是很难搞定它的，因为在像w1和w2这样不同的参数方向上，会需要不同的learning rate，用相同的learning rate很难达到最低点。如果x1和x2有相同的scale的话，loss在参数w1、w2平面上的投影就是一个正圆形，update参数会比较容易。</p><p>而且gradient descent的每次update并不都是向着最低点走的，每次update的方向是顺着等高线的方向(梯度gradient下降的方向)，而不是径直走向最低点；但是当经过对input的scale使loss的投影是一个正圆的话，不管在这个区域的哪一个点，它都会向着圆心走。因此feature scaling对参数update的效率是有帮助的</p><p><strong>如何做feature scaling</strong></p><p>假设有R个example(上标i表示第i个样本点)，$x^1,x^2,x^3,…,x^r,…x^R$，每一个example，它里面都有一组feature(下标j表示该样本点的第j个特征)</p><p>对每一个feature (demension)  i，都去算出它的平均值mean=$m_i$，以及标准差standard deviation=$\sigma_i$</p><p>对第r个example的第i个feature的值，减掉均值，除以标准差，即：</p><script type="math/tex; mode=display">x_i^r=\frac{x_i^r-m_i}{\sigma_i}</script><p><img src="/2020/06/30/ML%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89Gradient-Descent/QQ图片20200701212556.png" style="zoom:67%;"></p><h1 id="2-Gradient-Descent-Theory"><a href="#2-Gradient-Descent-Theory" class="headerlink" title="2.Gradient Descent Theory"></a>2.Gradient Descent Theory</h1><p>考虑当用梯度下降解决问题：</p><script type="math/tex; mode=display">\theta^*=\arg \underset{\theta}{\min} L(\theta)</script><p>每次更新参数 $\theta$，都得到一个新的$ \theta$，它都使得损失函数更小。即：</p><script type="math/tex; mode=display">L(\theta^0)>L(\theta^1)>L(\theta^2)>\dots</script><p>上述结论正确吗？其实是不正确的，我们并不能每次更新$\theta$，都能使损失函数更小。那么如何更新$\theta$才能使损失函数更小呢。</p><p><img src="/2020/06/30/ML%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89Gradient-Descent/QQ图片20200701214114.png" style="zoom: 33%;"></p><p>比如在$\theta^0$ 处，可以在一个小范围的圆圈内找到使损失函数最小的$\theta^1$，不断的这样去寻找。接着就考虑如何在这样一个小圆圈中寻找到$\theta^1$。这里就需要引入泰勒展开式（高数里都有讲啦）。</p><p><img src="/2020/06/30/ML%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89Gradient-Descent/QQ图片20200701212559.png" style="zoom:67%;"></p><p><img src="/2020/06/30/ML%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89Gradient-Descent/QQ图片20200701212603.png" style="zoom:67%;"></p><p>回到刚才的问题上，我们将点(a,b)附件的小圆内的损失函数在点(a,b)处展开：</p><script type="math/tex; mode=display">L(\theta)≈L(a,b)+\frac{\partial L(a,b)}{\partial \theta_1}(\theta_1-a)+\frac{\partial L(a,b)}{\partial \theta_2}(\theta_2-b)</script><p>令</p><script type="math/tex; mode=display">s=L(a,b),\quad u=\frac{\partial L(a,b)}{\partial \theta_1},\quad v=\frac{\partial L(a,b)}{\partial \theta_2}</script><p>则</p><script type="math/tex; mode=display">L(\theta)≈s + u\cdot (\theta_1-a)+v\cdot (\theta_2-b)</script><p>设红色圆圈的半径为d，则有限制条件：</p><script type="math/tex; mode=display">(\theta_1-a)^2+(\theta_2-b)^2≤d^2</script><p>求$L(\theta)_{min}$，这里有个小技巧，把$L(\theta)$转化为两个向量的乘积：</p><script type="math/tex; mode=display">u\cdot (\theta_1-a)+v\cdot (\theta_2-b)=(u,v)\cdot (\theta_1-a,\theta_2-b)=(u,v)\cdot (\Delta \theta_1,\Delta \theta_2)</script><p>显然，当向量$(\theta_1-a,\theta_2-b)$与向量$(u,v)$反向，且刚好到达red circle的边缘时(用$\eta$去控制向量的长度)，$L(\theta)$最小。</p><p><img src="/2020/06/30/ML%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89Gradient-Descent/QQ图片20200701212620.png" style="zoom:67%;"></p><p>于是$L(\theta)$局部最小值对应的参数为中心点减去gradient的加权：</p><script type="math/tex; mode=display">\begin{bmatrix}\Delta \theta_1 \\ \Delta \theta_2\end{bmatrix}=-\eta\begin{bmatrix}u \\v\end{bmatrix}=>\begin{bmatrix}\theta_1 \\\theta_2\end{bmatrix}=\begin{bmatrix}a\\b\end{bmatrix}-\eta\begin{bmatrix}u\\v\end{bmatrix}=\begin{bmatrix}a\\b\end{bmatrix}-\eta\begin{bmatrix}\frac{\partial L(a,b)}{\partial \theta_1}\\\frac{\partial L(a,b)}{\partial \theta_2}\end{bmatrix}</script><p>这就是gradient descent在数学上的推导，注意它的重要<strong>前提</strong>是，<strong>设定的红色圈圈的范围要足够小</strong>，这样泰勒展开给我们的近似才会精确，而$\eta$的值是与圆的半径成正比的，因此理论上learning rate要无穷小才能够保证每次gradient descent在update参数之后的loss会越来越小。于是当learning rate没有设置好，泰勒近似不成立，就有可能使gradient descent过程中的loss没有越来越小</p><p>当然泰勒展开可以使用二阶、三阶乃至更高阶的展开，但这样会使得运算量大大增加，反而降低了运行效率。</p><h1 id="3-More-Limitation-of-Gradient-Descent"><a href="#3-More-Limitation-of-Gradient-Descent" class="headerlink" title="3.More Limitation of Gradient Descent"></a>3.More Limitation of Gradient Descent</h1><p>之前已经讨论过，gradient descent有一个问题是它会停在local minima的地方就停止update了。事实上还有一个问题是，微分值是0的地方并不是只有local minima，settle point （鞍点）的微分值也是0。以上都是理论上的探讨，到了实践的时候，其实当gradient的值接近于0的时候，我们就已经把它停下来了，但是微分值很小，不见得就是很接近local minima，也有可能是在一个鞍点上。还有个限制就是在”坡度“小的区域update得很慢。总结一下就是下面三点：</p><ul><li>Very slow at the plateau</li><li>Stuck at saddle point</li><li>Stuck at local minima</li></ul><p><img src="/2020/06/30/ML%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89Gradient-Descent/QQ图片20200701212616.png" style="zoom:67%;"></p>]]></content>
    
    <summary type="html">
    
      本文主要介绍了使用Gradient Dsecent时的三个Tips：Tuning your learning rates；Stochastic Gradient Descent；Feature Scaling，以及Gradient Descent背后的数学原理。
    
    </summary>
    
    
      <category term="Machine Learning" scheme="http://nekomoon404.github.io/categories/Machine-Learning/"/>
    
    
      <category term="Machine Learning" scheme="http://nekomoon404.github.io/tags/Machine-Learning/"/>
    
      <category term="Gradient Descent" scheme="http://nekomoon404.github.io/tags/Gradient-Descent/"/>
    
  </entry>
  
  <entry>
    <title>单目视觉里程计</title>
    <link href="http://nekomoon404.github.io/2020/06/16/%E5%8D%95%E7%9B%AE%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1/"/>
    <id>http://nekomoon404.github.io/2020/06/16/%E5%8D%95%E7%9B%AE%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1/</id>
    <published>2020-06-16T02:15:05.000Z</published>
    <updated>2020-06-27T03:23:39.546Z</updated>
    
    <content type="html"><![CDATA[<p>视觉里程计(Visual Odometry，VO)是一种利用连续的图像序列来估计相机或机器人移动距离的方法，也被称为Visual SLAM问题的前端，是移动机器人定位导航领域中的关键技术之一。作业要求基于OpenCV初步实现一个简单的视觉里程计，我主要参考了高翔的《视觉slam十四讲》来完成，并将项目上传到Github，地址为<a href="https://github.com/nekomoon404/slam-VO" target="_blank" rel="noopener">https://github.com/nekomoon404/slam-VO</a>。下面整理了这次大作业的报告文档。</p><h2 id="视觉里程效果截图"><a href="#视觉里程效果截图" class="headerlink" title="视觉里程效果截图"></a>视觉里程效果截图</h2><p><img src="/2020/06/16/%E5%8D%95%E7%9B%AE%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1/微信图片_20200616071621.png" style="zoom:80%;"></p><h2 id="程序使用方法"><a href="#程序使用方法" class="headerlink" title="程序使用方法"></a>程序使用方法</h2><p>运行环境：Ubuntu16.04+OpenCV3.4.0</p><p>安装程序所需的依赖库：线性代数库<code>Eigen3</code>，基于图优化的库<code>g2o</code>。</p><p>使用的数据集：KITTI数据集 灰度序列  /00/image_0 中的前2000帧图片</p><p>运行前更改<code>slam-VO.h</code>文件中第137行对应的路径：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">ifstream <span class="title">myfile</span> <span class="params">(<span class="string">"/home/neko/slam-VO/poses/00.txt"</span>)</span></span>;</span><br></pre></td></tr></table></figure><p>更改<code>slam-VO.cpp</code>文件中第23到25行，以及第99行对应的路径：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sprintf</span>(filename1, <span class="string">"/home/neko/slam-VO/00/image_0/%06d.png"</span>, <span class="number">0</span>);</span><br><span class="line"><span class="built_in">sprintf</span>(filename2, <span class="string">"/home/neko/slam-VO/00/image_0/%06d.png"</span>, <span class="number">1</span>);</span><br><span class="line"><span class="built_in">string</span> pose_path =  <span class="string">"/home/neko/slam-VO/poses/00.txt"</span>;</span><br><span class="line"></span><br><span class="line"><span class="built_in">sprintf</span>(filename, <span class="string">"/home/neko/slam-VO/00/image_0/%06d.png"</span>, numFrame);</span><br></pre></td></tr></table></figure><p>进入<code>/build</code>文件夹，在终端依次执行来运行程序：</p><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">cmake</span></span> ..</span><br><span class="line">make</span><br><span class="line">./slam-VO</span><br></pre></td></tr></table></figure><h2 id="算法详细介绍"><a href="#算法详细介绍" class="headerlink" title="算法详细介绍"></a>算法详细介绍</h2><p>程序的<strong>整体流程</strong>如下：</p><p><img src="/2020/06/16/%E5%8D%95%E7%9B%AE%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1/流程图4.jpg" style="zoom: 67%;"></p><p>单目视觉初始化： </p><ol><li>读取第一、二帧图片，并提取第一帧图片的特征点；</li><li>通过光流跟踪法得到第二帧图片的特征点，删除跟踪失败的点；</li><li>计算本质矩阵，并恢复运动，并以该转换矩阵作为初始值。</li></ol><p>主循环：</p><p>连续读取图片，当读取图片帧数小于设定的最大帧数<code>MAX_FRAME</code>时：</p><ol><li>光流跟踪前一帧图片特征点，得到当前帧特征点，并删除跟踪失败的点;</li><li>计算本质矩阵，并恢复旋转运动$\pmb{R}$和平移运动$\pmb{t}$；</li><li>根据匹配到的两帧特征点，进行三角测量，计算两帧图片之间的距离尺度scale;</li><li>由前一帧图片的位置、当前图片旋转、平移矩阵、距离尺度，计算得到当前图片的位置，生成相机轨迹；</li><li>进行BA优化；</li><li>保存优化后的平移运动结果，画出轨迹；</li><li>判断跟踪后的特征点数目是否大于设定阈值<code>MIN_NUM_FEAT</code>，若小于则重新检测</li></ol><h2 id="1-图片提取"><a href="#1-图片提取" class="headerlink" title="1.图片提取"></a>1.图片提取</h2><p>根据网上的教程资料配置了Ubuntu16.04+OpenCV3.4.0的环境，具体步骤为：</p><ol><li><p>下载OpenCV3.4.0  sources版本，解压</p></li><li><p>安装<code>opencv</code>的依赖库和<code>cmake</code>包，通过<code>sudo apt-get install *</code>命令进行安装</p></li><li><p>进入解压完的<code>opencv</code>文件夹，创建编译文件夹，<code>mkdir build</code>，依次执行<code>cd build</code>， <code>cmake ..</code>，<code>make</code>，<code>make install</code>。</p></li><li><p>配置OpenCV的编译环境，将OpenCV的库添加到路径，从而可以让系统找到，<code>sudo gedit /etc/ld.so.conf.d/opencv.conf</code>，在打开的文本中写入<code>/usr/local/lib</code>，执行<code>sudo ldconfig</code></p></li><li><p>配置bash，执行<code>sudo gedit /etc/bash.bashrc</code>，在文本最末尾添加：</p><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PKG_CONFIG_PATH=$<span class="symbol">PKG_CONFIG_PATH:</span>/usr/local/<span class="class"><span class="keyword">lib</span>/<span class="title">pkgconfig</span></span></span><br><span class="line">export PKG_CONFIG_PATH</span><br></pre></td></tr></table></figure><p>保存，执行<code>source /etc/bash.bashrc</code>，使得配置生效：更新<code>sudo updatedb</code> </p></li></ol><p>程序中使用<code>sprintf()</code>函数读入指定路径下的图片序列，用<code>imread()</code>函数读取当前图片，用<code>imshow()</code>函数显示当前图片。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sprintf</span>(filename, /<span class="built_in">home</span>/neko/slam-VO/<span class="number">00</span>/image_0/%<span class="number">06</span>d.png, numFrame);</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"Current frame number:"</span>&lt;&lt;numFrame &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">currImage = imread(filename);</span><br><span class="line"></span><br><span class="line">imshow( <span class="string">"CAMERA IMAGE"</span>, currImage);</span><br></pre></td></tr></table></figure><h2 id="2-提取特征点"><a href="#2-提取特征点" class="headerlink" title="2.提取特征点"></a>2.提取特征点</h2><p>视觉里程计的核心问题是如何根据图形估计相机运动，比较方便的做法是：首先从图像中选取比较有代表性的点，这些点在相机视角发生少量变化后会保持不变，于是能在各个图像中找到相同的点。然后在这些点的基础上讨论，讨论相机位姿估计问题，以及这些点的定位问题，这些点被称为图像特征。</p><p>在本次作业中我们提取<strong>FAST关键点</strong>，<strong>FAST</strong> 是一种角点，主要检测局部像素灰度变化明显的地方，以速度快著称。它的思想是：如果一个像素与它邻域的像素差别较大（过亮或过暗）, 那它更可能是角点。它的检测过程如下：</p><ol><li>在图像中选取像素<script type="math/tex">p</script>，假设它的亮度为$I_p$。</li><li>设置一个阈值$T$ (比如$I_p$的20%)。</li><li>以像素$p$为中心, 选取半径为3的圆上的16个像素点。</li><li>假如选取的圆上，有连续的$N$个点的亮度大于$I_p+T$ 或小于$I_p-T$，那么像素$p$可以被认为是特征点。</li><li>循环以上四步，对每一个像素执行相同的操作。</li></ol><p><img src="/2020/06/16/%E5%8D%95%E7%9B%AE%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1/2.png" style="zoom:80%;"></p><p>​                                                                                <strong>图2-1 FAST特征点</strong></p><p>OpenCV中默认采用Fast-9-16，即在周围取16个像素点，若超过连续9个点与中心点差值大于阈值即成为候选角点。为了更高效，可以进行预处理，检测圆周上第1.5.9.13个像素，当其中有三个及以上的符合阈值，才可以入围，若不符合，便可以直接排除。同时需要搜索局部极大值，抑制非极大值元素来避免角点集中的问题。</p><p>程序中通过<code>featureDetection()</code>函数来实现：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">featureDetection</span><span class="params">(Mat img_1, <span class="built_in">vector</span>&lt;Point2f&gt;&amp; points1)</span></span>&#123;   </span><br><span class="line">  <span class="built_in">vector</span>&lt;KeyPoint&gt; kps;</span><br><span class="line">  <span class="keyword">int</span> fast_threshold = <span class="number">10</span>;</span><br><span class="line">  Ptr&lt;FastFeatureDetector&gt; detector=FastFeatureDetector::create();</span><br><span class="line">  detector-&gt;detect(img_1,kps);</span><br><span class="line">  KeyPoint::convert(kps, points1, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="3-特征跟踪与估计相机运动"><a href="#3-特征跟踪与估计相机运动" class="headerlink" title="3.特征跟踪与估计相机运动"></a>3.特征跟踪与估计相机运动</h2><h3 id="3-1-光流法特征跟踪"><a href="#3-1-光流法特征跟踪" class="headerlink" title="3.1.光流法特征跟踪"></a>3.1.光流法特征跟踪</h3><p>使用<strong>光流（Optical Flow）</strong>来跟踪特征点的运动。这样可以回避计算和匹配描述子带来的时间。光流是一种描述像素随着时间，在图像之间运动的方法。随着时间的经过，同一个像素会在图像中运动。计算部分像素运动的称为稀疏光流，计算所有像素的称为稠密光流。稀疏光流以 Lucas-Kanade 光流为代表，并可以在 SLAM 中用于跟踪特征点位置。</p><p><img src="/2020/06/16/%E5%8D%95%E7%9B%AE%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1/QQ图片20200615202025.png" style="zoom:67%;"></p><p>​                                                                           图3-1 LK光流法示意图</p><p>在LK光流中，来自相机的图像是随时间变化的。图像可以看作时间的函数$I(t)$。那么，一个在$t$时刻，位于$(x,y)$处的像素，它的灰度可以写成$I(x,y,t)$。这种方式把图像看成了关于位置与时间的函数，它的值域就是图像中像素的灰度。</p><p>引入<strong>灰度不变假设</strong>：同一个空间点的像素灰度值，在各个图像中是固定不变的。对于t时刻位于$(x,y)$处的像素，设$t+dt$时刻，它运动到$(x + dx, y + dy)$处。由于灰度不变,有：</p><script type="math/tex; mode=display">I(x+dx,y+dy,t+dt)=I(x,y,t)</script><p>通过对左边进行泰勒展开，保留一阶项，两边同时除$dt$，并写成矩阵形式：</p><script type="math/tex; mode=display">\begin{bmatrix} I_x \quad I_y\end{bmatrix} \begin{bmatrix} u \\v \end{bmatrix}=-I_t</script><p>引入额外的约束来计算$u, \,\,v$，假设某一个窗口内的像素具有相同的运动，如一个大小为$w \times w$的窗口，它含有$w^2$数量的像素，因此共有$w^2$个方程：</p><script type="math/tex; mode=display">\begin{bmatrix} I_x \quad I_y\end{bmatrix}_k \begin{bmatrix} u \\v \end{bmatrix}=-I_{tk}, \quad k=1,\dots,w^2</script><p>这是一个关于$u,\,\, v$的超定线性方程，可以使用最小二乘法求解，这样就得到了像素在图像间的运动速度$u,\,\, v$。</p><p>如果相机运动较快，两张图像差异较明显，那么单层图像光流法容易达到一个局部极小值，这种情况可以通过引入图像金字塔来改善。图像金字塔是指对同一个图像进行缩放，得到不同分辨率下的图像。以原始的金字塔作为金字塔底层，每往上一层，就对下层图像进行一定倍率的缩放，就得到一个金字塔。然后在计算光流时，先从顶层的图像开始计算，然后把上一层的追踪结果，作为下一层光流的初始值。OpenCV中的<code>calcOpticalFlowPyrLK()</code>函数正是基于这一原理实现多层光流函数。</p><p>在程序中通过<code>featureTracking()</code>函数来实现特征跟踪：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">featureTracking</span><span class="params">(Mat img_1, Mat img_2, <span class="built_in">vector</span>&lt;Point2f&gt;&amp; points1, <span class="built_in">vector</span>&lt;Point2f&gt;&amp; points2, <span class="built_in">vector</span>&lt;uchar&gt;&amp; status)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">float</span>&gt;err;   </span><br><span class="line">    calcOpticalFlowPyrLK(img_1, img_2, points1, points2, status, err);  <span class="comment">//调用光流法跟踪特征点</span></span><br><span class="line">    <span class="keyword">int</span> indexCorrection = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>( <span class="keyword">int</span> i=<span class="number">0</span>; i&lt;status.<span class="built_in">size</span>(); i++)   <span class="comment">//删除跟踪失败的点</span></span><br><span class="line">    &#123;  </span><br><span class="line">        Point2f pt = points2.at(i- indexCorrection);</span><br><span class="line">     <span class="keyword">if</span> ((status.at(i) == <span class="number">0</span>)||(pt.x&lt;<span class="number">0</span>)||(pt.y&lt;<span class="number">0</span>))</span><br><span class="line">        &#123;</span><br><span class="line">       <span class="keyword">if</span>((pt.x&lt;<span class="number">0</span>)||(pt.y&lt;<span class="number">0</span>))</span><br><span class="line">               &#123;</span><br><span class="line">       status.at(i) = <span class="number">0</span>;</span><br><span class="line">       &#125;</span><br><span class="line">       points1.erase (points1.<span class="built_in">begin</span>() + (i - indexCorrection));</span><br><span class="line">       points2.erase (points2.<span class="built_in">begin</span>() + (i - indexCorrection));</span><br><span class="line">       indexCorrection++;</span><br><span class="line">     &#125;</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-2-对极几何估计相机运动"><a href="#3-2-对极几何估计相机运动" class="headerlink" title="3.2.对极几何估计相机运动"></a>3.2.对极几何估计相机运动</h3><p>接下来根据匹配的点对估计相机的运动。当相机为单目时，只知道2D的像素坐标，因而问题是根据两组2D点估计运动，可以用<strong>对极几何</strong>来解决。</p><p><img src="/2020/06/16/%E5%8D%95%E7%9B%AE%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1/QQ图片20200613125004.png" style="zoom: 80%;"></p><p>​                                                                               图3-2 对极几何约束</p><p>如下图所示，我们希望求取两帧图像$I_1$，$I_2$之间的运动，设第一帧到第二帧的运动为$R$，$t$。两个相机中心分别为$O_1$，$O_2$现在，考虑$I_1$ 中有一个特征点$p_1$，它在$I_2$中对应着特征点$p_2$。根据针孔相机模型，可得两个像素点的$p_1$，$p_2$的像素位置：</p><script type="math/tex; mode=display">s_1p_1=KP,\quad s_2p_2=K(RP+t)</script><p>其中$K$为相机内参，$R$，$t$为两个坐标系的相机运动。使用齐次坐标表示像素点，例如$s_1p_1$和$s_2p_2$成投影关系，它们在齐次坐标下的意义是相等的，称为尺度意义下相等。经推导得到对极约束的表达式：</p><script type="math/tex; mode=display">p_2^Tk^{-T}t^\land RK^{-1}p_1=0</script><p>把中间部分记作两个矩阵：<strong>基础矩阵</strong>（Fundamental Matrix）$F$ 和<strong>本质矩阵</strong>（Essential Matrix）$E$，可以进一步简化对极约束：</p><script type="math/tex; mode=display">E=t ^\land R, \quad F=K^{-T}EK^{-1},\quad x_2^TEx_1=p_2^TFp_1=0</script><p>对极约束简洁地给出了两个匹配点的空间位置关系，相机位姿估计问题变为以下两步：</p><ol><li>根据配对点的像素位置，求出$E$ 或者$F$；</li><li>根据$E$或者$F$，求出$R$，$t$。</li></ol><p>在程序中我们使用本质矩阵$E$求解，然后通过本质矩阵获取摄像机的相对旋转和平移量：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//计算本质矩阵并恢复R,t</span></span><br><span class="line">E = findEssentialMat(prevFeatures, currFeatures, focal_length, principal_point, RANSAC, <span class="number">0.999</span>, <span class="number">1.0</span>, mask);</span><br><span class="line">recoverPose(E, prevFeatures,currFeatures,  R, t, focal_length, principal_point, mask);</span><br></pre></td></tr></table></figure><h3 id="3-3-三角测量"><a href="#3-3-三角测量" class="headerlink" title="3.3.三角测量"></a>3.3.三角测量</h3><p>在单目SLAM 中，仅通过单张图像无法获得像素的深度信息，我们需要通过三角测量（Triangulation）（或三角化）的方法来估计地图点的深度。三角测量是指，通过在两处观察同一个点的夹角，确定该点的距离。在SLAM 中主要用三角化来估计像素点的距离。</p><p><img src="/2020/06/16/%E5%8D%95%E7%9B%AE%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1/图片1.png" style="zoom: 50%;"></p><p>​                                                          图3-2 通过三角测量的方法获得地图点的深度</p><p>论上直线$O_1p_1$ 与 $O_2p_2$在场景中会相交于一点$P$，该点即是两个特征点所对应的地图点在三维场景中的位置。然而由于噪声的影响，这两条直线往往无法相交。因此，可以通过最二小乘去求解。设$x_1$，$x_2$为两个特征点的归一化坐标，那么它们满足：</p><script type="math/tex; mode=display">s_2x_2=s_1Rx_1+t</script><p>如果要算$s_1$，那么先对上式两侧左乘一个$x_2^\land$，得：</p><script type="math/tex; mode=display">s_2x_2^\land x_2=0=s_1x_2 ^\land R x_1 +x_2 ^\land t</script><p>该式左侧为零，右侧可以看成是$s_2$的一个方程，根据它可求出$s_2$，进而能求出$s_1$。这样就得到了两帧下的深度，确定了它们的空间坐标。由于噪声的存在，估得的$R,t$不一定精确使上式为零，所以常用最小二乘法求解。</p><p>在程序中通过<code>triangulation()</code>函数实现三角测量：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">triangulation</span> <span class="params">( </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> <span class="built_in">vector</span>&lt; Point2f&gt;&amp; points_1, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> <span class="built_in">vector</span>&lt; Point2f&gt;&amp; points_2, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> Mat&amp; R, <span class="keyword">const</span> Mat&amp; t, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="built_in">vector</span>&lt; Point3f &gt;&amp; points)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">   Mat T1 = (Mat_&lt;<span class="keyword">float</span>&gt; (<span class="number">3</span>,<span class="number">4</span>) &lt;&lt;</span><br><span class="line">        <span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,</span><br><span class="line">        <span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,</span><br><span class="line">        <span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>);</span><br><span class="line">    Mat T2 = (Mat_&lt;<span class="keyword">float</span>&gt; (<span class="number">3</span>,<span class="number">4</span>) &lt;&lt;</span><br><span class="line">        R.at&lt;<span class="keyword">double</span>&gt;(<span class="number">0</span>,<span class="number">0</span>), R.at&lt;<span class="keyword">double</span>&gt;(<span class="number">0</span>,<span class="number">1</span>), R.at&lt;<span class="keyword">double</span>&gt;(<span class="number">0</span>,<span class="number">2</span>), t.at&lt;<span class="keyword">double</span>&gt;(<span class="number">0</span>,<span class="number">0</span>),</span><br><span class="line">        R.at&lt;<span class="keyword">double</span>&gt;(<span class="number">1</span>,<span class="number">0</span>), R.at&lt;<span class="keyword">double</span>&gt;(<span class="number">1</span>,<span class="number">1</span>), R.at&lt;<span class="keyword">double</span>&gt;(<span class="number">1</span>,<span class="number">2</span>), t.at&lt;<span class="keyword">double</span>&gt;(<span class="number">1</span>,<span class="number">0</span>),</span><br><span class="line">        R.at&lt;<span class="keyword">double</span>&gt;(<span class="number">2</span>,<span class="number">0</span>), R.at&lt;<span class="keyword">double</span>&gt;(<span class="number">2</span>,<span class="number">1</span>), R.at&lt;<span class="keyword">double</span>&gt;(<span class="number">2</span>,<span class="number">2</span>), t.at&lt;<span class="keyword">double</span>&gt;(<span class="number">2</span>,<span class="number">0</span>)</span><br><span class="line">    );</span><br><span class="line">    Mat K = ( Mat_&lt;<span class="keyword">double</span>&gt; ( <span class="number">3</span>,<span class="number">3</span> ) &lt;&lt; <span class="number">718.856</span>, <span class="number">0</span>, <span class="number">607.1928</span>, <span class="number">0</span>, <span class="number">718.856</span>, <span class="number">185.2157</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span> );</span><br><span class="line">    <span class="built_in">vector</span>&lt;Point2f&gt; pts_1, pts_2;</span><br><span class="line">    <span class="keyword">for</span> ( <span class="keyword">int</span> idex=<span class="number">0</span>;idex&lt;points_1.<span class="built_in">size</span>();idex++ )</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 将像素坐标转换至相机坐标</span></span><br><span class="line">        pts_1.push_back ( pixel2cam( points_1[idex], K) );</span><br><span class="line">        pts_2.push_back ( pixel2cam( points_2[idex], K) );</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Mat pts_4d;</span><br><span class="line">    cv::triangulatePoints( T1, T2, pts_1, pts_2, pts_4d );</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 转换成非齐次坐标</span></span><br><span class="line">    <span class="keyword">for</span> ( <span class="keyword">int</span> i=<span class="number">0</span>; i&lt;pts_4d.cols; i++ )</span><br><span class="line">    &#123;</span><br><span class="line">        Mat x = pts_4d.col(i);</span><br><span class="line">        x /= x.at&lt;<span class="keyword">float</span>&gt;(<span class="number">3</span>,<span class="number">0</span>); <span class="comment">// 归一化</span></span><br><span class="line">        <span class="function">Point3f <span class="title">p</span> <span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">            x.at&lt;<span class="keyword">float</span>&gt;(<span class="number">0</span>,<span class="number">0</span>), </span></span></span><br><span class="line"><span class="function"><span class="params">            x.at&lt;<span class="keyword">float</span>&gt;(<span class="number">1</span>,<span class="number">0</span>), </span></span></span><br><span class="line"><span class="function"><span class="params">            x.at&lt;<span class="keyword">float</span>&gt;(<span class="number">2</span>,<span class="number">0</span>) </span></span></span><br><span class="line"><span class="function"><span class="params">        )</span></span>;</span><br><span class="line">        points.push_back( p );</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="4-生成相机轨迹与Ground-Truth比较"><a href="#4-生成相机轨迹与Ground-Truth比较" class="headerlink" title="4.生成相机轨迹与Ground Truth比较"></a>4.生成相机轨迹与Ground Truth比较</h2><p>Ground Truth轨迹绘制，通过读取00.txt中的数据绘制，<code>slam-VO.h</code>文件中定义了<code>get_Pose()</code>函数，<code>slam-VO.cpp</code>中函数调用程序如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">float</span>&gt;&gt; poses = get_Pose(pose_path);</span><br><span class="line">Point2f trace1 = Point2f(<span class="keyword">int</span>(poses[numFrame][<span class="number">3</span>]) + <span class="number">400</span>, <span class="keyword">int</span>(poses[numFrame][<span class="number">11</span>]) + <span class="number">150</span>); <span class="comment">//绘制Ground Truth      </span></span><br><span class="line"><span class="built_in">circle</span>(trace, trace1, <span class="number">1</span>, Scalar(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>), <span class="number">1</span>);</span><br></pre></td></tr></table></figure><p>初步未优化得到的相机运动轨迹绘制，在三角测量得到特征点三维信息后，通过判断两帧间是否有一定程度的位移决定该次三角测量精度是否准确，若可以，则绘制当前位置点，程序如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//三角测量</span></span><br><span class="line">triangulation (prevFeatures,currFeatures,R,t,points);</span><br><span class="line"><span class="built_in">cout</span>&lt;&lt;<span class="string">"id&lt;points.size():"</span>&lt;&lt;points.<span class="built_in">size</span>()&lt;&lt;<span class="built_in">endl</span>;        </span><br><span class="line"><span class="keyword">for</span> ( <span class="keyword">int</span> id=<span class="number">0</span>; id&lt;points.<span class="built_in">size</span>(); id++ )&#123;</span><br><span class="line"> points1.push_back(prevFeatures[id]);</span><br><span class="line">     points2.push_back(currFeatures[id]);</span><br><span class="line">&#125; </span><br><span class="line">        </span><br><span class="line">scale = getAbsoluteScale(numFrame, <span class="number">0</span>, t.at&lt;<span class="keyword">double</span>&gt;(<span class="number">2</span>));<span class="comment">//平移的距离     </span></span><br><span class="line"><span class="keyword">if</span> ((scale&gt;<span class="number">0.1</span>)&amp;&amp;(-t.at&lt;<span class="keyword">double</span>&gt;(<span class="number">2</span>) &gt; -t.at&lt;<span class="keyword">double</span>&gt;(<span class="number">0</span>)) &amp;&amp; (-t.at&lt;<span class="keyword">double</span>&gt;(<span class="number">2</span>) &gt; -t.at&lt;<span class="keyword">double</span>&gt;(<span class="number">1</span>)))&#123;    <span class="comment">//确保有一定程度的平移而不是纯旋转以保证三角测量的精度 </span></span><br><span class="line"> t_f = t_f + scale*(R_f*(-t));</span><br><span class="line">     R_f = R.inv()*R_f;</span><br><span class="line">     <span class="keyword">pre_t</span>=t.clone();</span><br><span class="line">     <span class="keyword">int</span> x = <span class="keyword">int</span>(t_f.at&lt;<span class="keyword">double</span>&gt;(<span class="number">0</span>)) + <span class="number">400</span>;</span><br><span class="line">     <span class="keyword">int</span> y = <span class="keyword">int</span>(t_f.at&lt;<span class="keyword">double</span>&gt;(<span class="number">2</span>)) + <span class="number">150</span>; </span><br><span class="line">     Point2f trace2 = Point2f(x,y) ;     </span><br><span class="line">     <span class="built_in">circle</span>(trace, trace2 ,<span class="number">1</span>, Scalar(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>), <span class="number">1</span>);<span class="comment">//绘制初步估计的轨迹</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span>&#123;</span><br><span class="line">     <span class="built_in">cout</span> &lt;&lt; <span class="string">"scale below 0.1, or incorrect translation"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="5-Bundle-Adjustment优化"><a href="#5-Bundle-Adjustment优化" class="headerlink" title="5.Bundle Adjustment优化"></a>5.Bundle Adjustment优化</h2><p>PnP用于求解3D到2D运动的投影位置方法。可以通过线性方法先求解相机位姿再求解空间投影点，但存在的问题是线性解法鲁棒性不太好，并且需要建立线性方程求代数解较为困难。因此，当运动比较连续时，一般选择非线性优化方法来进行迭代求解最优解，通常采用基于最小二乘问题的<strong>Bundle Adjustment(BA, 捆集调整)方法</strong>。针对本文采用的单目相机数据集，必须先对其进行初始化，再使用BA算法。</p><p><img src="/2020/06/16/%E5%8D%95%E7%9B%AE%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1/图片1.png" style="zoom:50%;"></p><p>非线性优化将相机位姿、空间特征点等多个参数看作优化变量。如上图所示，根据之前的特征匹配，已知$p_1$、$p_2$为同一空间点的两个投影点，利用最小化重投影误差对相机位姿进行优化，使计算得到的$p_2’$与实际$p_2$不断接近，直到达到精度范围或最大迭代次数。设相机位姿变换为$R$，$t$，对应李代数为$\xi$。相机内参矩阵为$K$。任一三维空间点P的坐标$ \pmb{P}_i=[X_i,Y_i,Z_i]^T$。对应的投影像素坐标为$\pmb{u}_i=[u_i,v_i]^T$。则像素点与空间点存在如下关系：</p><script type="math/tex; mode=display">s_i\begin{bmatrix}u_i\\v_i\\1 \end{bmatrix}=\pmb{K}(\exp(\pmb{\xi}^\land)\begin{bmatrix}X_i\\Y_i\\Z_i\\1 \end{bmatrix})_{1:3}</script><p>即：</p><script type="math/tex; mode=display">s_i\pmb{u}_i=\pmb{K}(\exp(\pmb{\xi}^\land)\pmb{P}_i)_{1:3}</script><p>因此，以相机位姿李代数$\xi$、特征点空间位置等为优化变量，以重投影误差为目标函数，计算将像素坐标观测值与按相机位姿计算得到的像素坐标计算值之间的误差，构建最小二乘问题，利用Gauss-Newton法或Levenburg-Marquadt优化算法寻找最优相机位姿和特征点空间坐标。优化模型如下所示：</p><script type="math/tex; mode=display">\xi^*=\arg \min\limits_{\xi}\frac{1}{2}\sum^n_{i=1}\Arrowvert u_i-\frac{1}{s_i}K\exp (\xi^\land)P_i\Arrowvert_2^2</script><p>在利用优化算法进行迭代的时候，最重要的是计算每次迭代的下降梯度方向，对目标函数误差求导可得：</p><script type="math/tex; mode=display">e(x+\Delta x)\approx e(x)+J\Delta x</script><p>其中，$J$为$2 \times 6$的雅各比矩阵。通过扰动模型求解李代数导数，计算过程如下：由上文已知像素点与空间点的关系，设$\pmb{P}’$为空间点$\pmb{P}$经相机位姿变换后的空间坐标，即$\pmb{P}’=(\exp(\pmb{\xi}^\land)\pmb{P})_{1:3}=[X’,Y’,Z’]^T$。将相机内参$K$展开得：</p><script type="math/tex; mode=display">\begin{bmatrix}su\\ sv \\s \end{bmatrix}=\begin{bmatrix}f_x &0 &c_x\\ 0 &f_y &c_y\\0 & 0 &1 \end{bmatrix} \begin{bmatrix} X' \\ Y' \\Z' \end{bmatrix}</script><p>消元可得：</p><script type="math/tex; mode=display">u=f_x\frac{X'}{Z'}+c_x, \quad v=f_y\frac{Y'}{Z'}+c_y</script><p>将相机位姿李代数左乘扰动量$\delta \pmb{\xi}$，再通过误差变化对扰动量的求导可得：</p><script type="math/tex; mode=display">\frac{\partial e}{\partial \delta \pmb{\xi}}=\lim \limits_{\delta \pmb{\xi}\to0}\frac{\delta \pmb{\xi}\bigoplus \pmb{\xi}}{\delta \pmb{\xi}}=\frac{\partial e}{\partial \pmb{P}'}\frac{\partial \pmb{P}'}{\partial\delta \pmb{\xi}}</script><p>误差变化$e$对于$\pmb{P}’$的求导可以根据之前消元得到的$u$、$v$表达式得到：</p><script type="math/tex; mode=display">\frac{\partial e}{\partial \pmb{P}'}= -\begin{bmatrix} \displaystyle\frac{\partial u}{\partial {X}'} & \displaystyle\frac{\partial u}{\partial {Y}'} & \displaystyle\frac{\partial u}{\partial {Z}'}  \\  \displaystyle\frac{\partial v}{\partial {X}'} & \displaystyle\frac{\partial v}{\partial {Y}'} & \displaystyle\frac{\partial v}{\partial {Z}'} \end{bmatrix} =- \begin{bmatrix} \displaystyle\frac{f_x}{Z'} & 0 & -\displaystyle\frac{f_x X'}{Z'^2}  \\  0 & \displaystyle\frac{f_y}{Z'} & -\displaystyle\frac{f_y Y'}{Z'^2} \end{bmatrix}</script><p>$\pmb{P}’$对扰动量$\delta \pmb{\xi}$求导为：</p><script type="math/tex; mode=display">\frac{\partial \pmb{P}'}{\partial\delta \pmb{\xi}}=[\pmb{I},\,\,-\pmb{P}'^ \land]</script><p>于是最终得到相机位姿导数的雅各比矩阵：</p><script type="math/tex; mode=display">\frac{\partial e}{\partial \delta \pmb{\xi}}=-\begin{bmatrix} \displaystyle\frac{f_x}{Z'} & 0 & -\displaystyle\frac{f_x X'}{Z'^2} & -\displaystyle\frac{f_x X' Y'}{Z'^2} &f_x+\displaystyle\frac{f_x X'}{Z'^2} &-\displaystyle\frac{f_x Y'}{Z'} \\ 0 & \displaystyle\frac{f_y}{Z'} & -\displaystyle\frac{f_y Y'}{Z'^2} &-f_y-\displaystyle\frac{f_y Y'}{Z'^2} & -\displaystyle\frac{f_y X' Y'}{Z'^2} &-\displaystyle\frac{f_y X'}{Z'}\end{bmatrix}</script><p>同理，对于特征点空间位置的优化，还需要将误差$e$对空间点$\pmb{P}$进行求导，可以得到如下计算模型：</p><script type="math/tex; mode=display">\frac{\partial e}{\partial \pmb{P}}=\frac{\partial e}{\partial \pmb{P}'}\frac{\partial \pmb{P}'}{\partial\delta \pmb{P}}</script><script type="math/tex; mode=display">\pmb{P}'=\exp(\pmb{\xi}^\land)\pmb{P}=\pmb{RP}+\pmb{t}</script><script type="math/tex; mode=display">\frac{\partial e}{\partial \delta \pmb{\xi}}=-- \begin{bmatrix} \displaystyle\frac{f_x}{Z'} & 0 & -\displaystyle\frac{f_x X'}{Z'^2}  \\  0 & \displaystyle\frac{f_y}{Z'} & -\displaystyle\frac{f_y Y'}{Z'^2} \end{bmatrix}\pmb{R}</script><p>基于以上推导，采用<code>g2o</code>库实现相机位姿图优化，部分代码如下图所示。图优化时以下一个相机位姿和所有特征点空间坐标为节点，以下一个相机中的投影坐标为边。以<code>RANSAC PnP</code>结果为初值，调用<code>g2o</code>进行优化。</p><p><code>slam-VO.h</code>文件中定义 <code>Bundle Adjustment()</code>函数程序如下：函数输入前一帧的三维信息和后一帧的两维信息，以及相机内参矩阵，则可得到优化后的相机变化位姿矩阵。函数定义中，首先初始化<code>g2o</code>，定义优化求解器，定义图优化的边和节点，定义误差函数等。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bundleAdjustment</span> <span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="built_in">vector</span>&lt; Point3f &gt; points_3d,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="built_in">vector</span>&lt; Point2f &gt; points_2d,</span></span></span><br><span class="line"><span class="function"><span class="params">    Mat K,</span></span></span><br><span class="line"><span class="function"><span class="params">    Mat R, Mat t,</span></span></span><br><span class="line"><span class="function"><span class="params">    Mat&amp; RR, Mat&amp; tt )</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 初始化g2o</span></span><br><span class="line">    <span class="keyword">typedef</span> g2o::BlockSolver&lt; g2o::BlockSolverTraits&lt;<span class="number">6</span>,<span class="number">3</span>&gt; &gt; Block; </span><br><span class="line">    <span class="comment">// pose 维度为 6, landmark 维度为 3</span></span><br><span class="line">    Block::LinearSolverType* linearSolver = <span class="keyword">new</span> g2o::LinearSolverCSparse&lt;Block::PoseMatrixType&gt;(); <span class="comment">// 线性方程求解器</span></span><br><span class="line">    Block* solver_ptr  = <span class="keyword">new</span> Block (linearSolver);    <span class="comment">// 矩阵块求解器</span></span><br><span class="line">    </span><br><span class="line">    g2o::OptimizationAlgorithmLevenberg* solver = <span class="keyword">new</span> g2o::OptimizationAlgorithmLevenberg (solver_ptr);</span><br><span class="line">    g2o::SparseOptimizer optimizer;</span><br><span class="line">    optimizer.setAlgorithm ( solver );</span><br><span class="line"></span><br><span class="line">    <span class="comment">// vertex</span></span><br><span class="line">    g2o::VertexSE3Expmap* pose = <span class="keyword">new</span> g2o::VertexSE3Expmap(); <span class="comment">// camera pose</span></span><br><span class="line">    Eigen::Matrix3d R_mat;</span><br><span class="line">    R_mat &lt;&lt;</span><br><span class="line">               R.at&lt;<span class="keyword">double</span>&gt; ( <span class="number">0</span>,<span class="number">0</span> ), R.at&lt;<span class="keyword">double</span>&gt; ( <span class="number">0</span>,<span class="number">1</span> ), R.at&lt;<span class="keyword">double</span>&gt; ( <span class="number">0</span>,<span class="number">2</span> ),</span><br><span class="line">               R.at&lt;<span class="keyword">double</span>&gt; ( <span class="number">1</span>,<span class="number">0</span> ), R.at&lt;<span class="keyword">double</span>&gt; ( <span class="number">1</span>,<span class="number">1</span> ), R.at&lt;<span class="keyword">double</span>&gt; ( <span class="number">1</span>,<span class="number">2</span> ),</span><br><span class="line">               R.at&lt;<span class="keyword">double</span>&gt; ( <span class="number">2</span>,<span class="number">0</span> ), R.at&lt;<span class="keyword">double</span>&gt; ( <span class="number">2</span>,<span class="number">1</span> ), R.at&lt;<span class="keyword">double</span>&gt; ( <span class="number">2</span>,<span class="number">2</span> );</span><br><span class="line">    pose-&gt;setId ( <span class="number">0</span> );</span><br><span class="line">    pose-&gt;setEstimate ( g2o::SE3Quat (R_mat,Eigen::Vector3d ( t.at&lt;<span class="keyword">double</span>&gt; ( <span class="number">0</span>,<span class="number">0</span> ), t.at&lt;<span class="keyword">double</span>&gt; ( <span class="number">1</span>,<span class="number">0</span> ), t.at&lt;<span class="keyword">double</span>&gt; ( <span class="number">2</span>,<span class="number">0</span> ) ) ) );</span><br><span class="line">    optimizer.addVertex ( pose );</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> index = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> ( <span class="keyword">const</span> Point3f p:points_3d )   <span class="comment">// landmarks</span></span><br><span class="line">    &#123;</span><br><span class="line">        g2o::VertexSBAPointXYZ* <span class="built_in">point</span> = <span class="keyword">new</span> g2o::VertexSBAPointXYZ();</span><br><span class="line">        <span class="built_in">point</span>-&gt;setId ( index++ );</span><br><span class="line">        <span class="built_in">point</span>-&gt;setEstimate ( Eigen::Vector3d ( p.x, p.y, p.z ) );</span><br><span class="line">        <span class="built_in">point</span>-&gt;setMarginalized ( <span class="literal">true</span> ); </span><br><span class="line">        optimizer.addVertex ( <span class="built_in">point</span> );</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// parameter: camera intrinsics</span></span><br><span class="line">    g2o::CameraParameters* camera = <span class="keyword">new</span> g2o::CameraParameters ( K.at&lt;<span class="keyword">double</span>&gt; ( <span class="number">0</span>,<span class="number">0</span> ), Eigen::Vector2d ( K.at&lt;<span class="keyword">double</span>&gt; ( <span class="number">0</span>,<span class="number">2</span> ), K.at&lt;<span class="keyword">double</span>&gt; ( <span class="number">1</span>,<span class="number">2</span> ) ), <span class="number">0</span> );</span><br><span class="line">    camera-&gt;setId ( <span class="number">0</span> );</span><br><span class="line">    optimizer.<span class="built_in">addParameter</span> ( camera );</span><br><span class="line"></span><br><span class="line">    <span class="comment">// edges</span></span><br><span class="line">    index = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> ( <span class="keyword">const</span> Point2f p:points_2d )</span><br><span class="line">    &#123;</span><br><span class="line">        g2o::EdgeProjectXYZ2UV* edge = <span class="keyword">new</span> g2o::EdgeProjectXYZ2UV();</span><br><span class="line">        edge-&gt;setId ( index );</span><br><span class="line">        edge-&gt;setVertex ( <span class="number">0</span>, <span class="keyword">dynamic_cast</span>&lt;g2o::VertexSBAPointXYZ*&gt; ( optimizer.vertex ( index ) ) );</span><br><span class="line">        edge-&gt;setVertex ( <span class="number">1</span>, pose );</span><br><span class="line">        edge-&gt;setMeasurement ( Eigen::Vector2d ( p.x, p.y ) );</span><br><span class="line">        edge-&gt;setParameterId ( <span class="number">0</span>,<span class="number">0</span> );</span><br><span class="line">        edge-&gt;setInformation ( Eigen::Matrix2d::Identity() );</span><br><span class="line">edge-&gt;setRobustKernel( <span class="keyword">new</span> g2o::RobustKernelHuber() );</span><br><span class="line">        optimizer.addEdge ( edge );</span><br><span class="line">        index++;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    optimizer.setVerbose ( <span class="literal">false</span> );</span><br><span class="line">    optimizer.initializeOptimization();</span><br><span class="line">    optimizer.optimize ( <span class="number">5</span>);</span><br><span class="line">    </span><br><span class="line">    Eigen::Isometry3d T = Eigen::Isometry3d ( pose-&gt;estimate() );</span><br><span class="line">    <span class="comment">//RR、t为优化后的R和t</span></span><br><span class="line">    RR=(Mat_&lt;<span class="keyword">double</span>&gt;(<span class="number">3</span>,<span class="number">3</span>)&lt;&lt;</span><br><span class="line">    T(<span class="number">0</span>,<span class="number">0</span>),T(<span class="number">0</span>,<span class="number">1</span>),T(<span class="number">0</span>,<span class="number">2</span>),</span><br><span class="line">    T(<span class="number">1</span>,<span class="number">0</span>),T(<span class="number">1</span>,<span class="number">1</span>),T(<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">    T(<span class="number">2</span>,<span class="number">0</span>),T(<span class="number">2</span>,<span class="number">1</span>),T(<span class="number">2</span>,<span class="number">2</span>));</span><br><span class="line"></span><br><span class="line">    tt=(Mat_&lt;<span class="keyword">double</span>&gt;(<span class="number">3</span>,<span class="number">1</span>)&lt;&lt;</span><br><span class="line">    T(<span class="number">0</span>,<span class="number">3</span>),T(<span class="number">1</span>,<span class="number">3</span>),T(<span class="number">2</span>,<span class="number">3</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>slam-VO.cpp</code>文件中调用该函数程序如下：输入前后两帧的三维特征信息、相机内参、相机变换位姿，可以返回 优化后的位资矩阵。同样，需要判断两帧间平移是否到达一定程度，否则需要进行尺度修正。然后将每次循环得到的轨迹进行实时绘制。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//BA优化</span></span><br><span class="line">bundleAdjustment ( points,points2, K,R,t, RR,tt );</span><br><span class="line"><span class="keyword">if</span> ((scale&gt;<span class="number">0.1</span>)&amp;&amp;(-tt.at&lt;<span class="keyword">double</span>&gt;(<span class="number">2</span>) &gt; -tt.at&lt;<span class="keyword">double</span>&gt;(<span class="number">0</span>)) &amp;&amp; (-tt.at&lt;<span class="keyword">double</span>&gt;(<span class="number">2</span>) &gt; -tt.at&lt;<span class="keyword">double</span>&gt;(<span class="number">1</span>)))</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span>(<span class="built_in">abs</span>(tt.at&lt;<span class="keyword">double</span>&gt;(<span class="number">2</span>)-t.at&lt;<span class="keyword">double</span>&gt;(<span class="number">2</span>))&lt;<span class="number">0.05</span>)</span><br><span class="line">    &#123;</span><br><span class="line"> t_E = t_E + scale*(R_E*(-tt));</span><br><span class="line">       R_E = RR.inv()*R_E;</span><br><span class="line">         <span class="keyword">pre_t</span>=tt.clone();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">         <span class="built_in">cout</span>&lt;&lt;<span class="string">"优化失败"</span>&lt;&lt;<span class="built_in">endl</span>;                        </span><br><span class="line"> t_E = t_E + scale*(R_E*(-t));</span><br><span class="line">         R_E = R.inv()*R_E;</span><br><span class="line">         <span class="keyword">pre_t</span>=t.clone();</span><br><span class="line">&#125;            </span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line">     <span class="built_in">cout</span> &lt;&lt; <span class="string">"scale below 0.1, or incorrect translation"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line">Point2f trace3 = Point2f(<span class="keyword">int</span>(t_E.at&lt;<span class="keyword">double</span>&gt;(<span class="number">0</span>)) + <span class="number">400</span>, <span class="keyword">int</span>(t_E.at&lt;<span class="keyword">double</span>&gt;(<span class="number">2</span>)) + <span class="number">150</span>);</span><br><span class="line"><span class="built_in">circle</span>(trace, trace3, <span class="number">1</span>, Scalar(<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>), <span class="number">1</span>);<span class="comment">//绘制BA优化后的轨迹</span></span><br></pre></td></tr></table></figure><p>得到的BA优化轨迹如图中红色轨迹所示，右上角可以看出，累积误差较大的时候，BA优化的轨迹展示出了更好的性能。由于这里只考虑相邻两帧之间的优化，因此随着累积误差的增大，对极约束估计以及BA优化得到的轨迹效果都越来越差，需要通过局部地图以及后端的回环检测等方法来优化。</p><p><img src="/2020/06/16/%E5%8D%95%E7%9B%AE%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1/微信图片_20200616071621.png" style="zoom: 67%;"></p>]]></content>
    
    <summary type="html">
    
      整理了一下这学期机器视觉课程的大作业。视觉里程计(Visual Odometry，VO)是一种利用连续的图像序列来估计相机或机器人移动距离的方法，要求基于OpenCV初步实现一个简单的视觉里程计，我主要参考了高翔的《视觉slam十四讲》来完成。
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>数据结构与算法（20）串</title>
    <link href="http://nekomoon404.github.io/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/"/>
    <id>http://nekomoon404.github.io/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/</id>
    <published>2020-04-04T01:24:46.000Z</published>
    <updated>2020-04-05T01:24:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>串或字符串属于线性结构，自然地可以直接利用向量或列表等序列结构加以实现。但字符串作为一种数据结构，特点极其鲜明，作为字符串基本组成元素的字符，种类通常不多，甚至可能极少。因此，为了高效地处理以字符串形式表示的海量数据，需要设计专门的处理方法。</p><p>本章直接利用C++所提供的字符数组，将重点几种在串匹配算法的设计、实现与优化。在此类应用中，更多地是以某一局部子串为单位，考查其对应的模式（pattern），因此也称作循模式访问（call-by-pattern）。</p><h1 id="1-串及串匹配"><a href="#1-串及串匹配" class="headerlink" title="1.串及串匹配"></a>1.串及串匹配</h1><h2 id="1-1-串"><a href="#1-1-串" class="headerlink" title="1.1.串"></a>1.1.串</h2><p><strong>字符串</strong>：</p><p>由来自字母表$\sum$的字符所组成的有限序列，$S=”a_0\,a_1\,a_2\dots\,a_{n-1}”$，其中$a_i\in \sum, 0 \le i &lt; n$。这里的$\sum$是所有可用字符的集合，称作<strong>字符表（alphabet）</strong>。字符串S所含的字符的总数n，称作S的长度，记作$|S|=n$，长度为0的串称作<strong>空串（null string）</strong>。通常，字符的种类不多，而串长$=n&gt;&gt;|\sum|$。</p><p><strong>子串：</strong></p><p>字符串中任一连续的片段，称作其子串（substring）。对于任意的$0\le i \le i+k &lt;n$，由字符串S中起始于位置i的连续k个字符组成的子串记作：<code>S.substr(i, k) = S[i, i+k)</code>。</p><p>起始于位置0，长度为k的子串称为<strong>前缀（prefix）</strong>：<code>S.prefix(k) = S.substr(0,k) = S[0,k)</code>。</p><p>终止于位置n-1、长度为k的子串称为<strong>后缀（suffix）</strong>：<code>S.suffix(k) = S.substr(n-k,k) = S[n-k,n)</code>。</p><p>空串是任何字符串的子串，也是任何字符串的前缀和后缀；任何字符串都是自己的子串，也是自己的前缀和后缀。此类子串。前缀和后缀分别称作<strong>平凡子串（trivial substring）</strong>、<strong>平凡前缀（trivial prefix）</strong>和<strong>平凡后缀（trivial suffix）</strong>。反之，字符串本身之外的所以非空子串。前缀和后缀，分别称作<strong>真子串（proper substring）</strong>、<strong>真前缀（proper prefix）</strong>和<strong>真后缀（proper suffix）</strong>。</p><p><strong>判等：</strong></p><p>字符串<code>S[0,n)</code>和<code>T[0,m)</code>称作相等，当且仅当二者长度相等（n=m），且对应字符分别相同。</p><p><strong>ADT：</strong></p><p>串结构主要的操作接口可归纳为下表：</p><div class="table-container"><table><thead><tr><th>操作接口</th><th>功能</th></tr></thead><tbody><tr><td><code>length()</code></td><td>查询串的长度</td></tr><tr><td><code>charAt(i)</code></td><td>返回第<code>i</code>个字符</td></tr><tr><td><code>substr(i,k)</code></td><td>返回从第<code>i</code>个字符起，长度为<code>k</code>的子串</td></tr><tr><td><code>prefix(k)</code></td><td>返回长度为<code>k</code>的前缀</td></tr><tr><td><code>suffix(k)</code></td><td>返回长度为<code>k</code>的后缀</td></tr><tr><td><code>equal(T)</code></td><td>判断T是否与当前字符串相等</td></tr><tr><td><code>concat(T)</code></td><td>将T串接在当前字符串之后</td></tr><tr><td><code>indexOf(P)</code></td><td>若P是当前字符串的一个子串，则返回该子串的起始位置；否则返回-1</td></tr></tbody></table></div><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200404102415.png" style="zoom: 50%;"></p><p>下面是一些实例：</p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200404102536.png" style="zoom:50%;"></p><h2 id="1-2-串匹配"><a href="#1-2-串匹配" class="headerlink" title="1.2.串匹配"></a>1.2.串匹配</h2><p>在涉及字符串的众多实际应用中，<strong>模式匹配</strong>是最常使用的一项基本操作。如在生物信息处理领域需要在蛋白质序列中寻找特定的氨基酸模式，或在DNA序列中寻找特定的碱基模式。再如邮件过滤器也需要根据事先定义的特征串，通过扫描电子邮件的地址、标题及正文来识别垃圾邮件等等。</p><p>上述所有应用问题，本质上都可转化和描述为如下形式：如何在字符串数据中，检测和提取以字符串形式给出的某一局部特征。这类操作都属于<strong>串模式匹配（string pattern matching）</strong>范畴，简称<strong>串匹配</strong>。一般地，即：</p><ul><li>对基于同一字符表的任何文本串T（|T| = n）和模式串P（|P| = m），判定T中是否存在某一子串与P相同，若存在（匹配），则报告该子串在T中的起始位置。</li></ul><p>串的长度n和m本身通常都很多，但相对而言n更大，即满足$2 \ll m \ll n$。</p><p>根据具体应用的要求不同，串匹配问题有多种形式：</p><ul><li><strong>模式检测（pattern detection）</strong>问题：只关心是否存在匹配而不关心具体的匹配位置，如垃圾邮件的检测；</li><li><strong>模式定位（pattern location）</strong>问题：若经判断的确存在匹配，则还需确定具体的匹配位置；</li><li><strong>模式计数（pattern counting）</strong>问题：若有多处匹配，则统计出匹配子串的总数；</li><li><strong>模式枚举（pattern enumeration）</strong>问题：在有多处匹配时，报告出所有匹配的具体位置。</li></ul><p>鉴于串结构自身的特点，在设计和分析串模式匹配算法时也必须做特殊的考虑，一个重要的问题是：如何对任一串匹配算法的性能作出客观的测量和评估。不幸的是评估算法性能的常规口径和策略并不适用于这一问题，因为若假设文本串T和模式串P都是随机生成的，那么计算得到的匹配成功的概率往往极低。</p><p>实际上，<strong>有效涵盖成功匹配情况的一种简便策略是，随机选取文本串T，并从T中随机取出长度为m的子串作为模式串P</strong>，这即是文本将采用的评价标准。</p><h1 id="2-蛮力算法"><a href="#2-蛮力算法" class="headerlink" title="2.蛮力算法"></a>2.蛮力算法</h1><p>蛮力串匹配是最直接的方法，不妨按自左向右的次序考查子串，逐个字符对比。如下图，模式串P的每一黑色方格对应于字符的一次匹配，每一灰色方格对应于一次失败，白色方格对应于未进行的一次对比。若经过检查，当前的m对字符均匹配，则意味着整体匹配成功，从而返回匹配子串的位置。</p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200404113720.png" style="zoom: 50%;"></p><p>蛮力算法的正确性显而易见，既然只有在某一轮的m次比对全部成功之后才成功返回，故不致于误报；反过来，所有对齐位置都会逐一尝试，故亦不致漏报。</p><p>下面是蛮力算法的两个实现版本，二者原理相同、过程相仿，但分别便于引入后续的不同改进算法，故在此先做一比较。</p><p>版本一：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/************************************************************************************</span></span><br><span class="line"><span class="comment"> * Text     :  0   1   2   .   .   .   i-j .   .   .   .   i   .   .   n-1</span></span><br><span class="line"><span class="comment"> *             ------------------------|-------------------|------------</span></span><br><span class="line"><span class="comment"> * Pattern  :                          0   .   .   .   .   j   .   .</span></span><br><span class="line"><span class="comment"> *                                     |-------------------|</span></span><br><span class="line"><span class="comment"> ***********************************************************************************/</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">match</span> <span class="params">( <span class="keyword">char</span>* P, <span class="keyword">char</span>* T )</span> </span>&#123; <span class="comment">//串匹配算法（Brute-force-1）</span></span><br><span class="line">   <span class="keyword">size_t</span> n = <span class="built_in">strlen</span> ( T ), i = <span class="number">0</span>; <span class="comment">//文本串长度、当前接受比对字符的位置</span></span><br><span class="line">   <span class="keyword">size_t</span> m = <span class="built_in">strlen</span> ( P ), j = <span class="number">0</span>; <span class="comment">//模式串长度、当前接受比对字符的位置</span></span><br><span class="line">   <span class="keyword">while</span> ( j &lt; m &amp;&amp; i &lt; n ) <span class="comment">//自左向右逐个比对字符</span></span><br><span class="line">      <span class="comment">/*DSA*/</span>&#123;</span><br><span class="line">      <span class="comment">/*DSA*/</span>showProgress ( T, P, i - j, j );   getchar();</span><br><span class="line">      <span class="keyword">if</span> ( T[i] == P[j] ) <span class="comment">//若匹配</span></span><br><span class="line">         &#123; i ++;  j ++; &#125; <span class="comment">//则转到下一对字符</span></span><br><span class="line">      <span class="keyword">else</span> <span class="comment">//否则</span></span><br><span class="line">         &#123; i -= j - <span class="number">1</span>; j = <span class="number">0</span>; &#125; <span class="comment">//文本串回退、模式串复位</span></span><br><span class="line">      <span class="comment">/*DSA*/</span>&#125;</span><br><span class="line">   <span class="keyword">return</span> i - j; <span class="comment">//如何通过返回值，判断匹配结果？i-j&lt;=n-m就表示成功，反之失败</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>版本二：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/************************************************************************************</span></span><br><span class="line"><span class="comment"> * Text     :  0   1   2   .   .   .   i   i+1 .   .   .   i+j .   .   n-1</span></span><br><span class="line"><span class="comment"> *             ------------------------|-------------------|------------</span></span><br><span class="line"><span class="comment"> * Pattern  :                          0   1   .   .   .   j   .   .</span></span><br><span class="line"><span class="comment"> *                                     |-------------------|</span></span><br><span class="line"><span class="comment"> ***********************************************************************************/</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">match</span> <span class="params">( <span class="keyword">char</span>* P, <span class="keyword">char</span>* T )</span> </span>&#123; <span class="comment">//串匹配算法（Brute-force-2）</span></span><br><span class="line">   <span class="keyword">size_t</span> n = <span class="built_in">strlen</span> ( T ), i = <span class="number">0</span>; <span class="comment">//文本串长度、与模式串首字符的对齐位置</span></span><br><span class="line">   <span class="keyword">size_t</span> m = <span class="built_in">strlen</span> ( P ), j; <span class="comment">//模式串长度、当前接受比对字符的位置</span></span><br><span class="line">   <span class="keyword">for</span> ( i = <span class="number">0</span>; i &lt; n - m + <span class="number">1</span>; i++ ) &#123; <span class="comment">//文本串从第i个字符起，与</span></span><br><span class="line">      <span class="keyword">for</span> ( j = <span class="number">0</span>; j &lt; m; j++ ) <span class="comment">//模式串中对应的字符逐个比对</span></span><br><span class="line">         <span class="comment">/*DSA*/</span>&#123;showProgress ( T, P, i, j ); getchar();</span><br><span class="line">         <span class="keyword">if</span> ( T[i + j] != P[j] ) <span class="keyword">break</span>; <span class="comment">//若失配，模式串整体右移一个字符，再做一轮比对</span></span><br><span class="line">         <span class="comment">/*DSA*/</span>&#125;</span><br><span class="line">      <span class="keyword">if</span> ( j &gt;= m ) <span class="keyword">break</span>; <span class="comment">//找到匹配子串</span></span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">return</span> i; <span class="comment">//如何通过返回值，判断匹配结果？i&lt;=n-m就表示成功，反之失败</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>时间复杂度：</strong></p><p>从理论上讲，蛮力算法至多迭代n-m+1轮，且各轮至多需要进行m次比对，故总共只需做不超过$(n-m+1)\cdot m$次比对，其中成功的和失败的各有$(m-1)\cdot (n-m+1)+1$和$n-m-2$次。因$m\ll n$，渐进的时间复杂度应为$O(n\cdot m)$。</p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200404115556.png" style="zoom: 45%;"></p><p>蛮力算法的效率也并非总是如此低下，如上右图，若将模式串P左右颠倒，则每经一次比对都可排除文本串中的一个字符，故此类情况下的运行时间将为$O(n)$。实际上，此类最好（或接近最好）情况出现的概率并不很低，尤其是在字符表较大时。</p><h1 id="3-KMP算法"><a href="#3-KMP算法" class="headerlink" title="3.KMP算法"></a>3.KMP算法</h1><h2 id="3-1-构思"><a href="#3-1-构思" class="headerlink" title="3.1.构思"></a>3.1.构思</h2><p>蛮力算法在最坏情况下所需时间，为文本串长度与模式长度的乘积，故无法应用于规模稍大的应用环境，很有必要改进。为此，不妨从最坏情况入手，最坏情况在于这里存在大量的局部匹配：每一轮的m次比对中，仅最后一次可能失配，而一旦发现失配，文本串、模式串的字符指针都要回退，并从头开始下一轮尝试。实际上，这列重复的字符比对操作没有必要。既然这些字符在前一轮迭代中已经接受过比对并且成功，我们也就掌握了它们的所有信息。接下来就要考虑如何利用这些信息，提高匹配算法的效率。</p><p>如下图，用<code>T[i]</code>和<code>P[j]</code>分别表示当前正在接受比对的一对字符。当本轮比对进行到最后一对字符并发现失配后，蛮力算法令两个字符指针同步回退（即令<code>i = i - j + 1</code>和<code>j = 0</code>），然后再从这一位置继续比对，然而事实上，指针<code>i</code>完全不必回退。</p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200404194755.png" style="zoom: 50%;"></p><p>因为经过前一次的比对，我们已经知道子串<code>T[i-j,i)</code>完全由<code>&#39;0&#39;</code>组成，便可预测出：在回退之后紧接着的下一轮对比中，前<code>j-1</code>次比对必然都会成功。因此可直接令<code>i</code>保持不变，令<code>j=j-1</code>，然后继续比对。如此下一轮只需1次比对，共减少<code>j-1</code>次。这个操作可以理解为：令<code>P</code>相对于<code>T</code>右移一个单元，然后从前一失配位置继续比对。实际上这一技巧可以推广：利用以往的成功比对所提供的信息（记忆），不仅可避免文本串字符指针的回退，而且可使模式串尽可能大跨度地右移（经验）。下面是一个更一般的例子：</p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200404195403.png" style="zoom:50%;"></p><h2 id="3-2-next表"><a href="#3-2-next表" class="headerlink" title="3.2.next表"></a>3.2.next表</h2><p>一般地，假设前一轮比对终止于<code>T[i]</code> $\ne$ <code>P[j]</code>，按以上构思，指针<code>i</code>不必回退，而是将<code>T[i]</code>与<code>P[t]</code>对齐并开始下一轮对比。接下来考虑<code>t</code>的值应该取作多少。</p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200404195703.png" style="zoom: 50%;"></p><p>如上图，经过此前一轮的对比，已经确定匹配的范围应为：<code>P[o,j) = T[i-j,i)</code>。</p><p>于是，若模式串P经适当右移之后，能够与T的某一（包含<code>T[i]</code>在内的）子串完全匹配，则一项必要条件就是：<code>P[0,t) = T[i-t,i) = P[j-t,j)</code>，亦即，在<code>P[0,j)</code>中长度为<code>t</code>的真前缀，应与长度为<code>t</code>的真后缀完全匹配，故<code>t</code>必来自集合：</p><script type="math/tex; mode=display">N(P,j)=\{0\le t \le j \,\,\,|\,\,\,P[0,t)=P[j-t,j)\}</script><p>一般地，该集合可能包含多个这样的<code>t</code>，而需要注意的是，<code>t</code>的值仅取决于模式串<code>P</code>以及前一轮比对的首个失配位置<code>P[j]</code>，而与文本串<code>T</code>无关。若下一轮比对将从<code>T[i]</code>与<code>P[t]</code>的比对开始，这等效于将<code>P</code>右移<code>j-t</code>个单元，位移量与<code>t</code>成反比。因此为保证<code>P</code>与<code>T</code>的对齐位置（指针<code>i</code>）绝不倒退，同时又不致遗漏任何可能的匹配，应在集合<code>N(P,j)</code>中挑选最大的<code>t</code>，即当有多个右移方案时，应该保守地选择其中移动距离最短者。</p><p>于是令：<code>next[j] = max( N(P,j) )</code>，则一旦发现P[i]与T[i]失配，即可转而将<code>P[ next[i] ]</code>与<code>T[i]</code>彼此对准，并从这一位置开始继续下一轮比对。</p><p>既然集合<code>N(P,j)</code>仅取决于模式串<code>P</code>以及失配位置<code>j</code>，而与文本串无关，作为其中的最大元素，<code>next[j]</code>也必然具有这一性质。对于任一模式串<code>P</code>，不妨通过预处理提前计算出所有位置<code>j</code>所对应的<code>next[j]</code>值，并整理为表格以表此后反复查询。</p><h2 id="3-3-KMP算法"><a href="#3-3-KMP算法" class="headerlink" title="3.3.KMP算法"></a>3.3.KMP算法</h2><p>上述思路可整理为如下代码，即著名的<strong>KMP算法</strong>。对照此前的蛮力算法，只是在<code>else</code>分支对失配情况的处理手法有所不同，这也是KMP算法的精髓所在。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">match</span> <span class="params">( <span class="keyword">char</span>* P, <span class="keyword">char</span>* T )</span> </span>&#123;  <span class="comment">//KMP算法</span></span><br><span class="line">   <span class="keyword">int</span>* next = buildNext ( P ); <span class="comment">//构造next表</span></span><br><span class="line">   <span class="keyword">int</span> n = ( <span class="keyword">int</span> ) <span class="built_in">strlen</span> ( T ), i = <span class="number">0</span>; <span class="comment">//文本串指针</span></span><br><span class="line">   <span class="keyword">int</span> m = ( <span class="keyword">int</span> ) <span class="built_in">strlen</span> ( P ), j = <span class="number">0</span>; <span class="comment">//模式串指针</span></span><br><span class="line">   <span class="keyword">while</span> ( j &lt; m  &amp;&amp; i &lt; n ) <span class="comment">//自左向右逐个比对字符</span></span><br><span class="line">      <span class="comment">//*DSA*/ &#123;</span></span><br><span class="line">      <span class="comment">//*DSA*/ showProgress ( T, P, i - j, j );</span></span><br><span class="line">      <span class="comment">//*DSA*/ printNext ( next, i - j, strlen ( P ) );</span></span><br><span class="line">      <span class="comment">//*DSA*/ getchar(); printf ( "\n" ); */</span></span><br><span class="line">      <span class="keyword">if</span> ( <span class="number">0</span> &gt; j || T[i] == P[j] ) <span class="comment">//若匹配，或P已移出最左侧（两个判断的次序不可交换）</span></span><br><span class="line">         &#123; i ++;  j ++; &#125; <span class="comment">//则转到下一字符</span></span><br><span class="line">      <span class="keyword">else</span> <span class="comment">//否则</span></span><br><span class="line">         j = next[j]; <span class="comment">//模式串右移（注意：文本串不用回退）</span></span><br><span class="line">      <span class="comment">//*DSA*/ &#125;</span></span><br><span class="line">   <span class="keyword">delete</span> [] next; <span class="comment">//释放next表</span></span><br><span class="line">   <span class="keyword">return</span> i - j;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>next[0] = -1</strong></p><p>只要<code>j&gt;0</code>，则必有$0\in N(P,j)$。此时<code>N(P,j)</code>非空，从而可以保证“ 在其中取最大值 ”这一操作的确可行。但反过来，若<code>j=0</code>，则即便集合<code>N(P,j)</code>可以定义，也必是空集。反观串匹配的过程，若在某一轮比对中首对字符即失配，则应将<code>P</code>直接右移一个字符，然后启动下一轮比对。如下表，不妨假想地在<code>P[0]</code>的左侧“ 附加 ”一个<code>P[-1]</code>，且该字符与任何字符都是匹配的，就实际效果而言，这一处理方法完全等同于“ 令<code>next[0] = -1</code> ”。</p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200404202952.png" style="zoom: 40%;"></p><p><strong>next[j+1]</strong></p><p>若已知<code>next[0,j]</code>，如何才能递推地计算出<code>next[j+1]</code>？若<code>next[j]=t</code>，则意味着在<code>P[0,j]</code>中，自匹配的真前缀和真后缀的最大长度为<code>t</code>，故必有<code>next[j=1]</code> $\le$ <code>next[j]+1</code>，当且仅当<code>P[j]=P[t]</code>时，取等号。如下图：</p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200404203402.png" style="zoom: 50%;"></p><p>一般地，若<code>P[j]</code> $\ne$ <code>P[t]</code>，由<code>next</code>表的功能定义，<code>next[j+1]</code>的下一候选者应该依次是：</p><p><code>next[ next[j] ] + 1</code>，<code>next[ next[ next[j] ] ] + 1</code>，……</p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200404203727.png" style="zoom: 40%;"></p><p>因此只需反复用<code>next[t]</code>替换<code>t</code>（即令<code>t = next[t]</code>），即可按优先次序遍历以上候选者；一旦发现<code>P[j]</code>与<code>P[t]</code>匹配（含与<code>P[t=-1]</code>的通配），即可令<code>next[j+1] = next[t] + 1</code>。</p><p>既然总有<code>next[t] &lt; t</code>，故在此过程中<code>t</code>必然严格递减；同时，即便<code>t</code>降低至<code>0</code>，亦必然会终止于通配的<code>next[0] = -1</code>，而不致下溢，如此该算法的正确性完全可以保证。</p><p><strong>构造next表：</strong></p><p>按照以上思路，可实现<code>next</code>表构造算法如下。<code>next</code>表的构造算法与KMP算法几乎完全一致，实际上按照以上分析，这一构造过程完全等效于串的自我匹配，因此两个算法在形式上的近似亦不足为怪。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span>* <span class="title">buildNext</span> <span class="params">( <span class="keyword">char</span>* P )</span> </span>&#123; <span class="comment">//构造模式串P的next表</span></span><br><span class="line">   <span class="keyword">size_t</span> m = <span class="built_in">strlen</span> ( P ), j = <span class="number">0</span>; <span class="comment">//“主”串指针</span></span><br><span class="line">   <span class="keyword">int</span>* N = <span class="keyword">new</span> <span class="keyword">int</span>[m]; <span class="comment">//next表</span></span><br><span class="line">   <span class="keyword">int</span> t = N[<span class="number">0</span>] = <span class="number">-1</span>; <span class="comment">//模式串指针</span></span><br><span class="line">   <span class="keyword">while</span> ( j &lt; m - <span class="number">1</span> )</span><br><span class="line">      <span class="keyword">if</span> ( <span class="number">0</span> &gt; t || P[j] == P[t] ) &#123; <span class="comment">//匹配</span></span><br><span class="line">         j ++; t ++;</span><br><span class="line">         N[j] = t; <span class="comment">//此句可改进...</span></span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="comment">//失配</span></span><br><span class="line">         t = N[t];</span><br><span class="line">   <span class="comment">//*DSA*/printString ( P ); printf ( "\n" );</span></span><br><span class="line">   <span class="comment">//*DSA*/printNext ( N, 0, m );</span></span><br><span class="line">   <span class="keyword">return</span> N;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>性能分析：</strong></p><p>由上可见，KMP算法借助<code>next</code>表可避免大量不必要的字符比对操作，但这意味着渐渐意义上的时间复杂度会有实质改进嘛？</p><p>为此的证明需要一些技巧，若令<code>k = 2i - j</code>，并考查<code>k</code>在KMP算法过程中的变化趋势，则不难发现，<code>while</code>循环每迭代一轮，<code>k</code>都会严格递增。对于<code>while</code>循环内部的<code>if - else</code>分支，无非两种情况：若转入<code>if</code>分支，则<code>i</code>和<code>j</code>同时加一，于是<code>k = 2i -j</code>必将增加；反之若转入<code>else</code>分支，则尽管<code>i</code>保持不变，但在赋值<code>j = next[j]</code> 之后<code>j</code>必然减少，于是<code>k = 2i -j</code>也必然增加。</p><p>纵观算法的整个过程：启动时有<code>i =j =0</code>，即<code>k =0</code>；算法结束时$i\le n$或$j \ge 0$，故有$k\le 2n$。在此期间尽管整数k从0开始持续地严格递增，但累计增幅不超过$2n$，故<code>while</code>循环至多执行$2n$轮。另外，<code>while</code>循环体内部不含任何循环或调用，故只需$O(1)$时间，因此若不计构造<code>next</code>表所需的时间，KMP算法本身的运行时间不超过$O(n)$。也就是说，尽管可能有$\Omega(n)$个对齐位置，但就分摊意义而言，在每一对齐位置仅需$O(1)$次对比。</p><p>既然<code>next</code>表构造算法的流程与KMP算法并无实质区别，故仿照上述分析可知，<code>next</code>表的构造仅需$O(m)$时间，综上，<strong>KMP算法的总体运行时间为$O(n+m)$</strong>。</p><h2 id="3-4-改进"><a href="#3-4-改进" class="headerlink" title="3.4.改进"></a>3.4.改进</h2><p>尽管以上KMP算法已可保证线性的运行时间，但在某些情况下仍有进一步改进的余地。如下面的例子，按照此前定义的<code>next</code>表，仍会进行多次本不必要的字符比对操作。前一轮对比因<code>T[i] = &#39;1&#39;</code> $\ne$ <code>&#39;0&#39; = P[3]</code>失配而中断，接下来KMP算法将依次将<code>P[2]</code>、<code>P[1]</code>和<code>P[0]</code>与<code>T[i]</code>对准并做比对。</p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200404211810.png" style="zoom:50%;"></p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200404211822.png" style="zoom:50%;"></p><p>不难发现原因出在 <code>P[3] = P[2] =P[1] = &#39;0&#39;</code>，而此前比对已发现<code>T[i]</code> $\ne$ <code>P[3]</code>，那么继续将<code>T[i]</code>和那些与<code>P[3]</code>相同的字符做比对，就是徒劳无功的。</p><p>就算法策略而言，引入<code>next</code>表的实质作用在于帮助我们利用以往成功比对所提供的“ 经验 ”，而实际上，此前已进行过的比对还远远不止这些，确切地说还包括那些失败的比对——作为“ 教训 ”。为把这类“ 负面 ”信息引入<code>next</code>表，只需将集合$N(P,j)$的定义修改为：</p><script type="math/tex; mode=display">N(P,j)=\{0\le t < j\,\,\,|\,\,\,P[0,t)=P[j-t,j)且P[t] \ne P[j]\}</script><p>也就是说，除“ 对应于自匹配长度 ”以外，t只要还同时满足“ 当前字符对不匹配 ” 的必要条件，方能归入集合$N(P,j)$并作为<code>next</code>表项的候选。</p><p>相应地，原<code>next</code>表构造算法也需稍作修改如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span>* <span class="title">buildNext</span> <span class="params">( <span class="keyword">char</span>* P )</span> </span>&#123; <span class="comment">//构造模式串P的next表（改进版本）</span></span><br><span class="line">   <span class="keyword">size_t</span> m = <span class="built_in">strlen</span> ( P ), j = <span class="number">0</span>; <span class="comment">//“主”串指针</span></span><br><span class="line">   <span class="keyword">int</span>* N = <span class="keyword">new</span> <span class="keyword">int</span>[m]; <span class="comment">//next表</span></span><br><span class="line">   <span class="keyword">int</span> t = N[<span class="number">0</span>] = <span class="number">-1</span>; <span class="comment">//模式串指针</span></span><br><span class="line">   <span class="keyword">while</span> ( j &lt; m - <span class="number">1</span> )</span><br><span class="line">      <span class="keyword">if</span> ( <span class="number">0</span> &gt; t || P[j] == P[t] ) &#123; <span class="comment">//匹配</span></span><br><span class="line">         N[j] = ( P[++j] != P[++t] ? t : N[t] ); <span class="comment">//注意此句与未改进之前的区别</span></span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="comment">//失配</span></span><br><span class="line">         t = N[t];</span><br><span class="line">   <span class="comment">/*DSA*/</span>printString ( P ); <span class="built_in">printf</span> ( <span class="string">"\n"</span> );</span><br><span class="line">   <span class="comment">/*DSA*/</span>printNext ( N, <span class="number">0</span>, <span class="built_in">strlen</span> ( P ) );</span><br><span class="line">   <span class="keyword">return</span> N;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>改进后的算法与原算法的唯一区别在于，每次在<code>P[0,j)</code>中发现长度为t的真前缀和真后缀相互匹配之后，还需进一步检查<code>P[j]</code>是否等于<code>P[t]</code>。唯有在<code>P[j]</code> $\ne $ <code>P[t]</code>时，才能将<code>t</code>赋予<code>next[j]</code>；否则需转而代之以<code>next[t]</code>，改进后<code>next</code>表的构造算法同样只需$O(m)$时间。</p><p>将改进后的KMP算法应用于前面的例子，在首轮比对因<code>T[i] = &#39;1&#39;</code> $\ne$ <code>&#39;0&#39; = P[3]</code>失配而中断之后，将随机以<code>P[ next[3] ] = P[-1]</code>与<code>T[i]</code>对齐，并进行下一轮比对。这样就等同于聪明且安全地跳过了三个不必要的对齐位置。</p><h1 id="4-BM算法"><a href="#4-BM算法" class="headerlink" title="4.BM算法"></a>4.BM算法</h1><h2 id="4-1-构思"><a href="#4-1-构思" class="headerlink" title="4.1.构思"></a>4.1.构思</h2><p>KMP算法的思路可概括为：当前比对一旦失配，即利用此前的比对所提供的信息，尽可能长距离地移动模式串。其精妙之处在于，无需显式地反复保存或更新比对的历史，而是独立于具体的文本串，事先根据模式串预测出所有可能出现的失配情况，并将这些信息记录于<code>next</code>表中。</p><p>回顾之前的知识不难发现：串匹配 = x次失败的对齐 + 0/1次成功的对齐，这样与其说要加速匹配，不如说是<strong>要加速失败——尽快排除失败的对齐</strong>。就单个对齐的位置的排除而言：平均仅需常数次比对（只要$|\sum|$不致太小，单次比对成功概率足够低），且具体的比对位置及次序无所谓。然后就排除更多后续对齐位置而言，不同的对比位置及次序，作用差异极大。通常是越靠前的位置，作用越小；越靠后的位置，作用越大。</p><p>BM算法与KMP算法类似，二者的区别仅在于预测和利用“ 历史 ”信息的具体策略与方法。BM算法中，模式串P与文本串T的对准位置依然<strong>“ 自左向右 ”推移</strong>，而在每一对准位置确实<strong>“ 自右向左 ”地逐一比对</strong>各字符。具体地，在每一轮自右向左的比对过程中，一旦发现失配，则将P右移一定距离并再次与T对准，然后重新一轮自右向左的扫描比对。</p><p>BM算法的主题框架，可实现为如下代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//////////////////////////////////////////////////////////////////////////</span></span><br><span class="line"><span class="comment">// Boyer-Moore算法</span></span><br><span class="line"><span class="comment">//////////////////////////////////////////////////////////////////////////</span></span><br><span class="line"><span class="function"><span class="keyword">void</span>     <span class="title">ShowProgress</span> <span class="params">( <span class="keyword">String</span>, <span class="keyword">String</span>,  <span class="keyword">int</span>,  <span class="keyword">int</span> )</span></span>;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span>  CARD_CHAR_SET     256   <span class="comment">//Cardinality of charactor set</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span>*     <span class="title">BuildBC</span> <span class="params">( <span class="keyword">String</span> )</span></span>; <span class="comment">//构造Bad Charactor Shift表</span></span><br><span class="line"><span class="function"><span class="keyword">int</span>*     <span class="title">suffixes</span> <span class="params">( <span class="keyword">String</span> )</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span>*     <span class="title">BuildGS</span> <span class="params">( <span class="keyword">String</span> )</span></span>; <span class="comment">//构造Good Suffix Shift表</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">match</span> <span class="params">( <span class="keyword">char</span>* P, <span class="keyword">char</span>* T )</span> </span>&#123; <span class="comment">//Boyer-Morre算法（完全版，兼顾Bad Character与Good Suffix）</span></span><br><span class="line">   <span class="keyword">int</span>* bc = buildBC ( P ); <span class="keyword">int</span>* gs = buildGS ( P ); <span class="comment">//构造BC表和GS表</span></span><br><span class="line">   <span class="keyword">size_t</span> i = <span class="number">0</span>; <span class="comment">//模式串相对于文本串的起始位置（初始时与文本串左对齐）</span></span><br><span class="line">   <span class="keyword">while</span> ( <span class="built_in">strlen</span> ( T ) &gt;= i + <span class="built_in">strlen</span> ( P ) ) &#123; <span class="comment">//不断右移（距离可能不止一个字符）模式串</span></span><br><span class="line">      <span class="keyword">int</span> j = <span class="built_in">strlen</span> ( P ) - <span class="number">1</span>; <span class="comment">//从模式串最末尾的字符开始</span></span><br><span class="line">      <span class="keyword">while</span> ( P[j] == T[i + j] ) <span class="comment">//自右向左比对</span></span><br><span class="line">         <span class="keyword">if</span> ( <span class="number">0</span> &gt; --j ) <span class="keyword">break</span>; <span class="comment">/*DSA*/</span>showProgress ( T, P, i, j ); <span class="built_in">printf</span> ( <span class="string">"\n"</span> ); getchar();</span><br><span class="line">      <span class="keyword">if</span> ( <span class="number">0</span> &gt; j ) <span class="comment">//若极大匹配后缀 == 整个模式串（说明已经完全匹配）</span></span><br><span class="line">         <span class="keyword">break</span>; <span class="comment">//返回匹配位置</span></span><br><span class="line">      <span class="keyword">else</span> <span class="comment">//否则，适当地移动模式串</span></span><br><span class="line">         i += __max ( gs[j], j - bc[ T[i + j] ] ); <span class="comment">//位移量根据BC表和GS表选择大者</span></span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">delete</span> [] gs; <span class="keyword">delete</span> [] bc; <span class="comment">//销毁GS表和BC表</span></span><br><span class="line">   <span class="keyword">return</span> i;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里采用了蛮力算法后一版本的方式，借助整数<code>i</code>和<code>j</code>指示文本串中当前的对齐位置<code>T[i]</code>和模式串中接受比对的字符<code>P[j]</code>。一旦局部失配，采用两种启发式策略确定最大的安全移动距离，为此需要经过预处理，根据模式串<code>P</code>整理出坏字符和好后缀两类信息。与KMP算法一样，算法过程中指针<code>i</code>始终单调递增；相应地，<code>P</code>相对于<code>T</code>的位置也绝不回退。</p><h2 id="4-2-坏字符策略"><a href="#4-2-坏字符策略" class="headerlink" title="4.2.坏字符策略"></a>4.2.坏字符策略</h2><p>如下图中(a)和(b)，若模式串<code>P</code>当前在文本串<code>T</code>中的对齐位置为<code>i</code>，且在这一轮自右向左将<code>P</code>与<code>substr(T,i,m)</code>的比对过程中，在<code>P[j]</code>处首次发现失配：<code>T[i+j] = &#39;X&#39;</code> $\ne$ <code>&#39;Y&#39; = P[j]</code>，则将<code>&#39;X&#39;</code>称作<strong>坏字符（bad character）</strong>。接下来考虑应该选择<code>P</code>中哪个字符对准<code>T[i+j]</code>。</p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200405174258.png" style="zoom: 40%;"></p><p>若<code>P</code>与<code>T</code>的某一（包括<code>T[i+j]</code>在内的）子串匹配，则必然在<code>T[i+j] = &#39;X&#39;</code>处匹配；反之，若与<code>T[i+j]</code>对准的字符不是<code>&#39;X&#39;</code>，则必然失配。故如图(c)，只需找出<code>P</code>中的每一字符<code>&#39;X&#39;</code>，分别于<code>T[i+j] = &#39;X&#39;</code>对准，并执行一轮自右向左的扫描比对。</p><p>若<code>P</code>中包含多个<code>&#39;X&#39;</code>，其实并没有必要逐一尝试，逐一对比并无法确保文本串指针<code>i</code>永不回退。一种简便而高效的做法是：仅尝试<code>P</code>中最靠右的字符<code>&#39;X&#39;</code>（若存在）。如此便可在确保不致遗漏匹配的前提下，始终单向地滑动模式串，如上图(c)若<code>P</code>中最靠右的字符<code>&#39;X&#39;</code>为<code>P[k] = &#39;X&#39;</code>，则<code>P</code>的右移量即为<code>j-k</code>。</p><p><strong>bc[ ]表：</strong></p><p>对于任一给定的模式串<code>P</code>，<code>k</code>值只取决于字符<code>T[i+j] = &#39;X&#39;</code>，因此可将其视作从字符表到整数（<code>P</code>中字符的秩）的一个函数：</p><script type="math/tex; mode=display">bc(c)=\begin{cases}k,\quad &若P[k]=c，且对所有的i>k都有P[i] \ne c\\-1,\quad &若P[\,\,\,]中不含字符c\end{cases}</script><p>故如当前对齐位置为<code>i</code>，则一旦出现坏字符<code>P[j] = &#39;Y&#39;</code>，即重新对齐与：<code>i += j - bc[ T[i+j] ]</code>，并启动下一轮比对。为此可预先将函数<code>bc()</code>整理为一份查询表，称作<strong>BC表</strong>。</p><p>接下来考虑<strong>BC</strong>表中可能出现的两种<strong>特殊情况</strong>：若<code>P</code>根本就不含坏字符<code>&#39;X&#39;</code>，如上图(d)，则模式串整体移过失配位置<code>T[i+j]</code>，用<code>P[0]</code>对准<code>T[i+j+1]</code>，再启动下一轮比对，此类字符在<strong>BC</strong>表的对应项置为-1，其效果也等同于在模式串的最左端，增添一个通配符。若<code>P</code>中含有坏字符<code>&#39;X&#39;</code>，但其中最靠右者的位置也可能太靠右，以至于<code>j-k &lt; 0</code>，相当于左移模式串。显然这是不必要的——匹配算法能进行到此，则此前左侧的所有位置已被显式或隐式地否定排除了，因此只需将P串右移一个单位，然后启动下一轮自右向左的比对。</p><p>以由大写字母和空格组成的字符表为例，与模式串”DATA STRUCTURES”相对应的BC表如下所示：</p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200405182700.png" style="zoom: 40%;"></p><p>按照以上思路，BC表的构造算法可实现如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//***********************************************************************************</span></span><br><span class="line"><span class="comment">//    0                       bc['X']                                m-1</span></span><br><span class="line"><span class="comment">//    |                       |                                      |</span></span><br><span class="line"><span class="comment">//    ........................X***************************************</span></span><br><span class="line"><span class="comment">//                            .|&lt;------------- 'X' free ------------&gt;|</span></span><br><span class="line"><span class="comment">//***********************************************************************************</span></span><br><span class="line"><span class="function"><span class="keyword">int</span>* <span class="title">buildBC</span> <span class="params">( <span class="keyword">char</span>* P )</span> </span>&#123; <span class="comment">//构造Bad Charactor Shift表：O(m + 256)</span></span><br><span class="line">   <span class="keyword">int</span>* bc = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">256</span>]; <span class="comment">//BC表，与字符表等长</span></span><br><span class="line">   <span class="keyword">for</span> ( <span class="keyword">size_t</span> j = <span class="number">0</span>; j &lt; <span class="number">256</span>; j ++ ) bc[j] = <span class="number">-1</span>; <span class="comment">//初始化：首先假设所有字符均未在P中出现</span></span><br><span class="line">   <span class="keyword">for</span> ( <span class="keyword">size_t</span> m = <span class="built_in">strlen</span> ( P ), j = <span class="number">0</span>; j &lt; m; j ++ ) <span class="comment">//自左向右扫描模式串P</span></span><br><span class="line">      bc[ P[j] ] = j; <span class="comment">//将字符P[j]的BC项更新为j（单调递增）——画家算法</span></span><br><span class="line">   <span class="comment">/*DSA*/</span>printBC ( bc );</span><br><span class="line">   <span class="keyword">return</span> bc;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如上的算法在对BC初始化之后，对模式串<code>P</code>做一遍线性扫描，并不断用当前字符的秩更新BC表中的对应项。因为是按秩递增的次序从左到右扫描，故只要字符<code>c</code>在<code>P</code>中出现过，则最终的<code>bc[c]</code>必会记录下其中最靠右者的秩，这类算法也因此被称作<strong>“ 画家算法 ”（painter’s algorithm）</strong>。</p><p>算法的运行时间可以分为两部分，分别消耗于其中的两个循环：前者是对字符表$\sum$中的每个字符分别做初始化，时间量不超过$O(|\sum|)$；后一循环对模式串P做一轮扫描，其中每个字符消耗$O(1)$时间，需要$O(m)$时间。因此<strong>BC表构造消耗时间为$O(|\sum|+m)$</strong>。</p><p>下面是一个运用BM_BC算法的<strong>实例</strong>：</p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200405184110.png" style="zoom:50%;"></p><p>整个过程总共做过6次成功的比对（黑色字符）和4次失败的比对（白色字符），累计10次，文本串的每个有效字符平均为10/11不足一次。</p><p><strong>复杂度：</strong></p><p>BM算法本身进行串模式匹配所需的时间与具体的输入十分相关，将文本串和模式串的长度分别记为n和m，则在通常情况下的实际运行时间往往低于$O(n)$。在最好情况下，每经过常数次比对，就可以将模式串右移m个字符（即整体右移），如下图中的一类情况（对应蛮力算法中的最坏情况），只需$n/m$次比对算法即可终止，故最好情况下BM算法只需$O(n/m)$时间。</p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200405184826.png" style="zoom:45%;"></p><p>如将模式串P左右颠倒，则对应着最坏的一类情况，在每一轮比对中，P总要完整地扫描一遍才发现失配并向右移动一个字符，运行时间需要$O(n \times m)$。</p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200405211653.png" style="zoom: 80%;"></p><h2 id="4-3-好后缀策略"><a href="#4-3-好后缀策略" class="headerlink" title="4.3.好后缀策略"></a>4.3.好后缀策略</h2><p>参照KMP算法的改进思路不难发现，坏字符策略仅利用了此前（最后一次）失败比对所提供的“ 教训 ”。而实际上在此之前，还做过一系列成功的比对，但这些“ 经验 ”却被忽略了。如上图，每当在<code>P[0] =&#39;1&#39;</code> $\ne$ <code>&#39;0&#39;</code> 处失配，自然地想到应该将其替换成字符<code>&#39;0&#39;</code>。但既然本轮比对过程中已有大量字符<code>&#39;0&#39;</code>的成功匹配，则无论将<code>P[0]</code>对准其中的任何一个都注定会失配。故此时更应明智地将<code>P</code>整体移过这段区间，直接以<code>P[0]</code><strong>对准<code>T</code>中尚未接受比对的首个字符</strong>，如此算法的运行时间将有望降回至$O(n)$。</p><p><strong>好后缀：</strong></p><p>每轮比对中的若干次（连续的）成功匹配，都对应于模式串P的一个后缀，称作<strong>“ 好后缀 ”（good suffix）</strong>，若要改进BM算法，必须利用好后缀提供的“ 经验 ”。一般地，如下图的(a)和(b)所示，设本轮自右向左的扫描终止于失配位置：<code>T[i+j] = &#39;X&#39;</code> $\ne$ <code>&#39;Y&#39; = P[j]</code>。若分别记：</p><ul><li><code>W = substr(T, i+j+1, m-j-1) = T[i+j+1, m+i)</code></li><li><code>U = suffix(P, m-j-1) = P[j+1, m)</code></li></ul><p>好后缀<code>U</code>长度为<code>m-j-1</code>，故只要<code>j &lt;= m-2</code>，则<code>U</code>必非空，且有<code>U = W</code>。接下来就应考虑：根据好后缀所提供的信息应如何确定，<code>P</code>中有哪个（哪些）字符值得与上一失配字符<code>T[i+j]</code>对齐，然后启动下一轮比对呢？</p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200405213530.png" style="zoom: 45%;"></p><p>如上图(c)设存在一整数<code>k</code>，使得在将<code>P</code>右移<code>j - k</code>个单元，并使<code>P[k]</code>与<code>T[i+j]</code>相互对齐之后，<code>P</code>能够与文本串<code>T</code>的某一（包含<code>T[m+i-1]</code>在内的）子串匹配，亦即：<code>P = substr(T, i+j-k, m) = T[i+k-k, m+i+j-k)</code>。</p><p>于是，若记：<code>V(k) = substr(P, k+1, m-j-1) = P[k+1, m-j+k)</code>，则必然有：<code>V(k) = W = U</code>，也就是说，若值得将P[k]与T[i+j]对齐并做新的一轮比对，则P的子串V(k)首先必须与P自己的后缀U相互匹配。</p><p>还有另一必要条件：<code>P</code>中的这两自匹配子串的前驱字符不得相等，即<code>P[k] != P[j]</code>，否则在对齐位置也注定不会出现与<code>P</code>的整体匹配。若模式串<code>P</code>中同时存在多个满足上述必要条件的子串<code>V(k)</code>，则不妨选取其中最靠右者（对应于最大的<code>k</code>，最小的右移距离<code>j-k</code>），这两点都与KMP算法的处理类似。</p><p><strong>gs[ ]表：</strong></p><p>如上图(c)若满足上述必要条件的子串<code>V(k)</code>起始于<code>P[k+1]</code>，则模式串对应的右移量就是<code>j-k</code>。而<code>k</code>本身仅取决于模式串<code>P</code>以及<code>j</code>值，因此又可仿照KMP算法通过预处理将模式串<code>P</code>转换为另一张查找表<code>gs[0, m)</code>，其中<code>gs[j] = j-k</code>分别记录对应的位移量。</p><p>若P中没有任何子串<code>V(k)</code>可与好后缀<code>U</code>完全匹配，则需要从<code>P</code>的所有前缀中，找出可与<code>U</code>的某一（真）后缀相匹配的最长者，作为<code>V(k)</code>，并取<code>gs[j] = m - |V(k)|</code>。如下例是模式串<code>P = “ICED RICE PRICE”</code>对应的GS表，<code>gs[5] = 12</code> 就意味着：一旦在<code>P[5] = &#39;R&#39;</code>处发生失配，则应将模式串<code>P</code>整体右移12个字符，然后继续启动下一轮比对，也可以等效地认为，以<code>P[5-12] = P[-7]</code>对准文本串中失配的字符，或以<code>P[0]</code>对准文本串中尚未对准过的最左侧字符。</p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200405215841.png" style="zoom: 40%;"></p><p>下面是一个运行好后缀策略进行串匹配的<strong>实例</strong>：</p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200405220307.png" style="zoom: 50%;"></p><p>整个过程中总共做10次成功的比对（黑色字符）和2次失败的比对（灰色字符），累计12次比对，文本串的每个字符，平均（12/13）不足一次。</p><p><strong>复杂度：</strong></p><p>同时结合BC表和GS表两种启发策略，加快模式串相对于文本串的右移速度，可以证明对于匹配失败的情况，总体比对的次数不致超过$O(n)$。若不排除完全匹配的可能，则该算法在最坏情况下的效率，有可能退化至与蛮力算法相当，所幸只要做些简单的改进，依然能够保证总体的比对次数不超过线性。综上<strong>在兼顾了坏字符与好后缀两种策略之后，BM算法的运行时间为$O(n+m)$</strong>。</p><h2 id="4-4-gs-表构造算法："><a href="#4-4-gs-表构造算法：" class="headerlink" title="4.4.gs[ ]表构造算法："></a>4.4.gs[ ]表构造算法：</h2><p><strong>蛮力算法：</strong></p><p>一个很直接的方法就是：对于每个好后缀<code>P(j, m)</code>，按照自后向前（<code>k</code>从<code>j-1</code>递减至0）的次序，将其与<code>P</code>的每个子串<code>P(k ,m+k-j)</code>逐一对齐，并核对是否出现有匹配的子串，一旦发现，对应的位移量即是<code>gs[j]</code>的取值。然而这里共有$O(m)$个好后缀，各需与$O(m)$个子串对齐，每次对齐后在最坏情况下需要比对$O(m)$次，因此该“算法”可能需要$O(m^3)$的时间。</p><p><strong>MS[ ]串与ss[ ]表：</strong></p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200405222044.png" style="zoom: 45%;"></p><p>实际上构造<code>gs[ ]</code>表仅需线性的时间，为此需要引入<code>ss[ ]</code>表。如上图，对于任一整数<code>j</code> $\in$ <code>[0, m)</code>，在<code>P[0, j)</code>的所有后缀中，考查那些与<code>P</code>的某一后缀匹配者。若将其中的最长者记作<code>MS[j]</code>，则<code>ss[j]</code>就是该串的长度<code>|MS[j]|</code>。当<code>MS[j]</code>不存在时，取<code>ss[j] = 0</code>。综上可定义<code>ss[j]</code>为：</p><script type="math/tex; mode=display">ss[j]=\max \{ 0\le s \le j+1\,\,\,|\,\,\,P(j-s,j]=P[m-s,m) \}</script><p>特别地，当<code>j =m-1</code>时，必有<code>s = m</code>——此时，有<code>P(-1, m-1] = P[0, m)</code>。如下例是模式串<code>P = &quot;ICED RICE PRICE&quot;</code>所对应的<code>ss[]</code>表：</p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200405222657.png" style="zoom: 45%;"></p><p><strong>由ss[ ]表构造gs[ ]表：</strong></p><p>如下图所示，任一字符<code>P[j]</code>所对应的<code>ss[j]</code>值，可分两种情况提供有效的信息。</p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200405231557.png" style="zoom: 45%;"></p><p>第一种情况如图(a)，设该位置j满足：<code>ss[j] = j+1</code>，即<code>MS[j]</code>就是整个前缀<code>P[0,j]</code>。此时，对于<code>P[m-j-1]</code>左侧的每个字符<code>P[i]</code>而言，对应于4.3节中图11.12(d)所示的情况，<code>m-j-1</code>都应该是<code>gs[i]</code>取值的一个候选。</p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200405213530.png" style="zoom: 45%;"></p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200405231602.jpg" style="zoom:67%;"></p><p>第二种情况如图(b)所示，设该位置<code>j</code>满足：<code>ss[j] &lt;= j</code>，即<code>MS[j]</code>只是<code>P[0, j]</code>的一个真后缀。同时既然<code>MS[j]</code>是极长的，故必有：<code>P[ m - ss[j] -1 ] != P[ j - ss[j] ]</code> 。这就意味着此时的字符<code>P[m - ss[j] - 1]</code>恰好对应于如4.3节中的图11.12(c)的情况，因此<code>m-j-1</code>也应是<code>gs[m - ss[j] - 1]</code>取值的一个候选。</p><p>反过来，根据此前的定义，每一位置<code>i</code>所对应的<code>gs[i]</code>值只可能来自与以上候选。进一步地，既然<code>gs[i]</code>的最终取值是上述候选中的最小（最安全者），故仿照构造<code>bc[]</code>表的画家算法，累计用时将不超过$O(m)$。</p><p><strong>ss[ ]表的构造：</strong></p><p><code>ss[]</code>表是构造<code>gs[]</code> 表的基础与关键，若采用蛮力策略，对每个字符<code>P[j]</code>都做一趟扫描比对，直到出现失配，如此累计需要$O(m^2)$时间。</p><p>为了提高效率，不妨自后想前地逆向扫描，并逐一计算出各字符<code>P[j]</code>对应的<code>ss[j]</code>值。如下图所示，此时必有<code>P[j] = P[m-hi+j-1]</code>，故<strong>可利用此前已计算出的<code>ss[m-hi+j-1]</code>，分两种情况快速地导出<code>ss[j]</code></strong>。在此期间，只需动态地记录当前的极长匹配后缀：<code>P(lo, hi] = P[m -hi +lo, m)</code>。</p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200405233543.png" style="zoom: 45%;"></p><p><strong>第一种情况</strong>如图(a)，设：<code>ss[m - hi +j -1] &lt;= j-lo</code>，此时<code>ss[m - hi +j -1]</code>也是<code>ss[j]</code>可能的最大取值，于是便可直接得到：<code>ss[j] = ss[m - hi +j -1]</code></p><p><strong>第二种情况</strong>如图(b)，设：<code>j-lo &lt; ss[m - hi +j -1]</code>，此时至少仍有：<code>P(lo, j] = P[m - hi + lo, m -hi +j)</code>，故只需将<code>P(j - ss[m - hi + j - 1], lo]</code> 与 <code>P[m - hi + j - ss[m -hi + j -1], m - hi + lo)</code>做一比对，也可确定<code>ss[j]</code>。当然这种情况下极大匹配串的边界<code>lo</code>和<code>hi</code>也需要相应左移。</p><p>以上构思只要实现得当，也只需$O(m)$时间即可构造出<code>ss[]</code>表。</p><p><strong>算法实现：</strong></p><p>按照以上思路，<strong>GS表</strong>的构造算法可实现如下代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span>* <span class="title">buildSS</span> <span class="params">( <span class="keyword">char</span>* P )</span> </span>&#123; <span class="comment">//构造最大匹配后缀长度表：O(m)</span></span><br><span class="line">   <span class="keyword">int</span> m = <span class="built_in">strlen</span> ( P ); <span class="keyword">int</span>* ss = <span class="keyword">new</span> <span class="keyword">int</span>[m]; <span class="comment">//Suffix Size表</span></span><br><span class="line">   ss[m - <span class="number">1</span>]  =  m; <span class="comment">//对最后一个字符而言，与之匹配的最长后缀就是整个P串</span></span><br><span class="line"><span class="comment">// 以下，从倒数第二个字符起自右向左扫描P，依次计算出ss[]其余各项</span></span><br><span class="line">   <span class="keyword">for</span> ( <span class="keyword">int</span> lo = m - <span class="number">1</span>, hi = m - <span class="number">1</span>, j = lo - <span class="number">1</span>; j &gt;= <span class="number">0</span>; j -- )</span><br><span class="line">      <span class="keyword">if</span> ( ( lo &lt; j ) &amp;&amp; ( ss[m - hi + j - <span class="number">1</span>] &lt; j - lo ) ) <span class="comment">//情况一</span></span><br><span class="line">         ss[j] =  ss[m - hi + j - <span class="number">1</span>]; <span class="comment">//直接利用此前已计算出的ss[]</span></span><br><span class="line">      <span class="keyword">else</span> &#123; <span class="comment">//情况二</span></span><br><span class="line">         hi = j; lo = __min ( lo, hi );</span><br><span class="line">         <span class="keyword">while</span> ( ( <span class="number">0</span> &lt;= lo ) &amp;&amp; ( P[lo] == P[m - hi + lo - <span class="number">1</span>] ) ) <span class="comment">//二重循环？</span></span><br><span class="line">            lo--; <span class="comment">//逐个对比处于(lo, hi]前端的字符</span></span><br><span class="line">         ss[j] = hi - lo;</span><br><span class="line">      &#125;</span><br><span class="line">   <span class="comment">//*DSA*/ printf ( "-- ss[] Table -------\n" );</span></span><br><span class="line">   <span class="comment">//*DSA*/ for ( int i = 0; i &lt; m; i ++ ) printf ( "%4d", i ); printf ( "\n" );</span></span><br><span class="line">   <span class="comment">//*DSA*/ printString ( P ); printf ( "\n" );</span></span><br><span class="line">   <span class="comment">//*DSA*/ for ( int i = 0; i &lt; m; i ++ ) printf ( "%4d", ss[i] ); printf ( "\n\n" );</span></span><br><span class="line">   <span class="keyword">return</span> ss;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span>* <span class="title">buildGS</span> <span class="params">( <span class="keyword">char</span>* P )</span> </span>&#123; <span class="comment">//构造好后缀位移量表：O(m)</span></span><br><span class="line">   <span class="keyword">int</span>* ss = buildSS ( P ); <span class="comment">//Suffix Size table</span></span><br><span class="line">   <span class="keyword">size_t</span> m = <span class="built_in">strlen</span> ( P ); <span class="keyword">int</span>* gs = <span class="keyword">new</span> <span class="keyword">int</span>[m]; <span class="comment">//Good Suffix shift table</span></span><br><span class="line">   <span class="keyword">for</span> ( <span class="keyword">size_t</span> j = <span class="number">0</span>; j &lt; m; j ++ ) gs[j] = m; <span class="comment">//初始化</span></span><br><span class="line">   <span class="keyword">for</span> ( <span class="keyword">size_t</span> i = <span class="number">0</span>, j = m - <span class="number">1</span>; j &lt; UINT_MAX; j -- ) <span class="comment">//逆向逐一扫描各字符P[j]</span></span><br><span class="line">      <span class="keyword">if</span> ( j + <span class="number">1</span> == ss[j] ) <span class="comment">//若P[0, j] = P[m - j - 1, m)，则</span></span><br><span class="line">         <span class="keyword">while</span> ( i &lt; m - j - <span class="number">1</span> ) <span class="comment">//对于P[m - j - 1]左侧的每个字符P[i]而言（二重循环？）</span></span><br><span class="line">            gs[i++] = m - j - <span class="number">1</span>; <span class="comment">//m - j - 1都是gs[i]的一种选择</span></span><br><span class="line">   <span class="keyword">for</span> ( <span class="keyword">size_t</span> j = <span class="number">0</span>; j &lt; m - <span class="number">1</span>; j ++ ) <span class="comment">//画家算法：正向扫描P[]各字符，gs[j]不断递减，直至最小</span></span><br><span class="line">      gs[m - ss[j] - <span class="number">1</span>] = m - j - <span class="number">1</span>; <span class="comment">//m - j - 1必是其gs[m - ss[j] - 1]值的一种选择</span></span><br><span class="line">   <span class="comment">//*DSA*/ printGS ( P, gs );</span></span><br><span class="line">   <span class="keyword">delete</span> [] ss; <span class="keyword">return</span> gs;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="5-算法纵览"><a href="#5-算法纵览" class="headerlink" title="5.算法纵览"></a>5.算法纵览</h1><p>本文针对串匹配问题，依次介绍了<strong>蛮力</strong>、<strong>KMP</strong>、<strong>基于BC表</strong>、<strong>综合BC表与GS表</strong>等四种典型算法，其渐进复杂度的跨度范围，可概括为：</p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200405234952.png" style="zoom: 45%;"></p><p>KMP算法相比于蛮力算法的优势在于无论何种情况，时间效率均稳定在$O(n+m)$，因此在蛮力算法效率接近或达到最坏的$O(n<em>m)$时，KMP算法的优势才会十分明显。仅采用坏字符启发策略（BC）的BM算法，时间效率介于$O(n</em>m)$至$O(n/m)$之间，其最好情况与最坏情况相差悬殊。结合了好后缀策略（BC+GS）后的BM算法，则介于$O(n+m)$与$O(n/m)$之间，其在改进最低效率的同时也保持了最高效率的优势。</p><p><strong>单次比对成功概率：</strong></p><p>有趣的是，<strong>单次比对成功的概率，是决定串匹配算法时间效率的一项关键因素</strong>。纵观以串匹配算法，在每一对齐位置所进行的一轮比对中，仅有最后一次可能失败：反之此前的所有比对（若的确进行过）必然都是成功的。而各种算法的最坏情况均可概括为：因启发策略不够精妙甚至不当，在每一对齐位置都需进行多达$\Omega(n)$次成功的比对，另加最后一次失败的比对。</p><p>若<strong>将单次比对成功的概率记作Pr</strong>，以上串匹配算法的时间性能随Pr的变化趋势，大致如下图所示，其中纵坐标为运行时间，分为$O(n/m)$、$O(n+m)$、$O(n*m)$三挡。（图线只是示意大致的增长趋势）由于对于同一算法，消耗于每一对齐位置的平均时间成本随Pr的提高而增加，因此计算时间与Pr都具有单调正相关的关系。</p><p><img src="/2020/04/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%EF%BC%8820%EF%BC%89%E4%B8%B2/QQ图片20200406000219.png" style="zoom: 45%;"></p><p><strong>字符表长度：</strong></p><p>实际上在所有字符均等概率出现的情况下，<strong>Pr的取值将主要决定于字符表的长度</strong>$|\sum|$，<strong>并与之成反比关系</strong>：字符越长，其中任何一对字符匹配的概率越低。在通常情况下，蛮力算法实际的运行效率并不算太低。而不同的串匹配算法也因此有各自适用的场合。</p>]]></content>
    
    <summary type="html">
    
      串或字符串属于线性结构，自然地可以直接利用向量或列表等序列结构加以实现。但字符串作为一种数据结构，特点极其鲜明，作为字符串基本组成元素的字符，种类通常不多，甚至可能极少。因此，为了高效地处理以字符串形式表示的海量数据，需要设计专门的处理方法。
    
    </summary>
    
    
      <category term="数据结构与算法" scheme="http://nekomoon404.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="串匹配" scheme="http://nekomoon404.github.io/tags/%E4%B8%B2%E5%8C%B9%E9%85%8D/"/>
    
      <category term="KMP算法" scheme="http://nekomoon404.github.io/tags/KMP%E7%AE%97%E6%B3%95/"/>
    
      <category term="BM算法" scheme="http://nekomoon404.github.io/tags/BM%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
</feed>
