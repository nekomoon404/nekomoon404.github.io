<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://nekomoon404.github.io').hostname,
    root: '/',
    scheme: 'Muse',
    version: '7.7.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="文本介绍了三种无监督学习的Generative Model：Pixel RNN，Variational Auto-encoder(VAE)和Generative Adversarial Network(GAN)。">
<meta property="og:type" content="article">
<meta property="og:title" content="ML笔记（15）Unsupervised Learning-Generative Model">
<meta property="og:url" content="http://nekomoon404.github.io/2020/07/29/ML%E7%AC%94%E8%AE%B0%EF%BC%8815%EF%BC%89Unsupervised-Learning-Generative-Model/index.html">
<meta property="og:site_name" content="nekomoon的个人小站">
<meta property="og:description" content="文本介绍了三种无监督学习的Generative Model：Pixel RNN，Variational Auto-encoder(VAE)和Generative Adversarial Network(GAN)。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200729160702.png">
<meta property="og:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200729161342.png">
<meta property="og:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200729161919.png">
<meta property="og:image" content="http://nekomoon404.github.io/2020/07/29/ML%E7%AC%94%E8%AE%B0%EF%BC%8815%EF%BC%89Unsupervised-Learning-Generative-Model/QQ%E5%9B%BE%E7%89%8720200729163517.png">
<meta property="og:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200729163521.png">
<meta property="og:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200729163524.png">
<meta property="og:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200729164544.png">
<meta property="og:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200729163528.png">
<meta property="og:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200729165853.png">
<meta property="og:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200729165849.png">
<meta property="og:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200729171354.png">
<meta property="og:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200729171550.png">
<meta property="og:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200729172145.png">
<meta property="og:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200729172808.png">
<meta property="og:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200729165857.png">
<meta property="og:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200729165901.png">
<meta property="og:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200729204112.png">
<meta property="og:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200729172813.png">
<meta property="og:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200729172816.png">
<meta property="og:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200729172821.png">
<meta property="og:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200729214950.png">
<meta property="og:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200729221051.png">
<meta property="og:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200729224154.png">
<meta property="og:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200729230209.png">
<meta property="og:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200729224258.png">
<meta property="og:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200812231603.png">
<meta property="og:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200812231826.png">
<meta property="article:published_time" content="2020-07-29T07:59:14.000Z">
<meta property="article:modified_time" content="2020-08-12T07:59:14.000Z">
<meta property="article:author" content="nekomoon">
<meta property="article:tag" content="Pixel RNN">
<meta property="article:tag" content="VAE">
<meta property="article:tag" content="GAN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ%E5%9B%BE%E7%89%8720200729160702.png">

<link rel="canonical" href="http://nekomoon404.github.io/2020/07/29/ML%E7%AC%94%E8%AE%B0%EF%BC%8815%EF%BC%89Unsupervised-Learning-Generative-Model/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>ML笔记（15）Unsupervised Learning-Generative Model | nekomoon的个人小站</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="nekomoon的个人小站" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">nekomoon的个人小站</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://nekomoon404.github.io/2020/07/29/ML%E7%AC%94%E8%AE%B0%EF%BC%8815%EF%BC%89Unsupervised-Learning-Generative-Model/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="nekomoon">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="nekomoon的个人小站">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          ML笔记（15）Unsupervised Learning-Generative Model
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-29 15:59:14" itemprop="dateCreated datePublished" datetime="2020-07-29T15:59:14+08:00">2020-07-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-08-12 15:59:14" itemprop="dateModified" datetime="2020-08-12T15:59:14+08:00">2020-08-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Deep Learning</span>
                  </a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>7.3k</span>
            </span>
            <div class="post-description">文本介绍了三种无监督学习的Generative Model：Pixel RNN，Variational Auto-encoder(VAE)和Generative Adversarial Network(GAN)。</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>关于Generative Model推荐一篇很好的文章，来自OpenAI的<a href="https://openai.com/blog/generative-models/" target="_blank" rel="noopener">Generative Models</a>。文章的开头引用了<em>Richard Feynman</em>的话，<em>“What I cannot create, I do not understand”</em>，我无法创造的东西，我也无法真正理解，机器可以做猫狗分类，但却不一定知道“猫”和“狗”的概念，但如果机器能自己画出“猫”来，它或许才真正理解了“猫”这个概念，这也是Generative Model想要让machine做的事。</p>
<p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729160702.png" style="zoom:67%;"></p>
<p>下面将简要介绍：PixelRNN、VAE和GAN这三种Generative model的方法。</p>
<h3 id="1-PixelRNN"><a href="#1-PixelRNN" class="headerlink" title="1. PixelRNN"></a>1. PixelRNN</h3><p>RNN可以处理长度可变的input，它的基本思想是可以根据过去发生的状态去推测下一个状态。PixelRNN的基本思想是每次只画一个pixel来生成一个image，这个pixel是由过去所有已产生的pixel共同决定的。例如一个$3\times 3$的Image，第一次给一个橙色的pixel，输入到NN中，output得到一个蓝色的pixel；然后再将上一步得到的橙色和蓝色的pixel一起输入到NN中得到一个浅蓝色的pixel；再下一步将这三个pixel输入到NN中得到一个灰色的pixel，以此类推就可以得到一个$3\times 3$的image。这种方法的精髓在于根据过去预测未来，画出来的图一般都是比较清晰的</p>
<p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729161342.png" style="zoom:67%;"></p>
<p>（Reference[1]: <a href="https://arxiv.org/abs/1601.06759" target="_blank" rel="noopener"><em>Oord A, Kalchbrenner N, Kavukcuoglu K. Pixel recurrent neural networks[J]. arXiv preprint arXiv:1601.06759, 2016.</em></a>）</p>
<p>这个方法也适用于语音生成，可以用前面一段的语音去预测接下来生成的语音信号。也可以用在影像上，用前面一段video来预测后面的video。</p>
<p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729161919.png" style="zoom:67%;"></p>
<p>（Reference[2]: <a href="https://arxiv.org/abs/1609.03499" target="_blank" rel="noopener"><em>Oord A, Dieleman S, Zen H, et al. Wavenet: A generative model for raw audio[J]. arXiv preprint arXiv:1609.03499, 2016.</em></a> </p>
<p>Reference[3]:  <a href="https://arxiv.org/abs/1610.00527" target="_blank" rel="noopener"><em>Kalchbrenner N, Oord A, Simonyan K, et al. Video pixel networks[C]//International Conference on Machine Learning. 2017: 1771-1779.</em></a>）</p>
<p><strong>pokemon creation</strong></p>
<p>下面这个小例子是给machine792个pekemon的image，想让machine学会去生成pekeon的Image。</p>
<p><img src="/2020/07/29/ML%E7%AC%94%E8%AE%B0%EF%BC%8815%EF%BC%89Unsupervised-Learning-Generative-Model/QQ图片20200729163517.png" style="zoom:67%;"></p>
<p>在使用Generative model去生成宝可梦之前，有几个tips需要注意：</p>
<ul>
<li><p>为了减少运算量，将40×40的图像截取成20×20</p>
</li>
<li><p>如果将每个pixel都以[R, G, B]的vector表示的话，生成的图像都是灰蒙蒙的，原因如下：</p>
<ul>
<li><p>亮度比较高的图像，一般都是RGB值差距特别大而形成的，如果各个维度的值大小比较接近，则生成的图像偏向于灰色；</p>
</li>
<li><p>如果用sigmoid function，最终生成的RGB往往都是在0.5左右（归一化之后），导致色彩度不鲜艳；</p>
</li>
<li><p>解决方案：将所有色彩集合成一个1-of-N encoding，由于色彩种类比较多，因此这里先对相近的颜色做clustering聚类表示为一种颜色，最终获得了167种色彩组成的向量。我们用这样的向量去表示每个pixel，可以让生成的色彩比较鲜艳。</p>
</li>
</ul>
</li>
</ul>
<p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729163521.png" style="zoom:67%;"></p>
<p>相关数据连接如下：</p>
<ul>
<li>原始图像(40*40)数据的<a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2016/Pokemon_creation/image.rar" target="_blank" rel="noopener">链接</a></li>
<li>裁剪后的图像(20*20)数据<a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2016/Pokemon_creation/pixel_color.txt" target="_blank" rel="noopener">链接</a></li>
<li>数值与色彩(RGB)的映射关系<a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2016/Pokemon_creation/colormap.txt" target="_blank" rel="noopener">链接</a></li>
</ul>
<p>使用PixelRNN训练好模型之后，给它看没有被放在训练集中的3张图像的一部分，分别遮住原图的50%和75%，得到的原图如下：</p>
<p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729163524.png" style="zoom:67%;"></p>
<p>训练好的pixel RNN预测到的图片如下：</p>
<p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729164544.png" style="zoom:60%;"></p>
<p>做这种Generation的task有一个难点是，设计上的好坏较难去evaluate。接下来我们让训练好的model凭空去画，但如果什么都不给machine让它从头开始画的话，它得到的每一个image可能都是一样的，因此我们要故意加一些random，即machine在画下一个pixel的时候不一定是选几率最高的颜色，也有几率选几率比较低的颜色，这样它每次画出来的图才会有点不一样。</p>
<p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729163528.png" style="zoom:67%;"></p>
<h3 id="2-VAE"><a href="#2-VAE" class="headerlink" title="2. VAE"></a>2. VAE</h3><p>上一篇笔记中介绍过Auto-encoder，如果我们拿出其中的Decoder，给它随机的code，就可以生成对应的图像。但普通的Decoder生成效果并不好，VAE（Variational Auto-encoder，可变自动编码器）可以得到更好的效果。</p>
<p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729165853.png" style="zoom:67%;"></p>
<p>在VAE中，code不再直接等于Encoder的输出，这里假设目标降维空间为3维，那我们使Encoder分别输出$m_1,m_2,m_3$和$\sigma_1,\sigma_2,\sigma_3$，此外我们从正态分布中随机取出三个点$e_1,e_2,e_3$，将下式作为最终的编码结果：</p>
<script type="math/tex; mode=display">
c_i = \exp(\sigma_i)\cdot e_i+m_i</script><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729165849.png" style="zoom:67%;"></p>
<p>再将$c_i$输入到Decoder里面得到output，我们希望MInimize reconstruction error。但此时，我们的训练目标不仅要最小化input和output之间的差距，还要同时最小化下式（比较“神妙”）：</p>
<script type="math/tex; mode=display">
\sum\limits_{i=1}^3 (1+\sigma_i-(m_i)^2-e^{\sigma_i})</script><h4 id="2-1-Pokemon-Creation"><a href="#2-1-Pokemon-Creation" class="headerlink" title="2.1. Pokemon Creation"></a>2.1. Pokemon Creation</h4><p>与PixelRNN不同的是，VAE画出的图一般都是不太清晰的，但在某种程度上我们可以控制生成的image。假设我们现在把VAE用在Pokemon creation上面，在Trainig的时候我们input一个pokemon，然后reconstruct一个同样的pokemon，learn出来的code设为10维。Learn好这个VAE之后，我们把Decoder的部分拿出来。我们在给Decoder输入10维的vector时可以固定其中的8维，只选2维出来，我们可以在2维平面上sample一系列的点，加上我们固定的8维后Input到Decoder中看输出的image是什么样的。这样我们就可以解读code的每一个dimension是代表什么含义，然后去控制VAE去生成一些image。</p>
<p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729171354.png" style="zoom:67%;"></p>
<p>下面是固定code中的8维，让剩下的2维变化得到的image，发现image的变化确实是有些规律的。</p>
<p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729171550.png" style="zoom:67%;"></p>
<h4 id="2-2-Writing-Poerty"><a href="#2-2-Writing-Poerty" class="headerlink" title="2.2. Writing Poerty"></a>2.2. Writing Poerty</h4><p>VAE还可以用来写诗，将input和output都换成是sentence，我们只需要得到某两句话对应的code，然后在降维后的空间中得到这两个code所在点的连线，从中间等间隔地取一些点，把这些点输入给Decoder，得到还原后的句子，就可以得到类似下图中的效果。</p>
<p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729172145.png" style="zoom: 80%;"></p>
<h4 id="2-3-Why-VAE"><a href="#2-3-Why-VAE" class="headerlink" title="2.3. Why VAE?"></a>2.3. Why VAE?</h4><p>VAE和传统的Auto-encoder相比，有什么优势呢？事实上，VAE就是加了噪声noise的Autoencoder，它的抗干扰能力更强，过渡生成能力也更强。</p>
<p>对原先的Autoencoder来说，假设我们得到了满月和弦月的code，从两者连线中随机获取一个点并映射回原来的空间，得到的图像很可能是完全不一样的东西，因为code和output得到的image是一一对应的。</p>
<p>而对VAE来说，它要保证在降维后的code空间中，加了noise的一段范围内的所有点都能够映射到目标图像，如下图所示，当某个点既被要求映射到满月、又被要求映射到弦月，则它最终映射出来的结果就很有可能是两者之间的过渡图像。</p>
<p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729172808.png" style="zoom:67%;"></p>
<p>再回过来头看VAE的结构，其中：</p>
<ul>
<li><p>$m_i$其实就代表原来的code</p>
</li>
<li><p>$c_i$则代表加了noise以后的code</p>
</li>
<li><p>$\sigma_i$代表了noise的variance，描述了noise的大小，这是由NN学习到的参数</p>
<p>（注：使用$\exp(\sigma_i)$的目的是保证variance是正的）</p>
</li>
<li><p>$e_i$是正态分布中随机采样的点</p>
</li>
</ul>
<p>注意到，损失函数仅仅让input和output差距最小是不够的，因为variance是由机器自己决定的，如果不加以约束，它自然会去让variance=0，这就跟普通的Autoencoder没有区别了。</p>
<p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729165857.png" style="zoom:67%;"></p>
<p>额外加的限制函数解释如下：</p>
<p>下图中，蓝线表示$e^{\sigma_i}$，红线表示$1+\sigma_i$，两者相减得到绿线。绿线的最低点$\sigma_i=0$，则variance $e^{\sigma_i}=1$，此时loss最低，而$(m_i)^2$项则是对code的L2 regularization，让它比较sparse，不容易过拟合。</p>
<p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729165901.png" alt></p>
<p>上面是比较直观的理由，以下是paper上比较常见的解释。我们回归到我们要做的事情是什么，假设要machine generate pokemon的image，那每一张pokemon的图都可以想成是高维空间中的一个点。假设它是20*20的image，在高维空间中也就是400维的点，在图上我们用一维描述它，但其实是一个高维的空间。那现在要做的就是estimate p(x)的分布，它表示一张图片像宝可梦的几率，然后就可以根据p(x)高的地方去sample出一张像宝可梦的图。</p>
<p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729204112.png" style="zoom:60%;"></p>
<p>Estimate the probability distributon可以用Gaussion mixture model。Guassion mixture model：现在有一个distribution(黑色的线)，这个黑色的distribution其实是很多的Gaussion(青蓝色)用不同的weight叠合起来的结果。如果你的gaussion数目够多，你就可以产生很复杂的distribution，公式为 $p(x)=\sum_{m}p(m)p(x|m)$ 。</p>
<p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729172813.png" style="zoom:67%;"></p>
<p>这样每一个$x$并不属于某一个class或者cluster，而是有一个vector来描述它不同面向的disstribution，描述它不同面向的特性，<strong>VAE其实就是Gaussian Mixture Model的Distributed representation的版本</strong>。</p>
<p>假设我们要sample一个vector $z$，$z$是从normal distribution中sample出来的，$z$的每一个dimension都代表了某种attribute（特质，特性）。由$z$可以决定Gaussian的mean $\mu$和variance $\sigma$，由于$z$是continous的，所有它有无穷的可能，那mean和variance也有无穷多的可能。</p>
<p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729172816.png" style="zoom:67%;"></p>
<p>$P(x)$的曲线是这样产生的：$z$上的每一个点都有可能被sample到，当sample出一个点后它就会对应到一个Gaussian，把它们mixture起来就得到了$P(x)$，即$P(x)=\int \limits_{z}P(z)P(x|z)dz $（注意因为$z$是continous的，所以这里要用积分，而不是sum）。</p>
<h4 id="2-4-Maximizing-Likelihood"><a href="#2-4-Maximizing-Likelihood" class="headerlink" title="2.4. Maximizing Likelihood"></a>2.4. Maximizing Likelihood</h4><p>那给出一个$z$怎么找出mean和variance呢，假设mean和variance都来自一个function，这个function就可以是一个NN。当然$z$的分布不一定是Gaussian，可以自己设定。那训练这个NN的目标就是要Maximiza the likelihood of the observed $x$，即使下式最大：</p>
<script type="math/tex; mode=display">
L=\sum \limits_{x}\log P(x)</script><p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729172821.png" style="zoom:67%;"></p>
<p>我们要做的就是调NN里的参数weight和bias，使得likelihood最大。然后我们需要引入另一个distribution $q(z|x)$，它是given $x$来决定在$z$的space上的mean和variance，还需要有另外一个NN’，input $x$之后会output对应的$z$的mean $\mu’(x)$和variance $\sigma’(x)$，即决定$z$要从什么样的mean和variance中被sample出来。</p>
<p>上图中上面的NN就相当于是VAE中的Decoder，下面的NN就相当于是VAE中的ENcoder。</p>
<p>下面是对$L=\sum \limits_{x}\log P(x)$的表达式的具体的推导：</p>
<p>推导$\log P(x)=L_b+KL(q(z|x)||P(z|x))$：</p>
<p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729214950.png" style="zoom:67%;"></p>
<p>我们本来要做的是找使得$L$最大的$P(x|z)$，现在转换为求使$L_b$最大的$P(x|z)$和$q(z|x)$。 </p>
<p>如果我们只找$p(x∣z)$ 这一项的话，然后去maximizing $L_b$ ，当增加$L_b$的时候，有可能会增加likehood，但不知道likehood跟lower bound之间到底有还差多少距离。你希望你做到的是：当lower bound上升的时候，likehood也跟着上升。但是有可能会遇到糟糕的事情是：lower bound上升的时候，likehood反而下降，因为不知道它们之间的差距是多少。</p>
<p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729221051.png" style="zoom:95%;"></p>
<p>引入$q(z|x)$这一项就是为了解决这一问题。如上图中蓝色的是likehood， $\log P(x)=L_b+KL$，如果你今天调 $q(z|x)$来maximizing $L_b$，会发现$q(z|x)$跟$\log P(x)$是没有关系的，即ikelihood不变，那maximizing $L_b$的同时也在minimize KL divergence，即让lower bound（$L_b$）跟likehood越来越接近。如果固定住 $p(x|z)$这一项，去调 $q(z|x)$这一项的话，会让$L_b$ 一直上升，直到KL divergence会完全不见。由于likehood一定要比lower bound大，这时你再调$p(x|z)$和$q(z|x)$来maximizing $L_b$的话，就可以保证likehood会一定增大。</p>
<p>这样做也会得到一个副产物，当maximize $L_b$这一项的时候，会让KL divergence越来越小，意味着会让 $q(z|x)$ 跟 $p(z|x)$越来越接近。所以接下来做的事情就是找$p(x|z)$跟$q(z|x)$，可以让$L_b$越大越好，就等同于让likehood越来越大，最后顺便会得到$q(z|x)$可以去approximation $p(z|x)$。</p>
<p>而$q$是个neural network，要去minimize $KL(q(z|x)||P(z))$就是去调NN‘让它产生的distribution和normal distribution越接近越好，而loss function就是之前讲过的那个式子$\sum \limits^{3} \limits_{i=1}(\exp(\sigma_i)-(1+\sigma_i)+(m_i)^2)$（这部分的推导可以参考VAE的原始论文）。</p>
<p>另外一项是转化为$\log P(x|z))$的期望值：</p>
<script type="math/tex; mode=display">
P(x)=\int \limits_{z}P(z)P(x|z)dz=E_{q(z|x)}[\log P(x|z)]</script><p>可以理解是我们从$q(z|x)$中去sample data，要让$\log P(x|z)$越大越好，这其实就是Auto-encoder在做的事情。你可以把$x$输入到NN’中得到mean $\mu’(x)$和variance $\sigma’(x)$，根据这个mean和variance可以sample出一个$z$；接下来把z输入到NN，得到mean $\mu(x)$和variance $\sigma(x)$，我们的目标是让这个mean和variance代表的distribution是$x$的几率越大越好，在实际使用中往往不考虑variance，那我们就是让最后输出的mean和$x$越接近越好，这不就是Auto-encoder在做的事情。</p>
<p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729224154.png" style="zoom:90%;"></p>
<p><strong>Conditional VAE</strong></p>
<p>还有一种方法叫Conditional VAE，举个例子，如果你让VAE可以产生手写的数字，给它一个digit，然后它把这个digit的特性抽取出来(笔画的粗细等等)，然后丢进encoder的时候一方面给它有关这个数字特性的distribution，另外一方面告诉decoder它是什么数字。那你就可以根据这一个digit，generate跟它style相近的digit。Conditional VAE可以根据某一个digit画出跟它style相近的数字。</p>
<p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729230209.png" style="zoom:80%;"></p>
<p><strong>Problems of VAE</strong></p>
<p>VAE有一个缺点，它只是在努力做到让生成的图像与数据集里的图像尽可能相似，却从来没有想过怎么样真的产生一张新的图像，因此由VAE生成的图像大多是数据集中图像的线性变化，而很难自主生成全新的图像。假设Decoder output跟真正的image之间有一个pixel的差距，那有时不同的pixel落在不同的位置会得到非常不一样的结果，如下图中的两个数字“7”，人很容易发现其区别：左边的像是真的数字，而右边明显是fake。但对VAE来说，它们只是有一个pixel的差异，两张image都是一样好或者不好的。VAE做到的只是模仿，而不是创造，GAN的诞生，就是为了创造。</p>
<p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200729224258.png" style="zoom:67%;"></p>
<h3 id="3-GAN"><a href="#3-GAN" class="headerlink" title="3. GAN"></a>3. GAN</h3><p>Generative Adversarial Network（GAN，对抗生成网络），基本思想类似天敌之间相互竞争，相互进步。</p>
<p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200812231603.png" style="zoom:67%;"></p>
<p>GAN由生成器(Generator)和判别器(Discriminator)组成：</p>
<ul>
<li>对判别器的训练：把生成器产生的图像标记为0，真实图像标记为1，丢给判别器训练分类，希望它能分辨real image和fake image；</li>
<li>对生成器的训练：调整生成器的参数，使产生的图像（fake image）能够“骗过”判别器，即判别器输出越接近1越好；</li>
<li>每次训练GAN时生成器和判别器要分开训练：先Fix住生成器，训练判别器的参数；再Fix 判别器，训练生成器的参数，如此反复。</li>
</ul>
<p><img src="https://gitee.com/nekomoon404/blog-img/raw/master/img/QQ图片20200812231826.png" style="zoom:80%;"></p>
<p>（PS：李老师后面会有专门介绍GAN的课程，之后再做详细记录吧。）</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Pixel-RNN/" rel="tag"># Pixel RNN</a>
              <a href="/tags/VAE/" rel="tag"># VAE</a>
              <a href="/tags/GAN/" rel="tag"># GAN</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/07/29/ML%E7%AC%94%E8%AE%B0%EF%BC%8814%EF%BC%89Unsupervised-Learning-Deep-Auto-encoder/" rel="prev" title="ML笔记（14）Unsupervised Learning-Deep Auto-encoder">
      <i class="fa fa-chevron-left"></i> ML笔记（14）Unsupervised Learning-Deep Auto-encoder
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/08/13/ML%E7%AC%94%E8%AE%B0%EF%BC%8816%EF%BC%89Transfer-Learning/" rel="next" title="DL笔记（16）Transfer Learning">
      DL笔记（16）Transfer Learning <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-PixelRNN"><span class="nav-text">1. PixelRNN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-VAE"><span class="nav-text">2. VAE</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-Pokemon-Creation"><span class="nav-text">2.1. Pokemon Creation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-Writing-Poerty"><span class="nav-text">2.2. Writing Poerty</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3-Why-VAE"><span class="nav-text">2.3. Why VAE?</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-4-Maximizing-Likelihood"><span class="nav-text">2.4. Maximizing Likelihood</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-GAN"><span class="nav-text">3. GAN</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="nekomoon"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">nekomoon</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">55</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">57</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/nekomoon404" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;nekomoon404" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:nekomoon404@163.com" title="E-Mail → mailto:nekomoon404@163.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="/atom.xml" title="RSS → &#x2F;atom.xml"><i class="fa fa-fw fa-rss"></i>RSS</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 2020.1.12 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">nekomoon</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">544k</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.7.0
  </div>

        








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  


   
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/moment.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment-precise-range-plugin@1.3.0/moment-precise-range.min.js"></script>
<script>
  function timer() {
    var ages = moment.preciseDiff(moment(),moment(20200112,"YYYYMMDD"));
    ages = ages.replace(/years?/, "年");
    ages = ages.replace(/months?/, "月");
    ages = ages.replace(/days?/, "天");
    ages = ages.replace(/hours?/, "小时");
    ages = ages.replace(/minutes?/, "分");
    ages = ages.replace(/seconds?/, "秒");
    ages = ages.replace(/\d+/g, '<span style="color:#1890ff">$&</span>');
    div.innerHTML = `我已在此等候你 ${ages}`;
  }
  var div = document.createElement("div");
  //插入到copyright之后
  var copyright = document.querySelector(".copyright");
  document.querySelector(".footer-inner").insertBefore(div, copyright.nextSibling);
  timer();
  setInterval("timer()",1000)
</script>


 
<script>
  var OriginTitile = document.title;
  var titleTime;
  document.addEventListener("visibilitychange", function() {
    if (document.hidden) {
      document.title = "(つェ⊂)我藏好了哦~" + OriginTitile;
      clearTimeout(titleTime);
    } else {
      document.title = "(*´∇｀*) 被你发现啦~" + OriginTitile;
      titleTime = setTimeout(function() {
        document.title = OriginTitile;
      }, 2000);
    }
  });
</script>

</body>
</html>
